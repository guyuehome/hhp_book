{"config":{"indexing":"full","lang":["en","ja"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-\\.]+"},"docs":[{"location":"","text":"引言 机器人是一个非常复杂的系统，硬件部分包括：各种各样感知环境信息的传感器、作为大脑进行计算的主控平台、执行动作的电机等等。软件层面包括：感知算法，规控算法，数据驱动的程式，操作系统等。 2022年6月，地平线机器人正式推出全新一代机器人开发平台，在软件、算法、工具层面给行业带来更多帮助。 本教程将会以旭日X3派为平台，介绍地平线机器人开发平台的使用原理与方法。 教程链接汇总 旭日X3派开发板使用手册： https://developer.horizon.ai/api/v1/fileData/documents_pi/index.html 机器人开发平台使用手册： https://developer.horizon.ai/api/v1/fileData/TogetherROS/index.html 视频课程： https://class.guyuehome.com/all/10284445/19617453 图文教程： https://hhp.guyuehome.com/ 教程问答： https://www.guyuehome.com/Bubble/circleDetail/id/92 博客泡圈： https://www.guyuehome.com/","text_tokens":["主控","执行",":","动作","引言","视频","地平线","操作系统","工具","进行","html","复杂","非常复杂","机器","，","id","等等","手册"," ","推出","驱动","92","平台","本","class","hhp","环境","19617453",".","给","各种","ai","软件","v1","www","bubble","各种各样","行业","包括","一个","年","多","地平","派","与","：","各样","机器人","大脑","课程","博客","原理","。","程式","开发","使用","horizon","6","togetherros","图文","帮助","filedata","以","感知","系统","带来","方法","circledetail","developer","10284445","、","全新","使用手册","pi","的","月","汇总","2022","介绍","链接","教程","api","是","计算","算法","信息","电机","旭日","硬件","all","感器","等","documents","数据","/","在","部分","_","传感","非常","x3","问答","作为","泡圈","更","index","com","层面","https","为","操作","规控","将会","传感器","一代","guyuehome","开发板","正式"],"title":"引言","title_tokens":["引言"]},{"location":"#_1","text":"机器人是一个非常复杂的系统，硬件部分包括：各种各样感知环境信息的传感器、作为大脑进行计算的主控平台、执行动作的电机等等。软件层面包括：感知算法，规控算法，数据驱动的程式，操作系统等。 2022年6月，地平线机器人正式推出全新一代机器人开发平台，在软件、算法、工具层面给行业带来更多帮助。 本教程将会以旭日X3派为平台，介绍地平线机器人开发平台的使用原理与方法。","text_tokens":["主控","执行","动作","地平线","操作系统","工具","进行","复杂","非常复杂","机器","，","等等"," ","推出","驱动","平台","本","环境","给","各种","软件","各种各样","行业","包括","一个","年","多","地平","派","与","：","各样","机器人","大脑","原理","。","程式","开发","使用","6","帮助","以","感知","系统","带来","方法","、","全新","的","月","2022","介绍","教程","是","计算","算法","信息","电机","旭日","硬件","感器","等","数据","在","部分","传感","非常","x3","作为","更","层面","为","操作","规控","将会","传感器","一代","正式"],"title":"引言","title_tokens":["引言"]},{"location":"#_2","text":"旭日X3派开发板使用手册： https://developer.horizon.ai/api/v1/fileData/documents_pi/index.html 机器人开发平台使用手册： https://developer.horizon.ai/api/v1/fileData/TogetherROS/index.html 视频课程： https://class.guyuehome.com/all/10284445/19617453 图文教程： https://hhp.guyuehome.com/ 教程问答： https://www.guyuehome.com/Bubble/circleDetail/id/92 博客泡圈： https://www.guyuehome.com/","text_tokens":["all","togetherros","图文","ai","filedata",":","v1","documents","/","www","bubble","circledetail","developer","_","视频","10284445","派","html","：","x3","使用手册","机器人","机器","问答","id","pi","泡圈","课程","博客","index","com","手册","https"," ","教程","92","开发","平台","api","使用","guyuehome","开发板","class","horizon","hhp","19617453","旭日","."],"title":"教程链接汇总","title_tokens":["教程","链接","汇总"]},{"location":"about/","text":"学机器人，上古月居 古月居 ，是华语地区知名的ROS机器人社区（ www.guyuehome.com ），致力于为机器人学习者提供优质的交流学习平台，线上用户超过120万人，努力构建集人才、内容、校企为一体的社区生态，2011年创建至今，累积高质量内容超过1000万字、视频课程超过1000小时，出版《ROS机器人开发实践》等畅销图书，与众多高校及企业建立合作，通过AI机器人+社区生态的创新模式，赋能面向未来的人才培养。 版权声明 古月居网站的所有作品，包括但不限于课程、视频、课件和源码等均为武汉精锋微控科技有限公司合法拥有版权或依法有权使用的作品，仅限被授权用户的个人学习使用。 未经本公司书面许可，任何单位或个人不得对本网站的作品进行使用、复制、修改、抄录、传播、镜像或与其它产品捆绑使用、销售等。 违反上述声明者，本公司将追究其法律责任。 如需授权请联系 brand@guyuehome.com 。","text_tokens":["万人","内容","课件","视频","构建","未经","进行","万字","其它","责任","，","机器","建立","培养","致力","众多","追究其","累积","联系"," ","平台","出版","《","交流","及","源码","抄录","有权","被","本","上述","赋能","或","依法","华语","书面","提供","通过","传播","网站",".","高质","镜像","面向","作品","知名","ai","限于","究其","小时","许可","www","用户","120","包括","交流学习","地区","年","与","明者","机器人","致力于","声明","课程","。","2011","单位","追究","版权","开发","人才","使用","图书","仅限","对本","超过","学习","（","优质","模式","质量","任何","捆绑","、","面向未来","古月","人才培养","个人","）","公司","的","科技","实践","高质量","未来","高校","销售","创新","复制","授权","是","均","线上","上","将","学习者","精锋","合作","声明者","等","+","如需","请","校企","法律","ros","和","至今","1000","武汉","微控","学","社区","法律责任","违反","不","com","企业","有限公司","合法","拥有","努力","为","一体","畅销","@","创建","有限","产品","guyuehome","不得","修改","生态","居","所有","集","但","》","brand"],"title":"关于我们","title_tokens":["关于","我们"]},{"location":"about/#_1","text":"古月居 ，是华语地区知名的ROS机器人社区（ www.guyuehome.com ），致力于为机器人学习者提供优质的交流学习平台，线上用户超过120万人，努力构建集人才、内容、校企为一体的社区生态，2011年创建至今，累积高质量内容超过1000万字、视频课程超过1000小时，出版《ROS机器人开发实践》等畅销图书，与众多高校及企业建立合作，通过AI机器人+社区生态的创新模式，赋能面向未来的人才培养。","text_tokens":["万人","内容","视频","构建","万字","，","机器","建立","培养","致力","众多","累积"," ","平台","出版","《","交流","及","赋能","华语","提供","通过",".","高质","面向","知名","ai","小时","www","用户","120","交流学习","地区","年","与","机器人","致力于","课程","。","2011","开发","人才","图书","超过","学习","（","优质","模式","质量","、","面向未来","古月","人才培养","）","的","实践","高质量","未来","高校","创新","是","线上","学习者","合作","等","+","校企","ros","至今","1000","社区","com","企业","努力","为","一体","畅销","创建","guyuehome","生态","居","集","》"],"title":"学机器人，上古月居","title_tokens":["学","上","古月","居","机器人","，","机器"]},{"location":"about/#_2","text":"古月居网站的所有作品，包括但不限于课程、视频、课件和源码等均为武汉精锋微控科技有限公司合法拥有版权或依法有权使用的作品，仅限被授权用户的个人学习使用。 未经本公司书面许可，任何单位或个人不得对本网站的作品进行使用、复制、修改、抄录、传播、镜像或与其它产品捆绑使用、销售等。 违反上述声明者，本公司将追究其法律责任。 如需授权请联系 brand@guyuehome.com 。","text_tokens":["课件","视频","未经","进行","责任","其它","，","联系"," ","抄录","源码","有权","被","本","上述","或","依法","书面","传播","网站",".","镜像","作品","限于","究其","许可","用户","包括","与","明者","声明","课程","。","单位","追究","版权","使用","仅限","对本","学习","任何","捆绑","、","古月","个人","公司","的","科技","销售","复制","授权","均","将","精锋","声明者","等","如需","请","法律","和","武汉","微控","法律责任","违反","不","com","有限公司","合法","拥有","为","@","有限","产品","不得","guyuehome","修改","居","所有","但","追究其","brand"],"title":"版权声明","title_tokens":["声明","版权"]},{"location":"hhp/1.1_%E6%99%BA%E8%83%BD%E6%9C%BA%E5%99%A8%E4%BA%BA%E5%8F%91%E5%B1%95%E4%B8%8E%E7%8E%B0%E7%8A%B6/","text":"智能机器人发展与现状 智能机器人正在改变着我们的生活，想象这样一种场景。 也许不知不觉的某一天，我们就会发现类似这样的机器人会真实出现在生活当中。 科技的发展日新月异，智能机器人也突飞猛进，伴随机器人发展而生的机器人操作系统，也是机器人重要的发展动力之一。 智能机器人举例 提到智能机器人，大家脑海里会映射出什么样的情景呢？ 是不是会有很多科幻电影中变形金刚、大白机器人、星球大战等场景呢？ 智能机器人这个概念，只是一个科幻词汇么？当然不是的，其实在我们身边，已经有越来越多智能机器人出现，我们来看看他们都在哪里？ 扫地机器人 先来看一个大家最熟悉的一个类型——扫地机器人。现在的扫地机器人，除了可以完成扫地、拖地这样一些基本功能之外，还搭载了激光雷达、相机、红外等十几种传感器。 一个全新的扫地机器人虽然是第一次来到你家，但是它可能用到 5 分到 10 分钟时间，很快就可以通过它的传感器对你的家庭环境了如指掌，也就是把实际的家庭环境做成了一张地图，这样他就会知道哪里是卧室，哪里是餐厅，哪里是厨房，不同的区域用多大的风力，用多大的水量来去清扫最为合适，它都会智能化地来做判断。 除此之外，它还得知道怎么样去躲避各种障碍物，比如说家里面的宠物、地上摆放的插线板，各种各样的杂物等等。 所以看似非常小的一个扫地机器人，其实已经是一个很智能化的家用设备了，正在潜移默化地改变着我们的生活。 自动化仓储 第二个案例，虽然大部分人在生活中不会直接接触，但却和每一个人息息相关，那就是自动化仓储。 这是京东某个实际部署运营的一套自动化的仓库，在里面可以看到各种各样的机器人，比如工业机械臂、移动机器人等等，这套立体仓库当中大量的货架也是自动化的，这就是一个典型的机器人应用场景。 之前有一个关于京东的新闻报道，里边讲到，从我们下单那刻开始，到商品分拣出来放到快递员手上，只需要20分钟。比如我们要买个手机，下单付款，20分钟之后，这个手机已经从这么庞大的仓库中顺利找到，并且完成了包装、打标、分配等一系列工序。这样，我们在绝大部分城市，基本都可以体验到下单之后，当天或者隔天收货的体验，为什么它可以做到如此高效，就是因为背后这一套由机器人组成的自动化系统，借助大数据的分析，甚至可以做到在你下单之前，平台就知道你将要买什么东西。比如说你会按照一个月的频率买米买面，那平台就可以预测到上个月你买的米应该快吃完了，然后就会在距离你家最近的一个仓库里面备货。 当你下单之后，这袋米可能半个小时送到你手上了。 自动驾驶 第三个案例，那就是当今最为热门的技术之一——自动驾驶。 自动驾驶汽车也是典型的移动机器人系统，为了保证绝对安全的驾驶过程，汽车上装配了非常多的传感器，以及极为复杂的控制算法。 视频中我们看到的是华为自动驾驶系统在实际路面上测试的效果，自动驾驶汽车通过多个相机、雷达、超声波，实时构建周围环境的三维信息，不仅可以动态识别路面上的行人车辆、车道线、交通指示灯等，还可以安全完成超车、会车、跟车、转向等重要功能，同时对突发状况也可以及时处理，比如躲避突然出现的车辆、礼让行人等，最终自动行驶入库，把我们安全顺利的送到目的地。 虽然自动驾驶相关的技术和法律法规还在不断完善中，但是相信有一天我们每个人都可以体验自动驾驶的乐趣，而且这一天不会太远。 智能机器人发展 机器人的发展横跨几十年，经历了三个重要时期。 2000年前，机器人主要应用于工业生产，俗称工业机器人，由示教器操控，帮助工厂释放劳动力，此时的机器人并没有太多智能而言，完全按照人类的命令执行动作，更加关注电气层面驱动器、伺服电机、减速机、控制器等设备，这是机器人的电气时代。 2000年后，计算机和视觉技术逐渐应用，机器人的类型不断丰富，出现了AGV、视觉检测等应用，此时的机器人传感器更加丰富，但是依然缺少自主思考的过程，智能化有限，只能感知局部环境，这是机器人的数字时代，不过这也是机器人大时代的前夜。 2015年之后，随着人工智能技术的快速发展，机器人成为了AI技术的最佳载体，家庭服务机器人、送餐机器人、四足仿生机器狗、自动驾驶汽车等应用呈井喷状爆发，智能机器人时代正式拉开序幕。 2015年之后，智能机器人市场迅速爆发，到2025年，国内人工智能市场有望达到1164亿元，而作为人工智能重要载体的机器人，市场更会达到1463亿元。 行业的快速发展，必将带动大量专业人才的需求，人才缺口也将逐年扩大，2025年，预计国内机器人行业的人才缺口将超过450万，人工智能方面的缺口更会达到1000万。 面对如此严峻的人才需求，国内各高校从2016年起，陆续开设机器人和人工智能专业，为人才的供给提供有力保障。 智能机器人的快速发展，必将对机器人开发提出更高的要求，软件层面最为热点的技术之一就是机器人操作系统，这也是我们课程的主角。 机器人操作系统 对于越来越复杂的智能机器人系统，已经不是一个人或者一个团队可以独立完成的，如何高效开发机器人，是技术层面上非常重要的一个问题，针对这个问题，一群斯坦福大学的有志青年尝试给出一个答案，那就是机器人操作系统。 ROS的诞生 2007年，他们诞生了这样一个想法，我们有没有可能做一款个人服务机器人，帮助我们完成洗衣、做饭、收拾家等一切你不想做的事情，甚至还可以在你无聊的时候，陪你聊天玩耍，最后他们真的做出来了。 当时，他们深知做出这样一款机器人并不容易，机械、电路、软件等都要涉及，而且横跨很多个专业，光靠自己肯定做不到，此时他们诞生了这样一个想法：既然自己做不到，那为什么不联合所有人一起干呢？如果设计一套标准的机器人平台和其中的软件，大家都可以在这个平台上做应用开发，既然应用软件都基于同一平台，应用的分享也很容易实现，这就类似别人开发的苹果手机应用，只要你有苹果手机，同样也可以用。 说干就干，初期的机器人原型是用实验室可以找到的木头和一些零部件组成的，后期有了充足的资金，才得以实现图中这款外观精致、性能强悍的机器人——PR2，Personal Robot 2代。 在这几个图中，我们可以看到PR2机器人已经可以完成叠毛巾、熨烫衣服、打台球、剪头发等一系列复杂的应用功能，以叠毛巾为例，这在当时是轰动机器人圈的重要研究，因为第一次有机器人可以完成柔性物体的处理，虽然效率很低，在100分钟之内只完成了5条毛巾的整理，但是在学术层面，却推动机器人向前走了一大步。 这款机器人中的软件框架就是ROS的原型，所以ROS因这款个人服务机器人而生，很快也从中独立出来，成为一款用于更多机器人的软件系统。 ROS怀揣“提高机器人软件复用率”的目标，促使社区快速发展和繁荣，时至今日，ROS已经广泛用于各种机器人的开发，无论是机械臂、移动机器人、水下机器人，还是人形机器人、复合机器人，统统都可以看到ROS的身影，ROS已经成为机器人领域的普遍标准。 ROS的特点 提高机器人软件复用率，这个目标简单来讲就是 不要重新造轮子 。 正如一家做汽车的公司，从零制造汽车并不是一个明智的做法，他们通常会采购A家的轮子、B家的引擎、C家的多媒体系统，最后把这些整合到一起做成汽车。同理，我们也可以将ROS社区中已有的各种软件集合到一起，在此之上去实现自己的创意，同时还可以将自己的成果分享给别人，这样大家都可以站在巨人的肩膀上，向前走的更远，一步一步，智能机器人才会有更多沉淀和更长远的进步。 围绕这个核心目标，ROS在自身的设计上也尽量做到了模块化，由 通信机制、开发工具、应用功能、生态系统 四大部分组成。同时ROS具备多项特点，这里的ROS是ROS1和ROS2的总称， 比如： 社区是全球化 的，那就可以集合全人类的智慧来推进机器人的智能化发展； 这些智慧的结晶都会以各种各样的 应用案例在社区中沉淀 下来； ROS本身也是完全开源的， 商业许可证非常宽松 ； 对商业应用功能友好，这就代表着公司可以直接使用ROS开发商业化的机器人产品， 缩短了产品的上市时间 ； ROS也可以 跨平台使用 ，Linux、Windows、嵌入式系统都可以跑； ROS2中也新增了很多 支持工业应用 的新特性和新技术，促使ROS在越来越多领域中被使用。 ROS的社区 社区是ROS快速发展的核心动力，什么是社区呢？其实就是ROS相关资源的整合方式，比如wiki说明、问答网站、应用源码、论坛讨论等都算是社区中的元素。 ROS全球社区有几个重要网站： answers.ros.org，这是一个ROS问答网站，大家可以在上边提出任何关于ROS的问题，全球很多开发者都很乐意回答我们的问题； wiki.ros.org，这是ROS的维基百科，记录了ROS教程和各种功能包的使用； discourse.ros.org，这是ROS论坛，关于ROS开发的新鲜事都可以在这里发表和查看，比如ROS的活动、新功能包的发布等等。 index.ros.org，是ROS各种资源的一个索引网站； packages.ros.org，是ROS功能包存储的数据库。 这几个网站的使用情况基本就可以代表ROS社区的活跃度了。 上图是近几年ROS社区页面浏览量的增长曲线，从总体趋势上来看，各项增长速度都非常快，wiki作为日常使用最为频繁的网站，使用度无疑是最高的，现在每个月有 150万左右 的访问量，answers和packages现在差不多，每个月有 80万 左右，其他两个不多，四项加起来每个月基本有 250万左右 的访问量，已经是一个活跃度非常棒的社区了。 从访问人数上来看，上边这张图更为清晰， wiki每个月有20到25万人使用 ， answers每个月有15万人以上使用 ，四项加起来每个月差不多有40多万的使用人数，这些用户绝大部分都是机器人开发者，可以看到ROS使用人数是越来越多了。 这张图是根据功能包下载次数统计得到的地域排名，基本上可以代表不同国家机器人研发的活跃程度，给大家作为一个参考。 总而言之，通过这些数据，我们可以看到的是ROS发展迅猛，正在助推机器人革命这一波大浪潮，大家每一个人在其中都大有可为。","text_tokens":["才","青年","红外","由","干","衣服","国家","结晶","不断","而生","映射","这套","频繁","视频","就","操作系统","是不是","怀揣","研发","，","绝大","驾驶","软件系统","控制器","隔天","？","识别","剪头发","pr2","重要","严峻","有望","供给","大步","猛进","障碍","扩大","概念","上个","陆续","么","迅猛","哪里","工序","一家","通过","之内","清晰","突飞","各种","ai","上市","无疑","找到","各","小时","2016","井喷","不仅","随着","案例","判断","问题","实验","专业人才","这是","台球","目标","今日","开发工具","肯定","带动","一个","部署","轰动","雷达","备货","1463","：","智能化","来","一系列","研究","基本功","绝大部分","课程","日常","总而言之","基本","维基百科","状","应该","用多大","同样","重新","后","这袋","可为","这款","使用","最高","维基","几十","里会","正在","半个","工厂","市场","呈","斯坦福大学","生态系统","250","25","一张","没有","中","答案","达到","缩短","合适","现状","几十年","包","超声","感知","系统","什么","也","完善","自动化","智慧","之一","转向","整合","可以","把","命令","风力","需求","太","高校","横跨","本身","劳动力","基本功能","商品","不是","最终","报道","而","电路","计算","拖地","两个","以上","地上","总体","自己","应用","业生","同时","斯坦福","效率","所以","尝试","商业化","向前","要求","买个","实时","维基百","一些","华为","程度","动力","组成","付款","跨平台","来到","闻报","操控","呢","自动","移动机器人","很多","很","整理","送到","知道","做到","搭载","数字","太远","亿元","5","领域","地来","毛巾","排名","成为","拉开序幕","450","如此","超车","统计","物体","成果","迅速","基于","引擎","说明","圈","无聊","根据","上图","分享","如果","广泛","商业","几年","熟悉","息息相关","线","跟车","此时","事情","乐意","索引","方式","几种","做","三个","得到","狗","柔性","大","第三个","大有可为","安全","律法","只是","同理","出现","差不多","得","执行","左右","万人","有没有","典型","革命","关注","资源","情景","大战","提出","快","杂物","举例","运营","而且","工具","代表","买","等等","工业","明智","站","如何","b","加","动机","得以","ros1","其实","资金","2","甚至","时至今日","驱动","平台","分配","仓储","了","总称","地域","1164","十几","之","轮子","统统","来看","机制","接触","扫地","完成","最为","这样","深知","给","那","比如","之外","网站",".","packages","手机","自身","发表","软件","多媒体","论坛","万","率","org","用户","会","激光雷达","打","保证","都","不多","与","目的地","万左右","技术","控制算法","向前走","记录","提高","。","收拾","法律法规","有力","立体","家庭","框架","完","大学","按照","15","；","学术","买米","四项","却","增长速度","容易","新增","极为","时代","科幻","不同","收货","起来","改变","同一","当中","发现","类型","一套","分拣","快递","2007","其中","地","分钟","人","送餐","不断完善","全新","公司","从中","强悍","但是","体验","新闻报道","吃","开发者","除此","繁荣","发状","丰富","光靠","智能","零","2025","检测","将","用到","出来","手上","入库","当然","此","情况","算法","因为","电机","一次","过程","实现","感器","更加","人工","工业生产","三维","厨房","通常","起","洗衣","下来","预测","车道","汽车","频率","传感","巨人","教器","用","wiki","到","和","浏览量","已经","模块","要","社区","摆放","肩膀","部件","核心","宠物","零部件","index","不","活跃","并","逐渐","层面","说干就干","包装","二个","个","木头","操作","有限","更会","潜移默化","还","水下","但","第二个","10","原型","预计","长远","特点","曲线","服务","一天","国内","苹果","方面","它","动作","餐厅","活动","线板","不过","构建","正如","answers","看到","突飞猛进","面对","必将","场景","为了","跑","windows","头发","地图","从","以及","家用","打标","最后","缺口","性能","词汇","初期","完全","宽松","生产","动态","潜移","清扫","经历","生活","出","突发","百科","发布","效果","80","下单","40","各项","环境","一个月","车辆","采购","上边","开始","超声波","变形金刚","标准","区域","多个","现在","活跃度","当今","开源","员","新闻","庞大","集合","模块化","更为","劳动","插","热门","视觉","针对","也许","机器人","控制","就是","高","浏览","对","电影","障碍物","人类","突然","全球","虽然","伺服电机","应用软件","后期","星球","高效","将要","开发","里面","100","买面","嵌入式","第三","personal","之前","驱动器","一大","主角","普遍","在生活中","超过","一切","简单","看似","默化","以","时间","聊天","爆发","开设","越来越","城市","增长","任何","新鲜事","减速","身影","家","除了","年前","不觉","做饭","借助","个人","月","参考","算是","为什么","科技","处理","这么","思考","日新月异","绝对","速度","臂","教程","是","米","多项","上","于","京东","除此之外","当天","指示","无论","变形","设备","系列","依然","无论是","多万","沉淀","大家","来讲","大量","一群","局部","放到","激光","里边","2000","数据","—","度","造","礼让","第二","移动","而言","ros","制造","发展","指示灯","用于","一步","相信","通信","下载","机械","独立","了如指掌","更","元素","访问","大部分","怎么样","由示","讨论","生态系","星球大战","上去","提到","近几年","第一","越来","第一次","法规","不到","生态","媒体","支持","家庭环境","行驶","因","c","围绕","正式","保障","推动","复用","robot","浪潮","一起","仿生","新月","某个","一种","对于","及时","想法","做法","查看","玩耍","序幕","页面","热点","时期","做出","棒","最佳","数据库","团队","他们","复杂","大部","全人类","机器","只要","大白","150","以叠","一系","你","并且","计算机","讲","2015","陪","福大","真实"," ","这个","所有人","款","主要","尽量","十年","车","源码","去","回答","东西","设计","被","你家","那刻","前夜","几个","促使","低","提供","别人","测试","自主","身边","先","之后","许可","目的","关于","各种各样","行业","这","人工智能","已有","不想","实验室","伺服","拉开","外观","多","年","不断丰富","不知不觉","功能","货架","各样","减速机","类似","脑海","张图","什么样","看看","上个月","a","“","20","一大步","discourse","逐年","相关","每","人才","状况","躲避","体系","比如说","嵌入","伴随","水量","声波","着","最","新鲜","当","不知","金刚","创意","帮助","叠","多媒体系统","专业","联合","推进","趋势","图中","分析","顺利","最近","时候","这一波","缺少","很快","路面","十几种","小","、","可能","不会","我们","的","仓库","周围","许可证","复合","既然","访问量","特性","只","卧室","有志","还是","释放","ros2","怎么","全球化","助推","信息","一款","某","有人","代","不要","据库","装配","想象","涉及","熨烫","周围环境","次数","等","分","agv","突发状况","给出","科幻电影","为例","每个","及时处理","法律","这里","友好","在","全人","部分","这些","快速","”","linux","载体","距离","存储","非常","至今","1000","进步","然后","条","问答","相机","作为","诞生","充足","四足","具备","人才需求","四大","人形","远","俗称","直接","乐趣","行人","交通","做成","其他","人数","真的","他","立体仓库","新","或者","为","产品","有","传感器","电气","基本上","所有","只能","需要","精致","实际","背后","当时","算机"],"title":"智能机器人发展与现状","title_tokens":["现状","与","发展","机器人","机器","智能"]},{"location":"hhp/1.1_%E6%99%BA%E8%83%BD%E6%9C%BA%E5%99%A8%E4%BA%BA%E5%8F%91%E5%B1%95%E4%B8%8E%E7%8E%B0%E7%8A%B6/#_1","text":"智能机器人正在改变着我们的生活，想象这样一种场景。 也许不知不觉的某一天，我们就会发现类似这样的机器人会真实出现在生活当中。 科技的发展日新月异，智能机器人也突飞猛进，伴随机器人发展而生的机器人操作系统，也是机器人重要的发展动力之一。","text_tokens":["不知","出现","突飞","一天","改变","系统","新月","当中","一种","发现","而生","动力","在","也","会","就","突飞猛进","也许","操作系统","场景","之一","不觉","不知不觉","发展","机器人","，","机器","我们","的","类似","科技","。","日新月异","真实","生活","重要"," ","操作","智能","是","猛进","正在","伴随","某","着","这样","想象"],"title":"智能机器人发展与现状","title_tokens":["现状","与","发展","机器人","机器","智能"]},{"location":"hhp/1.1_%E6%99%BA%E8%83%BD%E6%9C%BA%E5%99%A8%E4%BA%BA%E5%8F%91%E5%B1%95%E4%B8%8E%E7%8E%B0%E7%8A%B6/#_2","text":"提到智能机器人，大家脑海里会映射出什么样的情景呢？ 是不是会有很多科幻电影中变形金刚、大白机器人、星球大战等场景呢？ 智能机器人这个概念，只是一个科幻词汇么？当然不是的，其实在我们身边，已经有越来越多智能机器人出现，我们来看看他们都在哪里？","text_tokens":["科幻","只是","金刚","出现","变形金刚","大家","身边","等","什么","科幻电影","情景","映射","大战","越来越","在","呢","会","很多","一个","是不是","、","场景","多","都","他们","机器人","，","机器","已经","我们","来","的","脑海","电影","？","大白","词汇","什么样","其实","看看","星球","出"," ","这个","星球大战","不是","智能","提到","有","概念","越来","里会","么","当然","哪里","变形","中"],"title":"智能机器人举例","title_tokens":["举例","机器人","机器","智能"]},{"location":"hhp/1.1_%E6%99%BA%E8%83%BD%E6%9C%BA%E5%99%A8%E4%BA%BA%E5%8F%91%E5%B1%95%E4%B8%8E%E7%8E%B0%E7%8A%B6/#_3","text":"先来看一个大家最熟悉的一个类型——扫地机器人。现在的扫地机器人，除了可以完成扫地、拖地这样一些基本功能之外，还搭载了激光雷达、相机、红外等十几种传感器。 一个全新的扫地机器人虽然是第一次来到你家，但是它可能用到 5 分到 10 分钟时间，很快就可以通过它的传感器对你的家庭环境了如指掌，也就是把实际的家庭环境做成了一张地图，这样他就会知道哪里是卧室，哪里是餐厅，哪里是厨房，不同的区域用多大的风力，用多大的水量来去清扫最为合适，它都会智能化地来做判断。 除此之外，它还得知道怎么样去躲避各种障碍物，比如说家里面的宠物、地上摆放的插线板，各种各样的杂物等等。 所以看似非常小的一个扫地机器人，其实已经是一个很智能化的家用设备了，正在潜移默化地改变着我们的生活。","text_tokens":["红外","得","它","餐厅","杂物","线板","就","地图","，","机器","家用","等等","其实","你","潜移","清扫","生活"," ","了","十几","去","障碍","来看","你家","环境","哪里","通过","扫地","完成","最为","这样","比如","之外","各种","先","区域","现在","判断","各种各样","会","激光雷达","插","一个","都","雷达","功能","各样","机器人","智能化","就是","来","对","基本功","障碍物","。","基本","虽然","家庭","用多大","里面","躲避","比如说","正在","水量","一张","着","最","合适","看似","不同","默化","改变","时间","类型","也","很快","十几种","小","家","除了","、","地","分钟","可能","全新","可以","把","我们","的","风力","但是","除此","基本功能","是","智能","卧室","拖地","用到","怎么","除此之外","地上","设备","一次","感器","所以","大家","等","分","激光","厨房","一些","—","来到","很","传感","知道","搭载","到","5","非常","地来","已经","相机","摆放","了如指掌","宠物","怎么样","做成","他","熟悉","传感器","第一","第一次","潜移默化","还","几种","做","10","家庭环境","实际"],"title":"扫地机器人","title_tokens":["机器人","扫地","机器"]},{"location":"hhp/1.1_%E6%99%BA%E8%83%BD%E6%9C%BA%E5%99%A8%E4%BA%BA%E5%8F%91%E5%B1%95%E4%B8%8E%E7%8E%B0%E7%8A%B6/#_4","text":"第二个案例，虽然大部分人在生活中不会直接接触，但却和每一个人息息相关，那就是自动化仓储。 这是京东某个实际部署运营的一套自动化的仓库，在里面可以看到各种各样的机器人，比如工业机械臂、移动机器人等等，这套立体仓库当中大量的货架也是自动化的，这就是一个典型的机器人应用场景。 之前有一个关于京东的新闻报道，里边讲到，从我们下单那刻开始，到商品分拣出来放到快递员手上，只需要20分钟。比如我们要买个手机，下单付款，20分钟之后，这个手机已经从这么庞大的仓库中顺利找到，并且完成了包装、打标、分配等一系列工序。这样，我们在绝大部分城市，基本都可以体验到下单之后，当天或者隔天收货的体验，为什么它可以做到如此高效，就是因为背后这一套由机器人组成的自动化系统，借助大数据的分析，甚至可以做到在你下单之前，平台就知道你将要买什么东西。比如说你会按照一个月的频率买米买面，那平台就可以预测到上个月你买的米应该快吃完了，然后就会在距离你家最近的一个仓库里面备货。 当你下单之后，这袋米可能半个小时送到你手上了。","text_tokens":["由","典型","某个","它","这套","快","运营","看到","就","场景","从","大部","，","机器","绝大","买","等等","工业","打标","隔天","动机","一系","并且","你","讲","甚至","生活"," ","这个","平台","分配","仓储","了","下单","东西","上个","你家","那刻","一个月","工序","接触","开始","完成","这样","那","比如","各种","手机","找到","之后","小时","案例","关于","新闻","员","庞大","这是","各种各样","会","这","一个","部署","都","备货","货架","各样","机器人","就是","一系列","绝大部分","。","基本","上个月","虽然","立体","20","应该","完","高效","相关","按照","将要","这袋","每","里面","买面","买米","却","之前","比如说","半个","在生活中","中","当","收货","什么","系统","分析","顺利","当中","最近","一套","城市","也","分拣","快递","自动化","、","人","分钟","借助","可能","可以","不会","我们","的","为什么","仓库","体验","新闻报道","这么","吃","臂","商品","是","报道","只","米","京东","出来","手上","当天","应用","因为","系列","等","大量","买个","放到","里边","组成","数据","付款","闻报","在","预测","部分","自动","移动机器人","频率","送到","第二","移动","做到","知道","到","和","距离","已经","然后","机械","要","如此","直接","大部分","立体仓库","包装","二个","或者","息息相关","有","但","第二个","需要","实际","背后","大"],"title":"自动化仓储","title_tokens":["仓储","自动化","自动"]},{"location":"hhp/1.1_%E6%99%BA%E8%83%BD%E6%9C%BA%E5%99%A8%E4%BA%BA%E5%8F%91%E5%B1%95%E4%B8%8E%E7%8E%B0%E7%8A%B6/#_5","text":"第三个案例，那就是当今最为热门的技术之一——自动驾驶。 自动驾驶汽车也是典型的移动机器人系统，为了保证绝对安全的驾驶过程，汽车上装配了非常多的传感器，以及极为复杂的控制算法。 视频中我们看到的是华为自动驾驶系统在实际路面上测试的效果，自动驾驶汽车通过多个相机、雷达、超声波，实时构建周围环境的三维信息，不仅可以动态识别路面上的行人车辆、车道线、交通指示灯等，还可以安全完成超车、会车、跟车、转向等重要功能，同时对突发状况也可以及时处理，比如躲避突然出现的车辆、礼让行人等，最终自动行驶入库，把我们安全顺利的送到目的地。 虽然自动驾驶相关的技术和法律法规还在不断完善中，但是相信有一天我们每个人都可以体验自动驾驶的乐趣，而且这一天不会太远。","text_tokens":["出现","律法","一天","典型","不断","及时","视频","构建","看到","而且","为了","以及","复杂","，","驾驶","机器","动机","动态","识别","突发","重要"," ","了","效果","车","环境","车辆","通过","最为","完成","那","比如","测试","超声波","多个","不仅","当今","案例","目的","会","这","热门","保证","都","多","雷达","功能","目的地","机器人","技术","就是","控制","控制算法","对","。","法律法规","突然","虽然","相关","状况","第三","躲避","极为","声波","中","超声","系统","顺利","也","路面","完善","、","之一","转向","人","不断完善","可以","把","不会","我们","的","周围","但是","处理","体验","绝对","行驶","发状","是","最终","上","入库","指示","信息","算法","装配","过程","同时","感器","周围环境","等","三维","突发状况","实时","华为","每个","及时处理","—","法律","在","车道","汽车","自动","移动机器人","送到","礼让","移动","传感","太远","和","非常","指示灯","相信","相机","超车","乐趣","行人","交通","传感器","线","跟车","法规","有","还","三个","实际","第三个","安全"],"title":"自动驾驶","title_tokens":["驾驶","自动"]},{"location":"hhp/1.1_%E6%99%BA%E8%83%BD%E6%9C%BA%E5%99%A8%E4%BA%BA%E5%8F%91%E5%B1%95%E4%B8%8E%E7%8E%B0%E7%8A%B6/#_6","text":"机器人的发展横跨几十年，经历了三个重要时期。 2000年前，机器人主要应用于工业生产，俗称工业机器人，由示教器操控，帮助工厂释放劳动力，此时的机器人并没有太多智能而言，完全按照人类的命令执行动作，更加关注电气层面驱动器、伺服电机、减速机、控制器等设备，这是机器人的电气时代。 2000年后，计算机和视觉技术逐渐应用，机器人的类型不断丰富，出现了AGV、视觉检测等应用，此时的机器人传感器更加丰富，但是依然缺少自主思考的过程，智能化有限，只能感知局部环境，这是机器人的数字时代，不过这也是机器人大时代的前夜。 2015年之后，随着人工智能技术的快速发展，机器人成为了AI技术的最佳载体，家庭服务机器人、送餐机器人、四足仿生机器狗、自动驾驶汽车等应用呈井喷状爆发，智能机器人时代正式拉开序幕。 2015年之后，智能机器人市场迅速爆发，到2025年，国内人工智能市场有望达到1164亿元，而作为人工智能重要载体的机器人，市场更会达到1463亿元。 行业的快速发展，必将带动大量专业人才的需求，人才缺口也将逐年扩大，2025年，预计国内机器人行业的人才缺口将超过450万，人工智能方面的缺口更会达到1000万。 面对如此严峻的人才需求，国内各高校从2016年起，陆续开设机器人和人工智能专业，为人才的供给提供有力保障。 智能机器人的快速发展，必将对机器人开发提出更高的要求，软件层面最为热点的技术之一就是机器人操作系统，这也是我们课程的主角。","text_tokens":["出现","服务","执行","不断","仿生","国内","关注","方面","动作","提出","不过","热点","时期","操作系统","面对","必将","最佳","从","，","机器","驾驶","预计","控制器","工业","缺口","完全","生产","计算机","2015","经历","重要"," ","有望","驱动","严峻","主要","了","十年","供给","1164","扩大","陆续","环境","前夜","提供","最为","自主","ai","软件","之后","各","万","2016","井喷","随着","专业人才","这是","行业","劳动","这","人工智能","视觉","带动","伺服","拉开","多","年","不断丰富","1463","机器人","控制","技术","减速机","智能化","高","就是","对","课程","人类","。","伺服电机","有力","家庭","状","逐年","后","按照","开发","人才","几十","驱动器","市场","工厂","主角","呈","超过","没有","时代","达到","帮助","几十年","专业","感知","系统","爆发","开设","类型","缺少","也","减速","、","年前","送餐","保障","之一","我们","的","命令","但是","思考","需求","太","高校","横跨","劳动力","丰富","智能","是","2025","而","检测","计算","于","将","释放","应用","电机","设备","业生","依然","过程","更加","感器","人工","工业生产","等","agv","大量","要求","局部","2000","起","动力","操控","汽车","自动","快速","而言","传感","数字","教器","载体","亿元","到","发展","和","1000","作为","四足","成为","拉开序幕","450","如此","人才需求","更","俗称","迅速","由示","并","逐渐","层面","为","操作","有限","更会","此时","电气","传感器","只能","三个","狗","序幕","大","算机","正式"],"title":"智能机器人发展","title_tokens":["发展","机器人","机器","智能"]},{"location":"hhp/1.1_%E6%99%BA%E8%83%BD%E6%9C%BA%E5%99%A8%E4%BA%BA%E5%8F%91%E5%B1%95%E4%B8%8E%E7%8E%B0%E7%8A%B6/#_7","text":"对于越来越复杂的智能机器人系统，已经不是一个人或者一个团队可以独立完成的，如何高效开发机器人，是技术层面上非常重要的一个问题，针对这个问题，一群斯坦福大学的有志青年尝试给出一个答案，那就是机器人操作系统。","text_tokens":["那","斯坦福","青年","尝试","一群","系统","给出","问题","对于","越来越","针对","一个","操作系统","人","团队","复杂","机器人","，","机器","已经","可以","技术","非常","就是","的","如何","独立","。","层面","福大","高效","重要","大学","或者","开发","这个","操作","不是","智能","是","有志","上","越来","斯坦福大学","完成","答案"],"title":"机器人操作系统","title_tokens":["操作系统","系统","机器人","机器","操作"]},{"location":"hhp/1.1_%E6%99%BA%E8%83%BD%E6%9C%BA%E5%99%A8%E4%BA%BA%E5%8F%91%E5%B1%95%E4%B8%8E%E7%8E%B0%E7%8A%B6/#ros","text":"2007年，他们诞生了这样一个想法，我们有没有可能做一款个人服务机器人，帮助我们完成洗衣、做饭、收拾家等一切你不想做的事情，甚至还可以在你无聊的时候，陪你聊天玩耍，最后他们真的做出来了。 当时，他们深知做出这样一款机器人并不容易，机械、电路、软件等都要涉及，而且横跨很多个专业，光靠自己肯定做不到，此时他们诞生了这样一个想法：既然自己做不到，那为什么不联合所有人一起干呢？如果设计一套标准的机器人平台和其中的软件，大家都可以在这个平台上做应用开发，既然应用软件都基于同一平台，应用的分享也很容易实现，这就类似别人开发的苹果手机应用，只要你有苹果手机，同样也可以用。 说干就干，初期的机器人原型是用实验室可以找到的木头和一些零部件组成的，后期有了充足的资金，才得以实现图中这款外观精致、性能强悍的机器人——PR2，Personal Robot 2代。 在这几个图中，我们可以看到PR2机器人已经可以完成叠毛巾、熨烫衣服、打台球、剪头发等一系列复杂的应用功能，以叠毛巾为例，这在当时是轰动机器人圈的重要研究，因为第一次有机器人可以完成柔性物体的处理，虽然效率很低，在100分钟之内只完成了5条毛巾的整理，但是在学术层面，却推动机器人向前走了一大步。 这款机器人中的软件框架就是ROS的原型，所以ROS因这款个人服务机器人而生，很快也从中独立出来，成为一款用于更多机器人的软件系统。 ROS怀揣“提高机器人软件复用率”的目标，促使社区快速发展和繁荣，时至今日，ROS已经广泛用于各种机器人的开发，无论是机械臂、移动机器人、水下机器人，还是人形机器人、复合机器人，统统都可以看到ROS的身影，ROS已经成为机器人领域的普遍标准。","text_tokens":["推动","才","复用","robot","服务","干","衣服","有没有","一起","苹果","而生","想法","玩耍","就","看到","做出","而且","怀揣","头发","他们","复杂","，","机器","软件系统","只要","最后","性能","？","动机","初期","得以","以叠","一系","你","资金","陪","2","甚至","剪头发","pr2","时至今日","重要"," ","因","所有人","平台","这个","款","了","大步","设计","统统","几个","促使","低","之内","完成","这样","深知","别人","那","各种","标准","手机","软件","找到","率","台球","目标","今日","实验","这","肯定","打","不想","实验室","一个","外观","都","年","轰动","多","功能","：","机器人","就是","向前走","一系列","研究","类似","提高","收拾","。","虽然","“","应用软件","框架","一大步","后期","同样","开发","这款","100","学术","personal","却","容易","一大","普遍","没有","中","一切","帮助","叠","专业","联合","图中","什么","系统","聊天","同一","时候","一套","也","很快","2007","其中","身影","家","、","分钟","做饭","可能","个人","可以","我们","的","从中","为什么","强悍","但是","处理","复合","繁荣","既然","横跨","臂","光靠","是","只","电路","上","还是","出来","自己","有人","一款","应用","代","因为","无论","系列","一次","无论是","实现","涉及","熨烫","效率","大家","所以","等","向前","为例","一些","组成","洗衣","—","在","整理","呢","移动机器人","快速","很多","很","”","移动","用","ros","和","5","发展","至今","已经","用于","条","领域","诞生","充足","毛巾","机械","独立","要","成为","社区","部件","物体","更","人形","零部件","基于","不","并","说干就干","圈","无聊","层面","真的","分享","个","木头","如果","广泛","此时","有","事情","第一","不到","还","第一次","水下","所有","做","原型","精致","柔性","当时"],"title":"ROS的诞生","title_tokens":["诞生","ros","的"]},{"location":"hhp/1.1_%E6%99%BA%E8%83%BD%E6%9C%BA%E5%99%A8%E4%BA%BA%E5%8F%91%E5%B1%95%E4%B8%8E%E7%8E%B0%E7%8A%B6/#ros_1","text":"提高机器人软件复用率，这个目标简单来讲就是 不要重新造轮子 。 正如一家做汽车的公司，从零制造汽车并不是一个明智的做法，他们通常会采购A家的轮子、B家的引擎、C家的多媒体系统，最后把这些整合到一起做成汽车。同理，我们也可以将ROS社区中已有的各种软件集合到一起，在此之上去实现自己的创意，同时还可以将自己的成果分享给别人，这样大家都可以站在巨人的肩膀上，向前走的更远，一步一步，智能机器人才会有更多沉淀和更长远的进步。 围绕这个核心目标，ROS在自身的设计上也尽量做到了模块化，由 通信机制、开发工具、应用功能、生态系统 四大部分组成。同时ROS具备多项特点，这里的ROS是ROS1和ROS2的总称， 比如： 社区是全球化 的，那就可以集合全人类的智慧来推进机器人的智能化发展； 这些智慧的结晶都会以各种各样的 应用案例在社区中沉淀 下来； ROS本身也是完全开源的， 商业许可证非常宽松 ； 对商业应用功能友好，这就代表着公司可以直接使用ROS开发商业化的机器人产品， 缩短了产品的上市时间 ； ROS也可以 跨平台使用 ，Linux、Windows、嵌入式系统都可以跑； ROS2中也新增了很多 支持工业应用 的新特性和新技术，促使ROS在越来越多领域中被使用。","text_tokens":["复用","同理","由","结晶","一起","做法","正如","就","工具","跑","代表","windows","从","他们","全人类","，","机器","最后","工业","明智","站","b","ros1","完全","宽松"," ","这个","围绕","平台","尽量","了","总称","之","轮子","设计","被","机制","一家","采购","促使","别人","这样","给","那","比如","各种","上市","自身","软件","多媒体","率","许可","目标","案例","开源","集合","模块化","各种各样","会","已有","开发工具","这","一个","都","多","功能","：","各样","机器人","智能化","就是","技术","来","向前走","对","提高","人类","。","a","全球","重新","开发","人才","；","使用","嵌入式","体系","嵌入","生态系统","新增","着","中","缩短","创意","简单","推进","多媒体系统","以","系统","时间","越来越","也","家","、","智慧","把","公司","可以","我们","的","许可证","本身","特性","不是","智能","零","多项","是","上","将","此","ros2","全球化","自己","不要","应用","同时","实现","沉淀","大家","商业化","来讲","向前","通常","特点","组成","这里","跨平台","下来","友好","在","全人","汽车","这些","部分","造","linux","很多","巨人","做到","ros","制造","到","和","发展","非常","领域","一步","进步","通信","模块","具备","社区","四大","肩膀","更","成果","远","核心","直接","并","引擎","做成","生态系","新","分享","上去","商业","产品","有","越来","生态","还","媒体","支持","做","长远","整合","c"],"title":"ROS的特点","title_tokens":["ros","的","特点"]},{"location":"hhp/1.1_%E6%99%BA%E8%83%BD%E6%9C%BA%E5%99%A8%E4%BA%BA%E5%8F%91%E5%B1%95%E4%B8%8E%E7%8E%B0%E7%8A%B6/#ros_2","text":"社区是ROS快速发展的核心动力，什么是社区呢？其实就是ROS相关资源的整合方式，比如wiki说明、问答网站、应用源码、论坛讨论等都算是社区中的元素。 ROS全球社区有几个重要网站： answers.ros.org，这是一个ROS问答网站，大家可以在上边提出任何关于ROS的问题，全球很多开发者都很乐意回答我们的问题； wiki.ros.org，这是ROS的维基百科，记录了ROS教程和各种功能包的使用； discourse.ros.org，这是ROS论坛，关于ROS开发的新鲜事都可以在这里发表和查看，比如ROS的活动、新功能包的发布等等。 index.ros.org，是ROS各种资源的一个索引网站； packages.ros.org，是ROS功能包存储的数据库。 这几个网站的使用情况基本就可以代表ROS社区的活跃度了。 上图是近几年ROS社区页面浏览量的增长曲线，从总体趋势上来看，各项增长速度都非常快，wiki作为日常使用最为频繁的网站，使用度无疑是最高的，现在每个月有 150万左右 的访问量，answers和packages现在差不多，每个月有 80万 左右，其他两个不多，四项加起来每个月基本有 250万左右 的访问量，已经是一个活跃度非常棒的社区了。 从访问人数上来看，上边这张图更为清晰， wiki每个月有20到25万人使用 ， answers每个月有15万人以上使用 ，四项加起来每个月差不多有40多万的使用人数，这些用户绝大部分都是机器人开发者，可以看到ROS使用人数是越来越多了。 这张图是根据功能包下载次数统计得到的地域排名，基本上可以代表不同国家机器人研发的活跃程度，给大家作为一个参考。 总而言之，通过这些数据，我们可以看到的是ROS发展迅猛，正在助推机器人革命这一波大浪潮，大家每一个人在其中都大有可为。","text_tokens":["差不多","万人","左右","国家","浪潮","革命","页面","提出","频繁","查看","活动","快","answers","就","看到","棒","代表","数据库","从","研发","大部","，","绝大","机器","等等","加","？","150","其实","重要"," ","百科","发布","源码","了","地域","回答","80","40","来看","各项","迅猛","几个","上边","通过","最为","网站",".","清晰","给","比如","packages","各种","无疑","发表","论坛","万","活跃度","现在","问题","关于","org","更为","这是","用户","这","一个","都","多","不多","功能","：","万左右","机器人","就是","浏览","记录","日常","张图","绝大部分","总而言之","。","基本","全球","维基百科","20","discourse","相关","可为","开发","每","15","；","使用","最高","维基","四项","增长速度","正在","大有可为","250","25","中","新鲜","趋势","不同","包","起来","什么","这一波","越来越","增长","任何","新鲜事","其中","、","人","可以","我们","的","月","参考","算是","开发者","速度","访问量","教程","是","上","两个","以上","情况","总体","助推","应用","多万","据库","大家","次数","等","维基百","每个","程度","动力","这里","数据","度","资源","在","呢","这些","快速","很多","很","部分","而言","ros","wiki","存储","发展","和","浏览量","非常","已经","问答","到","作为","下载","排名","社区","统计","核心","元素","index","访问","不","活跃","讨论","说明","其他","大部分","人数","根据","新","上图","近几年","几年","有","越来","索引","乐意","基本上","方式","得到","大","整合","曲线"],"title":"ROS的社区","title_tokens":["社区","ros","的"]},{"location":"hhp/1.2_TogetherROS%E7%B3%BB%E7%BB%9F%E4%BB%8B%E7%BB%8D/","text":"智能机器人开发平台介绍 机器人是一个非常复杂的系统，硬件部分包括：各种各样感知环境信息的传感器、作为大脑进行计算的主控平台、执行动作的电机等等。软件层面包括：感知算法，规控算法，数据驱动的程式，操作系统等。 以操作系统为例，应用最为广泛的ROS系统在不断迭代，不过在智能时代洪流的冲击下，还是涌现出一些问题。 ROS的一些问题 ROS逐渐成为标准，大量机器人应用被贡献到社区，虽然提高了代码的通用性，但却难以发挥硬件的完整性能； 大量应用聚焦在机器人运动控制与定位导航等基础功能，智能化的应用较少； 在软件资源格外丰富的社区中，还缺少系统化的内容，帮助用户快速实现相关资源的复用。 很多开发者都在魔改ROS，去适配自己的机器人，所以机器人的研发成本非常高。从机械选型、系统定制、算法开发到数据闭环，每个过程都要付出高昂的成本，在这么高昂的成本下，做机器人是非常困难的一件事情。 在算法层面，机器人算法仍处于早期阶段，很多感知算法还停留在理论阶段，无法服务与实际场景，机器学习发展迅速，不过对于很多开发者来讲，数据的采集、标注、训练都是一个庞大的工作量，部署运行不仅十分困难，还要消耗大量的算力成本。 智能机器人涉及的领域和方法较多，目前整体的学习成本偏高，想要实现智能化应用的难度就更高，问题的出现，也带来了机遇与挑战。 地平线机器人开发平台 2022年6月，地平线机器人正式推出全新一代机器人开发平台，在软件、算法、工具层面给行业带来更多帮助。这套机器人开发平台的目的是打造软硬协同、极致优化、丰富易用的机器人开发组件与生态，由图中这几个部分组成，我们一一来看下。 平台的底层主要依托于地平线AIOT边缘AI芯片——旭日3和旭日5，内部集成了地平线最先进的伯努利2.0架构的AI 引擎，可提供 5TOPS 以上的等效算力。如此强大的算力支持，保证了智能机器人开发的基础条件。 芯片是基础建设，在此之上更重要的是一系列软件设施，正如我们电脑上的windows和linux，一套优质的操作系统，是上层应用软件开发的必要条件，TogetherROS在ROS系统的基础上，进行了大量的改良和优化，可以为开发者提供高效实用的系统环境。 在此之上，平台还会提供大量的机器人参考算法和应用功能示例，比如常用的建图、定位、导航，还有智能机器人中至关重要的智能化功能，比如一些基础算法，图像分类、图像分割、目标检测等，还有应用功能，人脸检测、人体跟踪、骨骼点检测、手势识别、语音处理等等，提供基于大量数据训练的模型，借助底层AI引擎的支持，可以快速、稳定的实现各种各样的智能应用。 同时平台还会配套一系列加速机器人开发的工具链，比如代码编写工具、系统调试工具、数据标注和训练工具等。 古月居和地平线也会共同打造机器人开发者社区，持续分享技术内容，沉淀更多开发者的智慧，更多机器人产业中的合作伙伴也会陆续加入，共同打造最为丰富的机器人开发者套件，建设智能机器人开发的生态圈。 在这个机器人开发平台之中，最为重要的就是TogetherROS系统了，起到了承上启下、连接各项功能的作用，我们将通过一系列课程为大家深入浅出的介绍。 TogetherROS的特点 在ROS系统庞大社区资源的基础上，结合智能机器人的发展和产业需求，TogetherROS应运而生。 TogetherROS有三个核心特点： 开源兼容，秉承开源精神的力量 TogetherROS和ROS系统一样，也是一套完全开源的系统，所有开发者都可以继续二次开发，接口方面和ROS2完全兼容，ROS2原有的功能也都可以继续复用，已有的机器人代码可以十分便利的迁移过来。 极致性能优化 相比ROS的通用化，TogetherROS更多考虑的是如何充分挖掘底层硬件的性能，比如提高数据传输的效率、增强人工智能处理的能力，在后续的使用案例中，大家可以充分感受到这一点。 丰富易用的软硬件组件 比如各种各样的传感器和开发套件，再比如算法模块、感知应用、机器人功能，还有提高开发效率的各种编程、部署工具。 TogetherROS系统框架 具体展开来看，TogetherROS的系统框架如图所示，其中深蓝色部分为地平线优化、新增的模块，其他是目前复用ROS2中的模块： 在系统通信的中间件部分，保留了ROS2中原本针对不同DDS的通信框架，与ROS2 foxy版本的接口完全兼容，方便复用ROS丰富工具包进行原型验证，在此之上增加了“zero-copy” 零拷贝 的通信机制，降低大数据传输时延和系统资源消耗。 在组件功能部分，TogetherROS提供“hobot CV” 视觉加速库 ，软硬件协同，可以提升CV算子性能、降低系统资源消耗；针对AI模型的推理，封装了“hobot_dnn” 功能包，可以调用底层芯片的AI引擎，简化板端AI开发与部署，释放BPU的算力。可以支持丰富的机器人传感器型号，比如相机、雷达、IMU、GPS等，节省驱动开发的时间，可以聚焦在机器人应用开发上。 除此之外，TogetherROS还会提供丰富的 软件调试和性能调优工具 ，方便用户定位问题和优化系统性能，在具体的行业应用中，还支持最小化和模块化的剪裁，利于部署在资源受限的嵌入式产品中。 总之，TogetherROS出于ROS，又不止于ROS，ROS原有的功能依然继承，重点是借助硬件能力，充分优化系统的性能，提高机器人开发的效率。","text_tokens":["基础","不断","这套","后续","就","操作系统","停留","研发","继承","非常复杂","，","库","识别","早期","系统资源","重要","拷贝","陆续","机遇","通过","出于","打造","各种","ai","感受","洪流","较","2.0","不仅","问题","必要条件","目标","案例","改","一个","部署","工具包","雷达","：","提升","智能化","之上","一系列","课程","整体","通用性","简化","增强","使用","中","兼容","包","之中","感知","系统","内部","也","推理","还会","智慧","软硬件","可以","伯努利","增加","起到","一一","便利","精神","需求","介绍","中间","版本","计算","以上","降低","原本","算子","二次","自己","应用","同时","旭日","困难","迭代","效率","所以","一些","组成","资源","偏高","模型","很多","依托","领域","优化","5","5tops","方便","成为","如此","迅速","基于","选型","引擎","分享","规控","广泛","系统化","电脑","继续","少","事情","冲击","上层","做","三个","大","如图所示","出现","执行","架构","内容","十分困难","高昂","工具","伙伴","等等","如何","利于","稳定","聚焦","推出","驱动","总之","平台","定位","型号","了","相比","代码","挖掘","来看","据传","必要","机制","最为","强大","给","比如","秉承","之外","最小","软件","用户","会","包括","保证","bpu","都","深蓝色","与","技术","深入浅出","产业","组件","提高","。","剪裁","训练","极致","再","框架","充分","无法","套件","；","还有","dnn","加速","却","新增","时代","学习","边缘","不同","带来","方法","又","加入","一套","配套","其中","力量","古月","全新","条件","格外","先进","十分","开发者","能力","板端","除此","丰富","集成","可","智能","零","检测","挑战","节省","将","此","承上启下","保留","算法","电机","hobot","过程","实现","感器","人工","_","下","传感","定位问题","建图","作用","跟踪","到","和","模块","社区","要","分类","核心","魔","逐渐","3","层面","社区资源","foxy","操作","通用化","一点","还","但","调优","原型","适配","特点","常用","手势","主控","服务","处于","易用","方面","动作","算力","不过","正如","生态圈","进行","涌现出","场景","windows","从","由图","最小化","性能","结合","成本","完全","标注","zero","编程","应运而生","具体","各项","环境","封装","标准","难以","开源","庞大","模块化","蓝色","视觉","针对","gps","机器人","控制","就是","高","虽然","应用软件","一样","链","高效","开发","嵌入式","受限","软件资源","数据传输","优质","6","建设","togetherros","接口","以","时间","二次开发","阶段","定制","借助","还要","月","参考","处理","等效","这么","时延","人脸","编写","持续","中间件","是","原有","上","于","完整","除此之外","不止","实用","系列","硬件","依然","沉淀","大家","涌现","来讲","大量","数据","—","应运","共同","验证","ros","发展","通信","现出","理论","机械","更","分割","aiot","生态","支持","运行","cv","贡献","深入","正式","复用","发挥","对于","工作量","图像","地平线","复杂","难度","机器","工作","一系","展开","重点"," ","dds","这个","主要","去","付出","-","被","仍","闭环","迁移","几个","过来","一件","提供","示例","调试","目的","目前","各种各样","行业","这","已有","人工智能","copy","多","年","地平","采集","功能","大脑","各样","合作伙伴","协同","“","程式","运动","相关","点","所示","芯片","嵌入","人体","最","帮助","至关重要","缺少","、","传输","我们","的","底层","考虑","2022","导航","设施","还是","调用","想要","释放","ros2","信息","软硬","定位导航","通用","涉及","合作","等","为例","每个","在","部分","至关","快速","linux","”","深蓝","非常","骨骼","相机","作为","消耗","连接","其他","为","产品","传感器","一代","有","imu","改良","居","语音","所有","实际"],"title":"智能机器人开发平台介绍","title_tokens":["介绍","机器人","机器","开发","平台","智能"]},{"location":"hhp/1.2_TogetherROS%E7%B3%BB%E7%BB%9F%E4%BB%8B%E7%BB%8D/#_1","text":"机器人是一个非常复杂的系统，硬件部分包括：各种各样感知环境信息的传感器、作为大脑进行计算的主控平台、执行动作的电机等等。软件层面包括：感知算法，规控算法，数据驱动的程式，操作系统等。 以操作系统为例，应用最为广泛的ROS系统在不断迭代，不过在智能时代洪流的冲击下，还是涌现出一些问题。","text_tokens":["迭代","感器","主控","各种","涌现","执行","等","软件","以","感知","系统","不断","为例","洪流","一些","动作","数据","问题","各种各样","在","部分","不过","包括","下","一个","传感","、","进行","操作系统","ros","涌现出","算法","：","非常","机器人","复杂","机器","非常复杂","，","各样","大脑","作为","的","等等","现出","。","层面","程式"," ","驱动","平台","操作","是","规控","广泛","智能","计算","传感器","还是","冲击","环境","信息","应用","电机","最为","时代","硬件"],"title":"智能机器人开发平台介绍","title_tokens":["介绍","机器人","机器","开发","平台","智能"]},{"location":"hhp/1.2_TogetherROS%E7%B3%BB%E7%BB%9F%E4%BB%8B%E7%BB%8D/#ros","text":"ROS逐渐成为标准，大量机器人应用被贡献到社区，虽然提高了代码的通用性，但却难以发挥硬件的完整性能； 大量应用聚焦在机器人运动控制与定位导航等基础功能，智能化的应用较少； 在软件资源格外丰富的社区中，还缺少系统化的内容，帮助用户快速实现相关资源的复用。 很多开发者都在魔改ROS，去适配自己的机器人，所以机器人的研发成本非常高。从机械选型、系统定制、算法开发到数据闭环，每个过程都要付出高昂的成本，在这么高昂的成本下，做机器人是非常困难的一件事情。 在算法层面，机器人算法仍处于早期阶段，很多感知算法还停留在理论阶段，无法服务与实际场景，机器学习发展迅速，不过对于很多开发者来讲，数据的采集、标注、训练都是一个庞大的工作量，部署运行不仅十分困难，还要消耗大量的算力成本。 智能机器人涉及的领域和方法较多，目前整体的学习成本偏高，想要实现智能化应用的难度就更高，问题的出现，也带来了机遇与挑战。","text_tokens":["复用","基础","出现","服务","处于","内容","十分困难","发挥","对于","算力","不过","高昂","工作量","就","场景","停留","从","研发","难度","，","机器","工作","性能","成本","标注","早期","聚焦"," ","定位","了","去","代码","付出","被","仍","闭环","一件","机遇","标准","难以","软件","较","不仅","问题","目前","改","庞大","用户","一个","部署","都","多","与","采集","功能","机器人","控制","智能化","高","提高","。","整体","训练","通用性","虽然","运动","相关","无法","开发","；","却","软件资源","中","学习","帮助","感知","系统","方法","带来","缺少","也","、","阶段","定制","格外","还要","的","十分","这么","开发者","导航","丰富","智能","是","挑战","想要","完整","自己","算法","应用","定位导航","硬件","实现","过程","困难","通用","涉及","所以","等","来讲","大量","每个","数据","资源","在","偏高","快速","很多","下","ros","到","发展","领域","非常","和","理论","机械","成为","社区","要","消耗","更","迅速","魔","选型","逐渐","层面","系统化","少","事情","还","但","做","运行","实际","贡献","适配"],"title":"ROS的一些问题","title_tokens":["ros","的","一些","问题"]},{"location":"hhp/1.2_TogetherROS%E7%B3%BB%E7%BB%9F%E4%BB%8B%E7%BB%8D/#_2","text":"2022年6月，地平线机器人正式推出全新一代机器人开发平台，在软件、算法、工具层面给行业带来更多帮助。这套机器人开发平台的目的是打造软硬协同、极致优化、丰富易用的机器人开发组件与生态，由图中这几个部分组成，我们一一来看下。 平台的底层主要依托于地平线AIOT边缘AI芯片——旭日3和旭日5，内部集成了地平线最先进的伯努利2.0架构的AI 引擎，可提供 5TOPS 以上的等效算力。如此强大的算力支持，保证了智能机器人开发的基础条件。 芯片是基础建设，在此之上更重要的是一系列软件设施，正如我们电脑上的windows和linux，一套优质的操作系统，是上层应用软件开发的必要条件，TogetherROS在ROS系统的基础上，进行了大量的改良和优化，可以为开发者提供高效实用的系统环境。 在此之上，平台还会提供大量的机器人参考算法和应用功能示例，比如常用的建图、定位、导航，还有智能机器人中至关重要的智能化功能，比如一些基础算法，图像分类、图像分割、目标检测等，还有应用功能，人脸检测、人体跟踪、骨骼点检测、手势识别、语音处理等等，提供基于大量数据训练的模型，借助底层AI引擎的支持，可以快速、稳定的实现各种各样的智能应用。 同时平台还会配套一系列加速机器人开发的工具链，比如代码编写工具、系统调试工具、数据标注和训练工具等。 古月居和地平线也会共同打造机器人开发者社区，持续分享技术内容，沉淀更多开发者的智慧，更多机器人产业中的合作伙伴也会陆续加入，共同打造最为丰富的机器人开发者套件，建设智能机器人开发的生态圈。 在这个机器人开发平台之中，最为重要的就是TogetherROS系统了，起到了承上启下、连接各项功能的作用，我们将通过一系列课程为大家深入浅出的介绍。","text_tokens":["手势","基础","架构","易用","内容","这套","常用","算力","正如","图像","地平线","操作系统","工具","进行","生态圈","伙伴","windows","由图","，","机器","等等","稳定","标注","一系","识别","重要","推出"," ","这个","平台","定位","主要","了","代码","陆续","来看","各项","必要","环境","几个","提供","通过","强大","最为","给","打造","比如","示例","各种","ai","软件","2.0","调试","目的","必要条件","目标","各种各样","行业","会","这","保证","年","多","地平","与","功能","各样","机器人","智能化","之上","技术","产业","合作伙伴","就是","组件","一系列","深入浅出","课程","。","协同","训练","极致","应用软件","链","高效","开发","套件","点","还有","加速","芯片","人体","中","最","优质","6","边缘","建设","帮助","togetherros","至关重要","之中","带来","系统","内部","加入","一套","配套","也","、","还会","智慧","古月","借助","全新","可以","条件","我们","先进","伯努利","的","一一","月","参考","底层","起到","处理","等效","开发者","2022","人脸","导航","介绍","编写","持续","丰富","设施","集成","可","是","智能","检测","上","以上","于","将","此","承上启下","算法","应用","系列","旭日","软硬","实用","实现","同时","沉淀","合作","大家","等","大量","一些","组成","数据","—","在","部分","至关","linux","依托","模型","下","快速","共同","ros","建图","作用","跟踪","和","优化","5","5tops","骨骼","社区","如此","分类","连接","更","基于","3","引擎","层面","分享","为","分割","操作","aiot","电脑","一代","生态","改良","上层","语音","居","支持","深入","正式"],"title":"地平线机器人开发平台","title_tokens":["地平线","地平","机器人","机器","开发","平台"]},{"location":"hhp/1.2_TogetherROS%E7%B3%BB%E7%BB%9F%E4%BB%8B%E7%BB%8D/#togetherros","text":"在ROS系统庞大社区资源的基础上，结合智能机器人的发展和产业需求，TogetherROS应运而生。 TogetherROS有三个核心特点： 开源兼容，秉承开源精神的力量 TogetherROS和ROS系统一样，也是一套完全开源的系统，所有开发者都可以继续二次开发，接口方面和ROS2完全兼容，ROS2原有的功能也都可以继续复用，已有的机器人代码可以十分便利的迁移过来。 极致性能优化 相比ROS的通用化，TogetherROS更多考虑的是如何充分挖掘底层硬件的性能，比如提高数据传输的效率、增强人工智能处理的能力，在后续的使用案例中，大家可以充分感受到这一点。 丰富易用的软硬件组件 比如各种各样的传感器和开发套件，再比如算法模块、感知应用、机器人功能，还有提高开发效率的各种编程、部署工具。","text_tokens":["复用","基础","易用","方面","后续","工具","，","机器","如何","性能","结合","完全"," ","编程","相比","代码","应运而生","挖掘","据传","迁移","过来","秉承","比如","各种","感受","开源","案例","庞大","各种各样","已有","人工智能","这","部署","都","多","功能","：","各样","机器人","产业","组件","提高","。","极致","再","一样","充分","开发","套件","增强","使用","还有","数据传输","中","togetherros","兼容","接口","感知","系统","一套","也","、","力量","二次开发","软硬件","可以","传输","的","底层","十分","考虑","处理","便利","精神","开发者","能力","需求","丰富","智能","是","原有","上","ros2","二次","算法","应用","软硬","硬件","通用","效率","感器","人工","大家","数据","资源","在","应运","传感","ros","到","发展","和","优化","模块","社区","核心","更","社区资源","通用化","有","继续","一点","传感器","所有","三个","特点"],"title":"TogetherROS的特点","title_tokens":["的","togetherros","特点"]},{"location":"hhp/1.2_TogetherROS%E7%B3%BB%E7%BB%9F%E4%BB%8B%E7%BB%8D/#togetherros_1","text":"具体展开来看，TogetherROS的系统框架如图所示，其中深蓝色部分为地平线优化、新增的模块，其他是目前复用ROS2中的模块： 在系统通信的中间件部分，保留了ROS2中原本针对不同DDS的通信框架，与ROS2 foxy版本的接口完全兼容，方便复用ROS丰富工具包进行原型验证，在此之上增加了“zero-copy” 零拷贝 的通信机制，降低大数据传输时延和系统资源消耗。 在组件功能部分，TogetherROS提供“hobot CV” 视觉加速库 ，软硬件协同，可以提升CV算子性能、降低系统资源消耗；针对AI模型的推理，封装了“hobot_dnn” 功能包，可以调用底层芯片的AI引擎，简化板端AI开发与部署，释放BPU的算力。可以支持丰富的机器人传感器型号，比如相机、雷达、IMU、GPS等，节省驱动开发的时间，可以聚焦在机器人应用开发上。 除此之外，TogetherROS还会提供丰富的 软件调试和性能调优工具 ，方便用户定位问题和优化系统性能，在具体的行业应用中，还支持最小化和模块化的剪裁，利于部署在资源受限的嵌入式产品中。 总之，TogetherROS出于ROS，又不止于ROS，ROS原有的功能依然继承，重点是借助硬件能力，充分优化系统的性能，提高机器人开发的效率。","text_tokens":["复用","算力","地平线","工具","进行","继承","，","机器","最小化","性能","利于","库","完全","zero","系统资源","聚焦","展开","重点"," ","dds","驱动","总之","拷贝","定位","型号","了","具体","-","来看","据传","机制","提供","出于","比如","封装","之外","ai","最小","软件","调试","问题","目前","用户","模块化","行业","蓝色","copy","视觉","针对","bpu","部署","gps","工具包","雷达","深蓝色","地平","与","功能","：","提升","机器人","之上","组件","提高","。","剪裁","协同","“","框架","充分","简化","开发","；","dnn","嵌入式","加速","受限","所示","芯片","嵌入","新增","数据传输","中","togetherros","兼容","不同","接口","包","系统","时间","又","推理","其中","、","还会","借助","软硬件","可以","传输","增加","的","底层","时延","能力","除此","板端","中间","版本","中间件","丰富","是","零","节省","原有","上","于","调用","降低","ros2","此","原本","释放","算子","除此之外","保留","应用","不止","hobot","软硬","硬件","依然","感器","效率","等","数据","资源","在","部分","_","模型","”","传感","验证","定位问题","ros","深蓝","和","优化","通信","模块","相机","方便","消耗","引擎","其他","foxy","为","产品","传感器","imu","还","调优","支持","原型","cv","大","如图所示"],"title":"TogetherROS系统框架","title_tokens":["框架","togetherros","系统"]},{"location":"hhp/1.3_TogetherROS%E4%B8%8EROS%E5%AF%B9%E6%AF%94/","text":"TogetherROS与ROS性能对比 ROS2 vs ROS1 先来看下两个大版本ROS的系统架构。 在这张图中，左侧是ROS1，右侧是ROS2，两者最明显的变化，就是Master。 在ROS1中，应用层里Master这个节点管理器的角色至关重要，所有节点都得听它指挥，类似是一个公司的CEO，有且只有一个，如果这个CEO突然消失，公司肯定会成一团乱麻。ROS2把这个最不稳定的角色请走了，节点可以通过另外一套discovery——自发现机制，找到彼此，从而建立稳定的通信连接。 中间层是ROS封装好的标准通信接口，我们写程序的时候，会频繁和这些通信接口打交道，比如发布一个图像的数据，接收一个雷达的信息，客户端库会再调用底层复杂的驱动和通信协议，让我们的开发变得更加简单明了。 在ROS1中，ROS通信依赖底层的TCP和UDP协议，而在ROS2中，通信协议更换成了更加复杂但也更加完善的DDS系统。 如果是在进程内需要进行大量数据的通信，ROS1和ROS2都提供了基于共享内存的通信方法，只不过名字不太一样而已。 最下边是系统层，也就是可以将ROS安装在哪些操作系统上，ROS1主要安装在Linux上，ROS2的可选项就很多了，Linux、windows、MacOS、RTOS都可以。 ROS2系统架构 ROS2相比ROS1最大的变化，除了省略了Master之外，应该就是通信系统的变化了。ROS1中基于TCP/UDP的通信系统，频繁诟病于延迟、丢数据、无法加密等问题，ROS2中的DDS在通信层面的功能就丰富多了。 DDS其实是物联网中广泛应用的一种通信协议，类似于我们常听说的5G通信一样，DDS是一个国际标准，能够实现该标准的软件系统并不是唯一的，所以我们可以选择多个厂家提供的DDS系统，比如这里的OpenSplice、FastRTPS，还有更多厂家提供的，每一家的性能不同，适用的场景也不同。 不过这就带来一个问题，每个DDS厂家的软件接口肯定是不一样的，如果我们按照某一家的接口写完了程序，想要切换其他厂家的DDS，不是要重新写代码么？这当然不符合ROS提高软件复用率的目标。 为了解决这个问题，ROS2设计了一个ROS Middleware，简称RMW，也就是制定一个标准的接口，比如如何发数据，如何收数据，数据的各种属性如何配置，都定义好了，如果厂家想要接入ROS社区，就得按照这个标准写一个适配的接口，把自家的DDS给移植过来，这样就把问题交给了最熟悉自家DDS的厂商。对于我们这些用户来讲，某一个DDS用的不爽，只要安装另一个，然后做一个简单的配置，程序一行的都不用改，轻松更换底层的通信系统。 举一个例子，比如我们在产品开发时，可以先用开源版本的DDS满足基本需求，部署交付的产品时，再更换为商业版本更稳定的DDS，这样可以减少开发成本。 TogetherROS vs ROS2 TogetherROS就是在这样一个ROS2架构的基础上，继续进行了优化，原本DDS通信的部分依然保留，可以适配不同厂家的DDS通信系统，在此之上，针对功能性的组件进行了众多优化和补充，在上一节中我们也给大家介绍了这套框架。 优化之后的TogetherROS系统，在数据传输和AI处理方面，到底有多少提升呢，我们来看具体的对比数据。 通信效率量化对比 先来看下操作系统至关重要的数据通信功能，我们针对ROS中最为常用的大数据传输模式——话题通信进行了测试。 在单元测试中，使用同样的算力平台，分别安装TogetherROS和ROS2系统，然后在其中运行一个话题通信的发布者与订阅者，实现不同数据量的传输。经过数据统计，我们可以看到，在数据通信延时方面，随着数据量的增加，ROS2系统在通信延时、发送端和接收端的CPU占用率上，都会程线性增加，可以预想，在数据量较大的情况下，系统的通信负荷会非常严重。 而在TogetherROS系统中，由于使用了零拷贝的传输机制，传输数据量的增加，并不会导致延时和CPU占用率的增加，极大程度节省了系统资源。 在场景测试中，我们尽量模拟真实机器人的应用，使用TogetherROS和ROS2系统连接了多个相机、雷达和里程计等传感器，作为大量数据的输入来源，继续进行了测试，结果和之前的单元测试类似，ROS2系统此时的CPU占用率已经超过90%，想要运行数据传输之外的应用功能，几乎是不可能的，通信延时也达到了15ms以上，这在某些实时性要求比较高的应用中，是不可接受的。 而在TogetherROS系统中，CPU占用和通信延时也微乎其微，更多系统资源都可以让给应用处理。 CV图像处理量化对比 再来看下智能机器人中视觉感知层面的处理，TogetherROS系统集成了地平线Hobot CV视觉加速库，通过底层芯片中的硬件引擎，软硬件协同，可以提升常用CV算子的性能，降低系统资源的消耗，例如高斯滤波、图像缩放、畸变校正等常用的视觉处理方法。 而且在接口风格上兼容OpenCV，可以做到与OpenCV混合编程，便于视觉应用的开发。 具体测试CV加速库的效率，与OpenCV中软件实现的效率进行对比，我们分别对比图像缩放的帧率，图像旋转的帧率，高斯滤波的帧率，通过Hobot CV视觉加速库运行的帧率可以做到OpenCV的2到3倍，甚至更多倍。 模型推理 在AI处理方面，ROS2原生系统中并没有太多支持，只能依赖社区中的资源，很难充分发挥硬件的算力。 对此，TogetherROS系统集成了Hobot DNN模型推理库，集成了众多开源模型，借助底层芯片中的AI引擎BPU，提供充足的算力保障，开发者实际使用中，就不用花费很多时间在模型的调教和数据的训练上，基于这套系统，很快就可以部署人工智能应用啦。 传感器驱动管理 在传感器层面，是大量数据传输的来源，TogetherROS也重点进行了优化，针对常用的传感器类型，系统中内置参数配置、系统调用和内存管理机制，同样是在芯片的硬件层面进行了加速和隔离，保障数据流的稳定生成。 机器人开发工具 机器人开发过程中的性能优化和调试，也是非常繁杂的工作，TogetherROS系统自带火焰图等工具，可以实现系统层面的调优和测试，便于开发者挖掘系统性能。 以上这些都是TogetherROS在ROS系统之上的优化和补充，未来更多特性也会不断迭代推出，让智能机器人的开发更加简单。","text_tokens":["基础","开发成本","不断","较大","频繁","这套","里","udp","分别","就","操作系统","，","软件系统","花费","？","库","众多","系统资源","重要","风格","拷贝","数据流","旋转","不用","数据量","么","适用","厂家","一家","通过","发布者","听","安装","各种","ai","交付","找到","问题","目标","随着","改","开发工具","肯定","部署","一个","交道","雷达","可选项","提升","之上","基本","生成","应该","同样","来源","重新","例子","使用","减少","层","没有","中","达到","模式","兼容","切换","火焰","感知","系统","一团乱","也","推理","完善","传输数据","客户端","属性","不爽","软硬件","把","可以","打交道","增加","校正","省略","混合","未来","需求","太","介绍","中间","版本","macos","只有","不是","而","两个","以上","降低","原本","算子","应用","图像处理","迭代","效率","单元测试","所以","要求","实时","程度","请","发","接收端","资源","多少","不太","呢","数据通","模型","很多","写","话题","补充","做到","优化","cpu","负荷","充分发挥","接收","变化","统计","隔离","基于","引擎","几乎","成","端","如果","广泛","模拟","商业","发送","熟悉","继续","此时","做","满足","大","得","左侧","架构","加密","能够","乱麻","功能性","滤波","接入","而且","工具","原生","听说","如何","90%","选择","稳定","ros1","其实","明显","简单明了","opensplice","量化","2","甚至","推出","驱动","平台","了","相比","分发","代码","图","挖掘","来看","据传","机制","master","进程","最为","这样","给","比如","之外","一团乱麻","软件","率","符合","让给","用户","会","丢","bpu","fastrtps","都","与","由于","组件","预想","提高","配置","。","训练","再","框架","5g","完","充分","无法","按照","还有","dnn","共享内存","加速","多倍","不同","带来","方法","发现","一套","类型","国际标准","其中","例如","彼此","节点","公司","中间层","库会","开发者","结果","发成","导致","opencv","丰富","集成","智能","零","接受","节省","自带","将","内置","会程","此","情况","当然","保留","可选","hobot","过程","实现","更加","感器","人工","/","轻松","下","传感","时","用","啦","到","和","已经","要","社区","收","不","用率","并","3","层面","rtos","自","物","操作","但","调优","而已","国际","适配","常用","方面","它","算力","不过","看到","会成","进行","量","场景","为了","windows","只不过","建立","性能","管理机制","成本","vs","发布","编程","广泛应用","下边","倍","具体","帧","另外","严重","封装","标准","订阅","多个","程序","哪些","高斯","开源","视觉","解决","针对","右侧","机器人","就是","高","有且","占用率","突然","让","一样","开发","经过","之前","两者","数据传输","超过","管理器","指挥","togetherros","简单","接口","时间","延迟","除了","不可","借助","里程","数据通信","处理","理器","依赖","微乎其微","是","缩放","上","于","一节","畸变","依然","硬件","内","唯一","调教","大家","厂商","应用层","来讲","大量","对此","数据","—","discovery","ceo","ros","通信","输入","管理","更","简称","很难","从而","角色","支持","运行","rmw","cv","变得","好","内存","保障","参数","复用","里程计","对比","一种","对于","发挥","选项","通信协议","定义","图像","地平线","交给","复杂","机器","只要","工作","极大","真实","重点"," ","一团","dds","这个","主要","尽量","更换","设计","举","过来","提供","间层","测试","先","middleware","之后","共享","产品开发","调试","单元","这","人工智能","协议","多","地平","功能","到底","某些","张图","类似","延时","实时性","协同","制定","每","繁杂","芯片","最","便于","至关重要","时候","联网","客户","很快","走","、","tcp","可能","比较","传输","我们","移植","不会","的","底层","名字","常","特性","者","调用","想要","ros2","消失","信息","诟病","某","软硬","系统集成","另","等","一行","每个","这里","在","部分","这些","至关","linux","通信接口","线性","非常","然后","该","相机","作为","充足","消耗","连接","其他","为","占用","自家","15ms","产品","有","传感器","最大","所有","只能","需要","实际"],"title":"性能对比","title_tokens":["对比","性能"]},{"location":"hhp/1.3_TogetherROS%E4%B8%8EROS%E5%AF%B9%E6%AF%94/#togetherrosros","text":"","text_tokens":[],"title":"TogetherROS与ROS性能对比","title_tokens":["togetherros","ros","与","对比","性能"]},{"location":"hhp/1.3_TogetherROS%E4%B8%8EROS%E5%AF%B9%E6%AF%94/#ros2-vs-ros1","text":"先来看下两个大版本ROS的系统架构。 在这张图中，左侧是ROS1，右侧是ROS2，两者最明显的变化，就是Master。 在ROS1中，应用层里Master这个节点管理器的角色至关重要，所有节点都得听它指挥，类似是一个公司的CEO，有且只有一个，如果这个CEO突然消失，公司肯定会成一团乱麻。ROS2把这个最不稳定的角色请走了，节点可以通过另外一套discovery——自发现机制，找到彼此，从而建立稳定的通信连接。 中间层是ROS封装好的标准通信接口，我们写程序的时候，会频繁和这些通信接口打交道，比如发布一个图像的数据，接收一个雷达的信息，客户端库会再调用底层复杂的驱动和通信协议，让我们的开发变得更加简单明了。 在ROS1中，ROS通信依赖底层的TCP和UDP协议，而在ROS2中，通信协议更换成了更加复杂但也更加完善的DDS系统。 如果是在进程内需要进行大量数据的通信，ROS1和ROS2都提供了基于共享内存的通信方法，只不过名字不太一样而已。 最下边是系统层，也就是可以将ROS安装在哪些操作系统上，ROS1主要安装在Linux上，ROS2的可选项就很多了，Linux、windows、MacOS、RTOS都可以。","text_tokens":["得","左侧","架构","它","频繁","通信协议","选项","乱麻","里","udp","不过","图像","就","会成","操作系统","进行","windows","复杂","，","只不过","建立","稳定","ros1","明显","简单明了","重要"," ","一团","发布","这个","驱动","dds","主要","了","下边","更换","来看","机制","另外","master","通过","提供","进程","听","比如","间层","封装","安装","标准","一团乱麻","先","找到","程序","共享","哪些","会","这","肯定","一个","交道","都","协议","雷达","可选项","右侧","就是","有且","张图","类似","。","突然","让","再","一样","开发","共享内存","层","两者","中","最","管理器","指挥","简单","至关重要","接口","系统","方法","时候","发现","一套","一团乱","客户","也","完善","走","、","彼此","客户端","tcp","节点","把","公司","可以","我们","打交道","的","中间层","底层","库会","理器","名字","依赖","中间","版本","macos","只有","是","而","上","两个","将","调用","ros2","消失","信息","应用","可选","内","更加","应用层","大量","请","数据","—","在","不太","这些","至关","discovery","linux","通信接口","下","写","ceo","很多","ros","和","通信","接收","变化","管理","连接","基于","不","rtos","自","变得","成","操作","如果","从而","角色","所有","但","需要","而已","大","好","内存"],"title":"ROS2 vs ROS1","title_tokens":[" ","vs","ros2","ros1"]},{"location":"hhp/1.3_TogetherROS%E4%B8%8EROS%E5%AF%B9%E6%AF%94/#ros2","text":"ROS2相比ROS1最大的变化，除了省略了Master之外，应该就是通信系统的变化了。ROS1中基于TCP/UDP的通信系统，频繁诟病于延迟、丢数据、无法加密等问题，ROS2中的DDS在通信层面的功能就丰富多了。 DDS其实是物联网中广泛应用的一种通信协议，类似于我们常听说的5G通信一样，DDS是一个国际标准，能够实现该标准的软件系统并不是唯一的，所以我们可以选择多个厂家提供的DDS系统，比如这里的OpenSplice、FastRTPS，还有更多厂家提供的，每一家的性能不同，适用的场景也不同。 不过这就带来一个问题，每个DDS厂家的软件接口肯定是不一样的，如果我们按照某一家的接口写完了程序，想要切换其他厂家的DDS，不是要重新写代码么？这当然不符合ROS提高软件复用率的目标。 为了解决这个问题，ROS2设计了一个ROS Middleware，简称RMW，也就是制定一个标准的接口，比如如何发数据，如何收数据，数据的各种属性如何配置，都定义好了，如果厂家想要接入ROS社区，就得按照这个标准写一个适配的接口，把自家的DDS给移植过来，这样就把问题交给了最熟悉自家DDS的厂商。对于我们这些用户来讲，某一个DDS用的不爽，只要安装另一个，然后做一个简单的配置，程序一行的都不用改，轻松更换底层的通信系统。 举一个例子，比如我们在产品开发时，可以先用开源版本的DDS满足基本需求，部署交付的产品时，再更换为商业版本更稳定的DDS，这样可以减少开发成本。","text_tokens":["复用","开发成本","加密","能够","得","一种","对于","频繁","通信协议","udp","不过","定义","就","接入","场景","为了","交给","听说","，","软件系统","只要","如何","性能","选择","？","稳定","ros1","其实","opensplice","成本"," ","dds","广泛应用","这个","了","相比","更换","代码","不用","设计","么","举","适用","厂家","一家","过来","提供","master","这样","给","比如","之外","安装","各种","标准","先","交付","软件","middleware","多个","程序","率","产品开发","符合","问题","目标","开源","改","用户","这","肯定","丢","解决","一个","fastrtps","协议","多","都","部署","功能","就是","类似","提高","配置","。","基本","再","一样","5g","应该","完","重新","制定","无法","按照","开发","每","例子","还有","减少","中","最","简单","切换","不同","接口","带来","系统","联网","延迟","也","国际标准","除了","、","属性","tcp","不爽","可以","把","我们","移植","的","底层","省略","rmw","常","需求","发成","版本","丰富","不是","是","于","想要","ros2","当然","诟病","应用","某","实现","唯一","另","所以","厂商","等","来讲","一行","每个","发","数据","这里","/","在","轻松","这些","写","时","ros","用","通信","然后","该","变化","要","社区","更","收","基于","不","简称","并","其他","层面","物","为","如果","广泛","自家","商业","产品","熟悉","最大","做","满足","国际","好","适配"],"title":"ROS2系统架构","title_tokens":["架构","ros2","系统"]},{"location":"hhp/1.3_TogetherROS%E4%B8%8EROS%E5%AF%B9%E6%AF%94/#togetherros-vs-ros2","text":"TogetherROS就是在这样一个ROS2架构的基础上，继续进行了优化，原本DDS通信的部分依然保留，可以适配不同厂家的DDS通信系统，在此之上，针对功能性的组件进行了众多优化和补充，在上一节中我们也给大家介绍了这套框架。 优化之后的TogetherROS系统，在数据传输和AI处理方面，到底有多少提升呢，我们来看具体的对比数据。","text_tokens":["给","基础","togetherros","大家","ai","不同","架构","之后","系统","方面","对比","数据","这套","在","也","部分","功能性","多少","呢","依然","针对","一个","进行","补充","功能","优化","和","提升","，","就是","通信","可以","之上","我们","组件","的","传输","到底","中","。","处理","众多","框架","介绍"," ","dds","了","具体","上","继续","有","ros2","此","原本","据传","来看","保留","厂家","一节","数据传输","适配","这样"],"title":"TogetherROS vs ROS2","title_tokens":[" ","ros2","togetherros","vs"]},{"location":"hhp/1.3_TogetherROS%E4%B8%8EROS%E5%AF%B9%E6%AF%94/#_1","text":"先来看下操作系统至关重要的数据通信功能，我们针对ROS中最为常用的大数据传输模式——话题通信进行了测试。 在单元测试中，使用同样的算力平台，分别安装TogetherROS和ROS2系统，然后在其中运行一个话题通信的发布者与订阅者，实现不同数据量的传输。经过数据统计，我们可以看到，在数据通信延时方面，随着数据量的增加，ROS2系统在通信延时、发送端和接收端的CPU占用率上，都会程线性增加，可以预想，在数据量较大的情况下，系统的通信负荷会非常严重。 而在TogetherROS系统中，由于使用了零拷贝的传输机制，传输数据量的增加，并不会导致延时和CPU占用率的增加，极大程度节省了系统资源。 在场景测试中，我们尽量模拟真实机器人的应用，使用TogetherROS和ROS2系统连接了多个相机、雷达和里程计等传感器，作为大量数据的输入来源，继续进行了测试，结果和之前的单元测试类似，ROS2系统此时的CPU占用率已经超过90%，想要运行数据传输之外的应用功能，几乎是不可能的，通信延时也达到了15ms以上，这在某些实时性要求比较高的应用中，是不可接受的。 而在TogetherROS系统中，CPU占用和通信延时也微乎其微，更多系统资源都可以让给应用处理。","text_tokens":["里程计","方面","较大","算力","分别","看到","操作系统","进行","量","场景","，","机器","90%","系统资源","极大","真实","重要"," ","发布","平台","拷贝","了","尽量","数据量","来看","据传","机制","最为","发布者","严重","之外","测试","安装","先","订阅","多个","随着","让给","单元","会","这","针对","一个","都","多","雷达","与","功能","机器人","由于","高","预想","某些","类似","延时","。","实时性","占用率","来源","同样","使用","经过","之前","数据传输","超过","中","达到","模式","togetherros","不同","至关重要","系统","也","其中","传输数据","、","不可","可能","可以","里程","传输","我们","增加","不会","的","比较","数据通信","处理","结果","导致","微乎其微","者","是","零","而","接受","节省","上","以上","想要","会程","ros2","情况","应用","实现","单元测试","感器","等","大量","要求","实时","程度","数据","接收端","—","资源","数据通","在","至关","下","线性","传感","话题","ros","和","cpu","非常","通信","负荷","然后","已经","相机","作为","接收","输入","统计","连接","更","不","用率","并","几乎","端","占用","操作","模拟","15ms","发送","传感器","继续","此时","运行","大","常用"],"title":"通信效率量化对比","title_tokens":["对比","通信","效率","量化"]},{"location":"hhp/1.3_TogetherROS%E4%B8%8EROS%E5%AF%B9%E6%AF%94/#cv","text":"再来看下智能机器人中视觉感知层面的处理，TogetherROS系统集成了地平线Hobot CV视觉加速库，通过底层芯片中的硬件引擎，软硬件协同，可以提升常用CV算子的性能，降低系统资源的消耗，例如高斯滤波、图像缩放、畸变校正等常用的视觉处理方法。 而且在接口风格上兼容OpenCV，可以做到与OpenCV混合编程，便于视觉应用的开发。 具体测试CV加速库的效率，与OpenCV中软件实现的效率进行对比，我们分别对比图像缩放的帧率，图像旋转的帧率，高斯滤波的帧率，通过Hobot CV视觉加速库运行的帧率可以做到OpenCV的2到3倍，甚至更多倍。","text_tokens":["对比","滤波","分别","图像","地平线","而且","进行","，","机器","性能","库","系统资源","2","甚至","风格"," ","编程","旋转","了","倍","具体","来看","帧","通过","测试","软件","高斯","率","视觉","地平","与","提升","机器人","。","协同","再","开发","加速","芯片","中","多倍","togetherros","兼容","便于","接口","感知","系统","方法","、","例如","软硬件","可以","校正","我们","的","底层","处理","混合","opencv","集成","智能","缩放","上","降低","算子","应用","畸变","软硬","硬件","实现","hobot","系统集成","效率","等","资源","在","下","做到","到","消耗","更","引擎","3","层面","运行","cv","常用"],"title":"CV图像处理量化对比","title_tokens":["图像处理","处理","图像","量化","对比","cv"]},{"location":"hhp/1.3_TogetherROS%E4%B8%8EROS%E5%AF%B9%E6%AF%94/#_2","text":"在AI处理方面，ROS2原生系统中并没有太多支持，只能依赖社区中的资源，很难充分发挥硬件的算力。 对此，TogetherROS系统集成了Hobot DNN模型推理库，集成了众多开源模型，借助底层芯片中的AI引擎BPU，提供充足的算力保障，开发者实际使用中，就不用花费很多时间在模型的调教和数据的训练上，基于这套系统，很快就可以部署人工智能应用啦。","text_tokens":["调教","togetherros","ai","人工","系统","时间","方面","对此","开源","发挥","数据","这套","资源","在","算力","推理","很快","模型","很多","人工智能","就","bpu","部署","多","保障","原生","啦","借助","和","，","充分发挥","可以","花费","充足","的","底层","社区","处理","。","库","训练","基于","开发者","依赖","hobot","并","太","充分","众多","引擎"," ","开发","集成","很难","分发","了","使用","dnn","智能","不用","上","应用","ros2","芯片","只能","支持","系统集成","实际","提供","没有","中","硬件"],"title":"模型推理","title_tokens":["模型","推理"]},{"location":"hhp/1.3_TogetherROS%E4%B8%8EROS%E5%AF%B9%E6%AF%94/#_3","text":"在传感器层面，是大量数据传输的来源，TogetherROS也重点进行了优化，针对常用的传感器类型，系统中内置参数配置、系统调用和内存管理机制，同样是在芯片的硬件层面进行了加速和隔离，保障数据流的稳定生成。","text_tokens":["参数","感器","togetherros","大量","系统","数据","类型","在","也","针对","传感","进行","、","保障","和","优化","，","传输","的","管理","配置","稳定","。","管理机制","隔离","生成","层面","来源","同样","重点","数据流","了","是","加速","传感器","内置","硬件","调用","据传","芯片","机制","数据传输","内存","中","常用"],"title":"传感器驱动管理","title_tokens":["感器","传感","传感器","驱动","管理"]},{"location":"hhp/1.3_TogetherROS%E4%B8%8EROS%E5%AF%B9%E6%AF%94/#_4","text":"机器人开发过程中的性能优化和调试，也是非常繁杂的工作，TogetherROS系统自带火焰图等工具，可以实现系统层面的调优和测试，便于开发者挖掘系统性能。 以上这些都是TogetherROS在ROS系统之上的优化和补充，未来更多特性也会不断迭代推出，让智能机器人的开发更加简单。","text_tokens":["实现","迭代","togetherros","测试","火焰","便于","更加","简单","等","系统","不断","调试","在","也","这些","会","工具","都","ros","补充","多","和","优化","非常","机器人","，","机器","可以","之上","工作","的","性能","。","更","开发者","让","未来","层面","特性"," ","推出","开发","繁杂","是","智能","自带","图","以上","挖掘","调优","中","过程"],"title":"机器人开发工具","title_tokens":["开发工具","工具","机器人","机器","开发"]},{"location":"hhp/1.4_TogetherROS%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF/","text":"TogetherROS应用场景 相比手机、电脑等通用平台，机器人的类型可是千变万化，构建机器人操作系统的难度就远比手机和电脑的操作系统要复杂很多。机器人的主流应用大致可以分为 服务机器人、工业机器人、特种机器人 三个方向，无论是在哪一方向，都会面临很多问题。比如传感器、执行器等器件选型复杂，不同场景下需要的性能和参数都有所不同，这就要求操作系统得兼容尽量多的器件。 不同场景下的计算平台算力和资源差异很大，一般都需要进行定制化的裁剪和优化，这就得有一系列工具便于系统的定制和裁剪。每个场景中的应用功能变化也很大，各种算法的集成和开发要尽量简单，算法基于的数据也在持续迭代，需要一套工具链来提供迭代和升级。 针对各种各样的需求变化，TogetherROS系统都提供了支持。 服务机器人 在服务机器人领域，场景和功能尤其复杂，有家里的扫地机器人，有餐厅里的送餐机器人，有咖啡店里的双臂机器人，还有物流送货的飞行机器人，虽然每一个机器人平台的构型不同，但都需要动态处理多种多样的环境变化，这就需要TogetherROS系统基于大量数据的AI处理和丰富的组件功能支持，快速推动各种功能的落地。 工业机器人 在工业机器人领域，目前的机器人主要以工业机械臂和物流移动机器人形态为主，场景相比服务机器人要标准很多，核心目的是要提高生产效率，这就要求机器人可以长期稳定的运行，同时实时处理各项运动功能，TogetherROS系统可裁剪和性能稳定等特点，都可以符合要求。 特种机器人 而在特种机器人的应用领域，结合了服务和工业场景中的不少特点，机器人形态多变，得动态处理各种复杂场景里的事件，例如火灾、地震、管道等场景，更是会发生很多不可预料的情况，TogetherROS系统中的AI处理可以较好的保障不同环境中的感知效果，同时端云联动，可以实现大量数据的训练和部署，不断提高对复杂环境的处理能力。 可见，TogetherROS系统充分考虑了众多应用场景的需求，不仅可以满足智能机器人开发过程中的每一个环节，也考虑到了机器人未来在产业中的应用效果。","text_tokens":["参数","推动","服务","执行","得","不断","环节","端云","餐厅","应用领域","很大","算力","里","构建","裁剪","就","操作系统","工具","进行","场景","复杂","难度","，","机器","工业","性能","稳定","动机","结合","生产","一系","动态","多变","众多","哪"," ","平台","主要","相比","尽量","了","效果","各项","环境","形态","提供","执行器","扫地","咖啡店","比如","比","手机","各种","ai","标准","化","较","目的","问题","目前","符合","不仅","各种各样","会","这","针对","一个","发生","都","多","部署","功能","各样","机器人","产业","长期","组件","一系列","对","链来","提高","。","训练","虽然","充分","运动","更是","多样","开发","每","还有","一般","多种多样","中","构型","实时处理","togetherros","兼容","便于","简单","双臂","分为","不同","物流","以","联动","感知","系统","类型","一套","也","预料","可是","、","尤其","一","送餐","例如","定制","不可","家里","不少","可以","特种","的","考虑","差异","处理","有所","能力","未来","需求","主流","臂","持续","丰富","集成","可","是","智能","而","计算","送货","情况","算法","无论","应用","方向","系列","同时","无论是","实现","过程","迭代","通用","感器","多种","效率","等","大量","器件","要求","实时","飞行","每个","数据","资源","在","移动机器人","快速","很多","下","地震","大致","传感","移动","火灾","咖啡","到","和","优化","领域","符合要求","升级","变化","机械","要","核心","远","事件","基于","选型","千变万化","为主","操作","落地","充分考虑","电脑","面临","传感器","有","管道","但","支持","运行","三个","需要","有所不同","满足","可见","好","特点","保障"],"title":"应用场景","title_tokens":["应用","场景"]},{"location":"hhp/1.4_TogetherROS%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF/#togetherros","text":"相比手机、电脑等通用平台，机器人的类型可是千变万化，构建机器人操作系统的难度就远比手机和电脑的操作系统要复杂很多。机器人的主流应用大致可以分为 服务机器人、工业机器人、特种机器人 三个方向，无论是在哪一方向，都会面临很多问题。比如传感器、执行器等器件选型复杂，不同场景下需要的性能和参数都有所不同，这就要求操作系统得兼容尽量多的器件。 不同场景下的计算平台算力和资源差异很大，一般都需要进行定制化的裁剪和优化，这就得有一系列工具便于系统的定制和裁剪。每个场景中的应用功能变化也很大，各种算法的集成和开发要尽量简单，算法基于的数据也在持续迭代，需要一套工具链来提供迭代和升级。 针对各种各样的需求变化，TogetherROS系统都提供了支持。","text_tokens":["参数","服务","执行","得","很大","算力","构建","裁剪","就","操作系统","工具","进行","场景","复杂","难度","，","机器","工业","性能","一系","哪"," ","平台","相比","尽量","了","提供","执行器","比如","比","手机","各种","化","问题","各种各样","会","这","针对","都","多","功能","各样","机器人","一系列","链来","。","开发","一般","中","便于","兼容","简单","togetherros","分为","不同","系统","类型","一套","也","可是","、","一","定制","可以","特种","的","差异","有所","需求","主流","持续","集成","计算","算法","无论","应用","方向","系列","无论是","迭代","通用","感器","等","器件","要求","每个","数据","资源","在","很多","下","大致","传感","和","优化","升级","变化","要","远","基于","选型","千变万化","操作","电脑","面临","传感器","有","支持","三个","需要","有所不同"],"title":"TogetherROS应用场景","title_tokens":["应用","场景","togetherros"]},{"location":"hhp/1.4_TogetherROS%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF/#_1","text":"在服务机器人领域，场景和功能尤其复杂，有家里的扫地机器人，有餐厅里的送餐机器人，有咖啡店里的双臂机器人，还有物流送货的飞行机器人，虽然每一个机器人平台的构型不同，但都需要动态处理多种多样的环境变化，这就需要TogetherROS系统基于大量数据的AI处理和丰富的组件功能支持，快速推动各种功能的落地。","text_tokens":["构型","推动","多种","物流","双臂","togetherros","ai","服务","不同","各种","大量","系统","飞行","数据","餐厅","在","里","这","快速","就","一个","尤其","都","场景","送餐","咖啡","领域","和","功能","机器人","，","机器","复杂","家里","组件","的","变化","处理","。","基于","虽然","动态","多样","丰富","每","平台","落地","还有","有","送货","但","环境","支持","需要","多种多样","扫地","咖啡店"],"title":"服务机器人","title_tokens":["服务","机器人","机器"]},{"location":"hhp/1.4_TogetherROS%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF/#_2","text":"在工业机器人领域，目前的机器人主要以工业机械臂和物流移动机器人形态为主，场景相比服务机器人要标准很多，核心目的是要提高生产效率，这就要求机器人可以长期稳定的运行，同时实时处理各项运动功能，TogetherROS系统可裁剪和性能稳定等特点，都可以符合要求。","text_tokens":["实时处理","物流","效率","togetherros","标准","服务","等","以","要求","系统","实时","目的","符合","目前","在","移动机器人","这","很多","裁剪","就","移动","都","场景","领域","和","功能","机器人","，","机器","可以","长期","工业","符合要求","的","提高","机械","性能","要","稳定","动机","处理","。","核心","生产","运动","臂","为主","可","主要","相比","是","各项","运行","形态","特点","同时"],"title":"工业机器人","title_tokens":["工业","机器人","机器"]},{"location":"hhp/1.4_TogetherROS%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF/#_3","text":"而在特种机器人的应用领域，结合了服务和工业场景中的不少特点，机器人形态多变，得动态处理各种复杂场景里的事件，例如火灾、地震、管道等场景，更是会发生很多不可预料的情况，TogetherROS系统中的AI处理可以较好的保障不同环境中的感知效果，同时端云联动，可以实现大量数据的训练和部署，不断提高对复杂环境的处理能力。 可见，TogetherROS系统充分考虑了众多应用场景的需求，不仅可以满足智能机器人开发过程中的每一个环节，也考虑到了机器人未来在产业中的应用效果。","text_tokens":["服务","得","不断","环节","端云","应用领域","里","场景","复杂","，","机器","工业","结合","多变","动态","众多"," ","了","效果","环境","形态","各种","ai","较","不仅","会","部署","发生","一个","机器人","产业","对","提高","。","训练","充分","更是","开发","每","中","togetherros","联动","不同","感知","系统","也","预料","、","例如","不可","不少","可以","特种","的","考虑","处理","能力","未来","需求","智能","而","情况","应用","同时","过程","实现","等","大量","数据","在","很多","地震","火灾","到","领域","和","事件","充分考虑","管道","满足","可见","好","特点","保障"],"title":"特种机器人","title_tokens":["特种","机器人","机器"]},{"location":"hhp/2.1_%E6%9C%BA%E5%99%A8%E4%BA%BA%E5%BC%80%E5%8F%91%E5%A5%97%E4%BB%B6%E4%BB%8B%E7%BB%8D/","text":"旭日X3派介绍 TogetherROS是一个软件层面的系统，要想使用它，当然得找一个硬件层面的计算平台，安装之后才能使用啦。 之前我们提到，TogetherROS会基于地平线的AI芯片，充分发挥硬件性能，我们如何使用这颗芯片呢？ 旭日X3派 没问题，地平线已经为我们准备好了，那就是搭载旭日X3芯片的机器人开发板——旭日X3派。 第一眼看上去，大家是否会想到树莓派呢？没错，为了适应开发者的使用习惯，兼容市面上大量已有的模块，旭日X3派的整体外观和接口形态都接近树莓派，不过面向的开发对象以及板卡的计算实力，和树莓派就完全不同了。 类似这些常用的传感器，旭日X3派统统都可以支持，未来还有更多机器人套件会出现在大家身边。 大家可以在这张表中，看到旭日X3派的硬件资源，CPU是四核A53，频率1.2Hz，在系统内还可以进行超频，BPU就是硬件级的AI引擎，这是旭日X3派相比市面上其他开发板，最大的不同，也是核心性能的主要来源，类似于业界常听到的NPU，这里使用的是地平线机器人独有的伯努利2.0架构，可以提供5Tops的等效算力支持。 内存方面，大家可以选择2GB或者4GB的版本，存储使用的是SD卡，我们可以自行选择，只要大于8GB就可以啦。 在多媒体方面，旭日X3派支持硬件级别的H265和H264编解码，常用的图像和视频都可以流畅播放。 接口方面，尽量可以满足我们常用外接设备和开发的需求，这里是一个CSI的相机接口，板载USB有3个，包含1个USB3.0和2个USB2.0，这里是一个板载的调试串口，我们可以通过它获取系统层面的很多调试信息，也可以与板卡进行通信。 板卡上也搭载了有线网络和无线网络，这个有线网口我们可以直接用网线连接到电脑，就可以在电脑上远程登录和板卡通信了，或者连接到路由器，让板卡直接上网，无线网络和蓝牙是一个二合一的模块，我们也可以直接通过wiki，让板卡连接到某个网络中。 显示接口主要是这里的HDMI，如果我们先要看到系统界面，或者后续很多视觉例程的识别效果，都可以通过HDMI外接一个显示器进行显示。 最后还有至关重要的扩展接口，有40个引脚，和树莓派的接口定义一致，什么GPIO、串口、I2C、SPI等等，一应俱全。 这块板卡我们在使用的时候，推荐使用5V3A的电源，通过TypeC线连接到这里供电，官方提供的系统目前是Ubuntu20.04，使用起来和原生系统没有太大差别。 总体来讲， 旭日X3派是一款面向生态开发者的嵌入式AI开发板，接口兼容树莓派，具有5Tops的端侧推理算力，以及4核ARM A53的处理能力。 面对个人开发者，旭日X3派可以让每一位开发者拥有自己的AI开发套件，不再受开发板高昂的价格限制，面对高等院校，使用旭日X3派开发套件探索AI和机器人应用是学习的开始，有助于学生快速入门人工智能与机器人开发，面对产业，旭日X3派以及地平线的AI工具链，可以帮助客户将产品尽快推向市场，快速落地智能机器人方向的解决方案。 旭日X3M芯片 在旭日X3派上，最为核心的当然就是这颗AI芯片了，这是关于芯片的具体信息，供大家参考。 值得一提的是，随着芯片的技术迭代，2023年，地平线将推出X5芯片，比较大的变化是CPU升级到了8核A55，主频提升到1.8GHz，BPU的算力也将达到8Tops，还加入了GPU，以及更多可扩展的接口。 在使用旭日X3派的过程中，大家也可以期待旭日X5派了。 旭日X3派接口 好啦，还是回到旭日X3派的开发接口上来，我们再做一个整理，这些就是我们使用开发板进行智能机器人开发过程中，最为常用的接口啦。 大家目前在树莓派或者其他开发板上使用的绝大部分模块，基本都可以在旭日X3派上复用，同时还有更多智能化的玩法等着大家。 关于40Pin扩展接口的序号排布，大家可以看这里，引脚的序号是从靠近HDMI板卡内测的开始算起，是引脚1，然后依次蛇形计数，分别是1、2、3、4、5，一直到这里是39和40。 上图是40PIN扩展接口的详细定义，有3.3V和5V的电源信号，有I2C、I2S、SPI、UART等通信接口，还有很多可动态配置的GPIO信号，基本可以满足各种各样的机器人开发啦。 好啦，关于旭日X3派这块开发板我们已经了解清楚了，具体该如何使用呢，我们后续操作起来。","text_tokens":["获取","视频","分别","后续","就","线网","，","绝大","？","usb","有线","识别","重要","回到","接近","通过","安装","面向","上网","ai","各种","供电","调试信息","2.0","问题","随着","树莓","这是","无线","一个","有助","提升","智能化","无线网络","绝大部分","整体","基本","csi","来源","sd","使用","蛇形","市场","外","外接","typec","中","没有","达到","兼容","引脚","系统","什么","hz","也","推理","依次","高等院校","上来","可以","伯努利","显示器","未来","npu","需求","播放","介绍","太","版本","计算","总体","自己","应用","独有","找","推向","旭日","同时","3.3","迭代","资源","整理","呢","官方","这颗","超频","很多","搭载","信号","5","cpu","5tops","充分发挥","变化","基于","引擎","一应","上图","如果","落地","电脑","线","做","满足","大","方案","出现","院校","得","架构","二合","受","高昂","工具","原生","等等","值得","如何","选择","2","推出","平台","助于","分发","了","相比","统统","硬件资源","算","形态","最为","那","软件","多媒体","接设备","尽快","会","bpu","都","派","与","1","技术","产业","配置","清楚","。","一位","主频","具有","再","x3m","充分","套件","还有","2gb","学习","不同","起来","ubuntu20.04","限制","加入","看上","推向市场","俱全","能力","开发者","可","gpu","智能","这块","将","8","当然","i2c","方向","市面上","过程","路由器","感器","人工","界面","路由","起","业界","是否","频率","传感","5v","用","wiki","啦","到","和","x3","已经","usb3.0","模块","升级","才能","要","核心","i2s","3","网络","层面","个","操作","uart","有线网","还","远程","编解码","一眼","常用","张表中","h264","看上去","方面","它","没","算力","不过","看到","面对","进行","为了","以及","串口","最后","性能","推荐","完全","动态","实力","效果","具体","了解","40","对象","开始","板载","学生","有助于","流畅","二合一","视觉","解决","想","入门","价格","机器人","板卡","就是","网线","级","让","不再","链","开发","嵌入式","之前","值得一提的是","togetherros","接口","无线网","一致","市面","个人","参考","处理","等效","核","解码","卡","spi","是","准备","上","于","计数","设备","硬件","内","ghz","大家","来讲","大量","四核","—","解决方案","靠近","通信","供","更","口","大部分","拥有","扩展","上去","提到","第一","生态","媒体","支持","级别","好","内存","复用","v","8tops","1.8","合一","包含","某个","发挥","定义","图像","地平线","一应俱全","大部","机器","只要","详细","第一眼","usb2.0"," ","这个","主要","a53","尽量","听到","想到","玩法","x5","提供","39","身边","先","之后","调试","目前","关于","各种各样","已有","这","人工智能","外观","多","年","地平","h265","没错","各样","2023","类似","端侧","适应","看","接口定义","每","探索","5v3a","芯片","嵌入","着","1.2","排布","是从","帮助","至关重要","习惯","时候","客户","序号","例程","、","比较","我们","的","差别","高等","8gb","a55","hdmi","还是","信息","一款","4gb","面上","40pin","等","一直","这里","在","内测","这些","至关","快速","部分","通信接口","显示","自行","存储","电源","然后","该","相机","常听到","连接","直接","其他","大于","为","或者","期待","蓝牙","gpio","产品","传感器","有","开发板","最大","arm","登录","4"],"title":"旭日X3派介绍","title_tokens":["介绍","x3","派","旭日"]},{"location":"hhp/2.1_%E6%9C%BA%E5%99%A8%E4%BA%BA%E5%BC%80%E5%8F%91%E5%A5%97%E4%BB%B6%E4%BB%8B%E7%BB%8D/#x3","text":"TogetherROS是一个软件层面的系统，要想使用它，当然得找一个硬件层面的计算平台，安装之后才能使用啦。 之前我们提到，TogetherROS会基于地平线的AI芯片，充分发挥硬件性能，我们如何使用这颗芯片呢？","text_tokens":["togetherros","安装","ai","得","软件","之后","系统","它","发挥","会","呢","这颗","地平线","一个","想","地平","啦","，","充分发挥","我们","的","才能","如何","性能","？","要","。","基于","层面","充分"," ","平台","是","使用","提到","分发","计算","之前","芯片","当然","找","硬件"],"title":"旭日X3派介绍","title_tokens":["介绍","x3","派","旭日"]},{"location":"hhp/2.1_%E6%9C%BA%E5%99%A8%E4%BA%BA%E5%BC%80%E5%8F%91%E5%A5%97%E4%BB%B6%E4%BB%8B%E7%BB%8D/#x3_1","text":"没问题，地平线已经为我们准备好了，那就是搭载旭日X3芯片的机器人开发板——旭日X3派。 第一眼看上去，大家是否会想到树莓派呢？没错，为了适应开发者的使用习惯，兼容市面上大量已有的模块，旭日X3派的整体外观和接口形态都接近树莓派，不过面向的开发对象以及板卡的计算实力，和树莓派就完全不同了。 类似这些常用的传感器，旭日X3派统统都可以支持，未来还有更多机器人套件会出现在大家身边。 大家可以在这张表中，看到旭日X3派的硬件资源，CPU是四核A53，频率1.2Hz，在系统内还可以进行超频，BPU就是硬件级的AI引擎，这是旭日X3派相比市面上其他开发板，最大的不同，也是核心性能的主要来源，类似于业界常听到的NPU，这里使用的是地平线机器人独有的伯努利2.0架构，可以提供5Tops的等效算力支持。 内存方面，大家可以选择2GB或者4GB的版本，存储使用的是SD卡，我们可以自行选择，只要大于8GB就可以啦。 在多媒体方面，旭日X3派支持硬件级别的H265和H264编解码，常用的图像和视频都可以流畅播放。 接口方面，尽量可以满足我们常用外接设备和开发的需求，这里是一个CSI的相机接口，板载USB有3个，包含1个USB3.0和2个USB2.0，这里是一个板载的调试串口，我们可以通过它获取系统层面的很多调试信息，也可以与板卡进行通信。 板卡上也搭载了有线网络和无线网络，这个有线网口我们可以直接用网线连接到电脑，就可以在电脑上远程登录和板卡通信了，或者连接到路由器，让板卡直接上网，无线网络和蓝牙是一个二合一的模块，我们也可以直接通过wiki，让板卡连接到某个网络中。 显示接口主要是这里的HDMI，如果我们先要看到系统界面，或者后续很多视觉例程的识别效果，都可以通过HDMI外接一个显示器进行显示。 最后还有至关重要的扩展接口，有40个引脚，和树莓派的接口定义一致，什么GPIO、串口、I2C、SPI等等，一应俱全。 这块板卡我们在使用的时候，推荐使用5V3A的电源，通过TypeC线连接到这里供电，官方提供的系统目前是Ubuntu20.04，使用起来和原生系统没有太大差别。 总体来讲， 旭日X3派是一款面向生态开发者的嵌入式AI开发板，接口兼容树莓派，具有5Tops的端侧推理算力，以及4核ARM A53的处理能力。 面对个人开发者，旭日X3派可以让每一位开发者拥有自己的AI开发套件，不再受开发板高昂的价格限制，面对高等院校，使用旭日X3派开发套件探索AI和机器人应用是学习的开始，有助于学生快速入门人工智能与机器人开发，面对产业，旭日X3派以及地平线的AI工具链，可以帮助客户将产品尽快推向市场，快速落地智能机器人方向的解决方案。","text_tokens":["获取","视频","后续","就","线网","，","？","usb","有线","识别","重要","接近","通过","面向","上网","ai","供电","调试信息","2.0","问题","树莓","这是","无线","一个","有助","无线网络","整体","csi","来源","sd","使用","市场","外","外接","typec","中","没有","兼容","引脚","系统","什么","hz","也","推理","高等院校","可以","伯努利","显示器","未来","npu","需求","播放","太","版本","计算","总体","自己","应用","独有","推向","旭日","资源","呢","官方","超频","很多","搭载","cpu","5tops","引擎","一应","如果","落地","电脑","线","满足","大","方案","出现","院校","架构","二合","受","高昂","工具","原生","等等","选择","2","助于","了","相比","统统","硬件资源","形态","那","多媒体","接设备","尽快","会","bpu","都","派","与","1","产业","。","一位","具有","套件","还有","2gb","学习","不同","起来","ubuntu20.04","限制","看上","推向市场","俱全","能力","开发者","智能","这块","将","i2c","方向","市面上","路由器","感器","人工","界面","路由","业界","是否","频率","传感","用","wiki","啦","到","和","x3","已经","usb3.0","模块","要","核心","3","网络","层面","个","有线网","还","远程","编解码","一眼","常用","张表中","h264","看上去","方面","它","没","算力","不过","看到","面对","进行","为了","以及","串口","最后","性能","推荐","完全","实力","效果","40","对象","开始","板载","学生","有助于","流畅","二合一","视觉","解决","入门","价格","机器人","板卡","就是","网线","级","让","不再","链","开发","嵌入式","接口","无线网","一致","市面","个人","处理","等效","核","解码","卡","spi","是","准备","上","于","设备","硬件","内","大家","来讲","大量","四核","—","解决方案","通信","更","口","拥有","扩展","上去","第一","生态","媒体","支持","级别","好","内存","合一","包含","某个","定义","图像","地平线","一应俱全","机器","只要","第一眼","usb2.0"," ","这个","主要","a53","尽量","听到","想到","提供","身边","先","调试","目前","已有","这","人工智能","外观","多","地平","h265","没错","类似","端侧","适应","接口定义","每","探索","5v3a","芯片","嵌入","1.2","帮助","至关重要","习惯","时候","客户","例程","、","我们","的","差别","高等","8gb","hdmi","信息","一款","4gb","面上","这里","在","这些","至关","快速","显示","自行","存储","电源","相机","常听到","连接","直接","其他","大于","为","或者","蓝牙","gpio","产品","传感器","有","开发板","最大","arm","登录","4"],"title":"旭日X3派","title_tokens":["x3","派","旭日"]},{"location":"hhp/2.1_%E6%9C%BA%E5%99%A8%E4%BA%BA%E5%BC%80%E5%8F%91%E5%A5%97%E4%BB%B6%E4%BB%8B%E7%BB%8D/#x3m","text":"在旭日X3派上，最为核心的当然就是这颗AI芯片了，这是关于芯片的具体信息，供大家参考。 值得一提的是，随着芯片的技术迭代，2023年，地平线将推出X5芯片，比较大的变化是CPU升级到了8核A55，主频提升到1.8GHz，BPU的算力也将达到8Tops，还加入了GPU，以及更多可扩展的接口。 在使用旭日X3派的过程中，大家也可以期待旭日X5派了。","text_tokens":["达到","迭代","ghz","ai","大家","接口","8tops","1.8","随着","关于","加入","这是","在","算力","也","这颗","bpu","地平线","年","多","派","地平","到","以及","x3","cpu","，","就是","技术","比较","提升","可以","升级","的","供","参考","值得","2023","变化","中","。","核心","更","主频","核","a55"," ","推出","扩展","可","gpu","期待","了","是","使用","具体","上","将","还","芯片","8","当然","值得一提的是","信息","x5","大","最为","旭日","过程"],"title":"旭日X3M芯片","title_tokens":["芯片","旭日","x3m"]},{"location":"hhp/2.1_%E6%9C%BA%E5%99%A8%E4%BA%BA%E5%BC%80%E5%8F%91%E5%A5%97%E4%BB%B6%E4%BB%8B%E7%BB%8D/#x3_2","text":"好啦，还是回到旭日X3派的开发接口上来，我们再做一个整理，这些就是我们使用开发板进行智能机器人开发过程中，最为常用的接口啦。 大家目前在树莓派或者其他开发板上使用的绝大部分模块，基本都可以在旭日X3派上复用，同时还有更多智能化的玩法等着大家。 关于40Pin扩展接口的序号排布，大家可以看这里，引脚的序号是从靠近HDMI板卡内测的开始算起，是引脚1，然后依次蛇形计数，分别是1、2、3、4、5，一直到这里是39和40。 上图是40PIN扩展接口的详细定义，有3.3V和5V的电源信号，有I2C、I2S、SPI、UART等通信接口，还有很多可动态配置的GPIO信号，基本可以满足各种各样的机器人开发啦。 好啦，关于旭日X3派这块开发板我们已经了解清楚了，具体该如何使用呢，我们后续操作起来。","text_tokens":["复用","v","分别","定义","后续","进行","大部","，","机器","绝大","详细","如何","动态","2"," ","了","具体","了解","40","算","玩法","回到","开始","最为","39","各种","目前","关于","树莓","各种各样","一个","都","多","派","各样","智能化","机器人","就是","1","板卡","绝大部分","配置","清楚","。","基本","看","再","开发","使用","还有","蛇形","着","中","排布","是从","引脚","接口","起来","序号","依次","4","、","上来","可以","我们","的","hdmi","spi","可","智能","是","这块","上","还是","计数","i2c","同时","旭日","过程","3.3","40pin","大家","等","一直","起","这里","整理","在","这些","部分","内测","很多","通信接口","呢","5v","靠近","啦","到","5","和","x3","信号","电源","通信","然后","已经","该","模块","更","i2s","大部分","3","其他","上图","扩展","或者","操作","uart","gpio","有","开发板","做","满足","好","常用"],"title":"旭日X3派接口","title_tokens":["x3","接口","派","旭日"]},{"location":"hhp/2.2_TogetherROS%E7%B3%BB%E7%BB%9F%E5%AE%89%E8%A3%85/","text":"TogetherROS系统安装 我们在旭日X3派上安装系统镜像，并进一步完成TogetherROS系统的安装，大家如果手上有旭日X3派开发板的话，建议跟随一起操作。 先来了解一下TogetherROS系统安装的整体流程： 第一步，要完成硬件的准备，我们需要找到一块旭日X3派的开发板，并且准备好电源线、SD卡、读卡器、串口模块等必要的配件，当然还需要有一台操作的电脑啦。 硬件都准备好之后，就可以进入第二步，给旭日X3派下载并安装Ubuntu系统镜像，这是TogetherROS系统运行必要的底层环境。 第三步，就可以开始安装TogetherROS啦。 安装完成后，我们还需要进一步完成一些配置工作，可以也让旭日X3派板卡上的各项功能都运行起来，保证TogetherROS的顺利运行。 最后一步，就是体验TogetherROS出厂自带的一些例程啦，确定一切安装顺利，为后续机器人开发最好准备。 接下来，我们就按照这个流程，开始操作。 硬件准备 先来完成硬件准备： 找到一块旭日X3派的板卡，准备好一套5V3A的电源和TypeC电源线，稍后会连接到这里的电源接口，给板卡供电。 然后准备好一张8GB以上的SD卡和读卡器，下一步我们会在上边烧写系统镜像。 接下来使用一个串口模块，连接旭日X3派和笔记本电脑，便于下一步看到系统镜像的启动信息。 如果大家有网线和HDMI显示器的话，也可以先准备好，在之后的操作中用的上，如果没有也没关系，不影响TogetherROS系统的基本使用。 硬件准备齐全之后，就可以进入第二步了。 安装Ubuntu系统 我们来给旭日X3派安装Ubuntu系统，关于系统镜像和烧写工具，都可以在 地平线AI社区 中找到。 下载SD卡镜像 首先登录地平线AI社区，点击”产品中心——资源中心“， 进入页面后下拉至”X3派资料包“专区，其中有两个镜像，点击下载其中的”旭日X3派系统镜像（服务版）“，会有一个压缩包，把它保存到当前电脑桌面。 此外，我们稍后将镜像烧写到SD卡里，需要用到烧写小工具，如果大家电脑上没有合适的工具，可以下拉到”工具“专区，点击下载”烧录 工具rufus\"。 下载完后我们来看一下两个压缩文件中的内容： 其中一个是烧写X3派镜像文件的工具，压缩包中有两个文件，一个是system_sdcard.img文件，是我们稍后会用于烧写SD卡的镜像文件；另一个是disk_nand.img文件，用于烧写旭日X3派中的flash文件，大多数情况下都用不到； 另一个压缩包里是我们稍后用于烧写镜像的rufus工具。 我们把两个压缩包都解压出来，然后把SD卡放进读卡器、插到电脑端 接下来就可以开始烧写SD卡镜像。 烧写SD卡镜像 运行解压出来的烧写工具rufus。启动后需要确认几个参数： 第一个是确定烧写到哪个磁盘上。工具软件会默认搜索当前读取到的SD卡，下图所示磁盘名称，就是演示时插好的16GB的SD卡。 下一步我们点击“选择”，找到需要烧写的镜像文件。演示中已经把需要的system_sdcrd.img文件放在了桌面上，选中它点击“打开”； 下面的内容就可以用默认的配置，点击“开始”会弹出警告告诉我们将把磁盘里的所有文件都清除掉，这没有问题，我们点击“选择“，就开始烧写SD卡镜像了。 进度条显示“准备就绪”后，点击“关闭”，此时你的SD卡镜像就已经烧写完成了，我们把SD卡的读卡器拔出来。 连接串口 接下来把SD卡插到旭日X3派上。 把串口模块连接到电脑的USB上。 连接好串口模块后，为了确保串口已经跟电脑连接成功、并且安装好了驱动，我们可以右键“我的电脑”图标、选择“管理”，在打开的”计算机管理“界面中找到”设备管理器——端口“，检查一下你的USB串口是否已经显示出了对应的设备。演示中的端口号为COM6,说明串口已经成功驱动了。 如果没有看到自己的设备号、或者设备号前有一个叹号或者问号标记，说明你的驱动没有安装好，可以搜索网络上的技术博客，来完成串口模块的驱动安装。 关闭“计算机管理”窗口，接下来就要通过串口与旭日X3派进行连接了。这里我们需要用到一个串口小工具，大家可以使用自己常用的工具。 演示中使用的串口工具是MobaXterm,十分推荐大家使用这个工具，里面集成了开发过程中需要使用的各种小工具，我们后续的串口通讯、SSH网络通讯，都会使用这些工具完成。 打开MobaXterm,点击左上角的\"Session\"； 找到里面的“Serial\"串口选项，点击打开；串口号选择本机连接到旭日X3派的相应端口，演示中为COM6; 波特率选择921600。选项好后点击“OK”。 现在串口已经连接成功了，但当前旭日X3派的板子还没有上电，所以没有任何信息弹出。 我们把电源线与旭日X3派连接好。 可以看到弹出了日志提醒：“当前系统正在启动”。等待系统加载完成。 现在可以看到系统已经加载成功了。 串口登录系统 接下来我们需要登录系统。我们有两个账号可以用来登录： 账号1：用户名为root，密码也为root； 账号2：用户名为storise，密码也为storise； 这里演示使用root用户来登录。输入用户名、密码，回车，需要等待大约1分钟，因为第一次登录需要展开一些系统必要的安装软件，安装好后系统会自动重启。 系统自动重启后，再次使用root用户登录。现在你的UBUNTU系统就已经安装好了。 我们可以使用LINUX系统常用的一些命令行进行查看和设置，比如ls查看当前命令，pwd查看当前路径，还可以使用mkdir命令创建文件夹，比如这里,一个test文件夹就创建成功了。 到这里为止，旭日X3派上的Ubuntu系统就安装成功啦，我们继续下一步。 安装TogetherROS系统 安装TogetherROS系统。 为了达到更好的通信效率，我们后续使用有线网络连接旭日X3派，这里大家可以拿出一根网线，直接连接电脑和旭日X3派的网口。 旭日X3派中出厂已经配置好了静态IP地址，是192.168.1.10，我们将使用的电脑也配置到同一网段即可。 配置有线网络 接下来请大家拿一根网线，连接旭日X3派和电脑。 然后，在电脑端打开控制面板，找到“查看网络状态和任务”。 找到已经连接成功的以太网，点击它； 会弹出一个窗口，我们点击“属性”。 再次弹出窗口，我们双击选择“Internet协议版本4”。 然后会弹出一个配置IP地址的窗口，我们勾选”使用下面的IP地址“。 按照如下信息填入： IP地址：192.168.1.100 子网掩码：255.255.255.0 默认网关：192.168.1.1 我们使用的旭日X3派的板子IP为192.168.1.10，所以IP后三位除了.10和网关.1以外，大家可以选用1-255之间的任意数字，这里使用.100； 填写完在所有窗口点击“确定”，最后关闭窗口。现在网络的配置就完成了，此时电脑端的静态IP就是192.168.1.100,我们通过这个IP与旭日X3派产生连接。 SSH远程登录 我们再次打开MobaXterm软件,点击左上角的\"Session\"，找到里面的\"SSH\",输入 旭日X3派板子的IP192.168.1.10，点击”OK“。 弹出登录窗口，我们用root账户登录：用户名为root，密码为root。这里会弹窗询问是否保存登录密码，如果需要保存就点“YES”，不需要保存就点“NO”。 现在我们就成功通过网络SSH协议登录到了旭日X3派板子上，和之前我们用串口登录的效果几乎是一样的，但现在我们是用网络通讯，所以现在通讯的效率和传输的速度会更高。 配置完成网络通讯后，我们来正式安装TogetherROS。 下载TogetherROS安装包 拷贝安装包 我们打开地平线社区的网站，在“产品中心”页面下拉到“机器人平台”，这里面都是TogetherROS相关的资源。 我们找到其中的\"TogetherROS DEB安装包\"，点击下载到电脑端。大概有300多兆的文件大小，很快就能下载完成。 这里我们先使用DEB安装包，来直接安装编译好的二进制文件。未来课程中我们会介绍如何通过源码编译的方式进行安装。 接下来我们进行TogetherROS镜像文件的复制安装。 安装TogetherROS 首先我们需要把电脑端的TogetherROS镜像文件，拷贝到旭日X3派板端。 大家可以在电脑上右键打开一个终端，并使用scp命令进行文件拷贝，命令格式为：scp + 空格 + .\\ + <要拷贝的文件名> + 用户名 + @ + 旭日X3派的IP地址 + :/ +旭日X3派上的文件目录名。 演示中使用的命令如下： $ scp . \\t ros_debV1_20220607894835.0.deb root@192.169.1.10:/userdata 这样就可以将TogetherROS镜像文件从电脑端拷贝到旭日X3派的userdata目录下。 除了这种拷贝方法，大家还可以使用MobaXterm软件，它提供了一种基于SCP命令的可视化的文件复制方式。 大家可以点击MobaXterm软件页面左侧的“SSH browser”，左边显示的目录就是旭日X3派板子上的文件目录结构。 我们找到板子上对应的userdata文件夹，双击打开它。 使用MobaXterm软件，可以把togetherROS镜像文件从电脑本机上直接拖到板子的文件目录底下。 现在TogetherROS安装包已经传输完成。我们在命令行中进入板子的userdata文件夹下，再确认安装包已经存放到了文件夹。命令行： $ cd /userdata/ $ ls 确认完毕后，我们用LINUX命令行dpkg进行安装，命令格式为:\"dpkg -i <要安装的包的名称>“，大家根据自己实际的版本号进行安装。此处使用命令为： $ dpkg -i tros_debV1_20220607094835.0.deb 等待安装完成，我们用命令“cd /opt\"进入opt文件夹，用ls命令检查一下该路径下的文件，可以看到opt文件夹下有一个tros文件夹，这个文件夹里就是我们刚刚安装好的TogetherROS的所有系统文件了。 如果觉得终端里看不方便，也可以使用MobaXterm软件的可视化浏览器来查看。 大家可以点击/opt/tros文件夹，看看其中的文件结构。 /include文件夹里，是我们后续会用到的关于系统的头文件的调用路径； /lib文件夹里面是库文件； /share文件夹里是安装好的功能包的路径； /src文件夹里是后续会用到的代码； /tools文件夹里是一些小工具。 除此之外，还有很多.bat,.sh脚本文件，它们是用来设置环境变量的。这是因为，你的LINUX系统不知道你安装包的路径在哪，所以需要通过环境变量的脚本来告诉系统，如何找到对应的TogetherROS的功能包、和功能包里的命令工具。 环境变量在我们后续操作里会频繁地使用到，我们会使用到一个”source\"命令来配置环境变量，例如： $ source /opt/tros/setup.bash 运行上面这行命令，就会把当前环境变量设置到系统里去；下次再运行ROS2、TogetherROS指令时，就能找到功能包的路径了。 到这里，TogetherROS也安装完成，下一节我们将对开发板和TogetherROS进行配置。","text_tokens":["烧写","桌面","dpkg","频繁","里","选中","后续","就","三步","填写","解压","会弹","网段","，","行","usb","准备就绪","有线","库","放进","拷贝","多兆","状态","压缩包","本","标记","名","通过","安装","各种","ai","供电","找到","关系","问题","ip192.168","网口","这是","搜索","警告","一个","弹出","ls","：","来","课程","root","脚本","storise","整体","基本","i","后","sd","我","debv1","端的","使用","卡里","压缩文件","\\","scp","里会","二步","正在","1.10","一张","typec","没有","中","点击","达到","合适","烧","包","设置","255.0","系统","第一步","也","此外","演示","属性","机","串","可以","把","显示器","上面","命令","三位","能","安装包","src","未来","路径","系统文件","介绍","版本","复制","下拉","空格","计算","以上","两个","进入","自己","这种","旭日","sdcrd","效率","所以","回车","$","+","一些","请","资源","自动","很多","写","拔出来","用户名","数字","知道","tools","读卡","方便","就要","基于","include","说明","根据","几乎","端","如果","serial","版","镜像文件","接下","下面","电脑","专区","关闭","此时","session","继续","询问","cd","方式","工具软件","文件","source","一根","最好","下拉至","地址","左边","左侧","mobaxterm","内容","browser","清除","网络通讯","ubuntu","静态","yes","可视","首先","工具","com6","稍后","提醒","头文件","userdata","如何","配件","选择","账户","2","哪","驱动","平台","了","等待","代码","中心","来看","必要","电源线","完成","流程","\"",".","给","disk","比如","网站","这样","之外","对应","软件","为止","拿","拉到","用户","编译","告诉","会","sdcard","ok","完毕","保证","都","派","与","完在","1","技术","掩码","配置","system","放在","。","下拉到","加载","电源接口","再","按照","第一个","；","还有","二进制","号","拔出","子网","默认","16gb","电脑桌","任务","存放","opt","制面","起来","方法","share","用来","同一","一套","其中","test","1.100","地","921600","分钟","例如","大多数","拖","ip","十分","体验","除此","启动","一台","文件夹","选用","集成","影响","自带","环境变","将","接下来","用到","手上","出来","情况","当然","磁盘","日志","因为","一次","过程","任意","界面","资料","/","下来","_","是否","下","打开","机上","时","用","啦","到","和","笔记本","x3","已经","模块","进度条","要","社区","成功","底下","不","并","网络","确保","进一步","操作","笔记","面板","可视化","刚刚","环境变量","还","波特率","但","没关","10","远程","右键","常用","服务","大约",":","1.1","名为","弹窗","它","包里","好后","此处","看到","进行","为了","前","从","串口","最后","出厂","192.168","deb",";","推荐","叹","波特","出","效果","目录","再次","了解","192.169","各项","环境","20220607894835.0","上边","开始","t","完后","哪个","之间","现在","齐全","插","派板","板卡","机器人","就是","网线","通讯","ssh","控制","高","以外","浏览","博客","对","让","一样","弹","读取","开发","里面","文件大小","100","确定","一块","第三","之前","中为","一切","（","跟随","管理器","togetherros","接口","上电","任何","除了","读卡器","rufus","internet","勾选","理器","速度","<","卡","图标","是",">","准备","上","setup","就点","以太","除此之外","一节","设备","硬件","即可","nand","大家","300","更好","左上角","—","第二","ros","就绪","上角","一步","用于","通信","下载","输入","管理","问号","更","件夹","网关","255","no","第一","第一次","不到","版本号","拿出","运行","当前","中用","bash","好","压缩","正式","参数","子网掩码","一起","页面","一种","选项","查看","双击","第二步","img","命令行","pwd","地平线","建议","口号","文件名","板子","机器","工作","网络连接","多数","浏览器","掉","并且","你","计算机","展开","账号"," ","这个","源码","去","它们","-","几个","大多","端口","提供","tros","镜像","先","之后","关于","重启","这","协议","地平","功能","计算机管理","中有","看看","看","“","flash","进制","相关","终端","下图","20220607094835.0","所示","5v3a","笔记本电脑","窗口","保存","进度","变量","电脑桌面","便于","觉得","相应","大小","顺利","名称","烧录","很快","产生","拷贝到","没关系","例程","小","是因为","端口号","、","密码","检查","）","传输","我们","第三步","的","底层","8gb","检查一下","hdmi","ip地址","填入","调用","ros2","确认","左上","信息","下次","面上","一下","另","跟","等","bat","控制面板","这里","实际","大概","在","如下","这些","结构","linux","的话","”","指令","显示","桌面上","电源","255.255","然后","格式","该","mkdir","sh","连接",",","直接","户名","为","或者","文件目录","@","lib","创建","产品","以太网","有","开发板","所有","需要","登录","4","算机"],"title":"系统安装","title_tokens":["安装","系统"]},{"location":"hhp/2.2_TogetherROS%E7%B3%BB%E7%BB%9F%E5%AE%89%E8%A3%85/#togetherros","text":"我们在旭日X3派上安装系统镜像，并进一步完成TogetherROS系统的安装，大家如果手上有旭日X3派开发板的话，建议跟随一起操作。 先来了解一下TogetherROS系统安装的整体流程： 第一步，要完成硬件的准备，我们需要找到一块旭日X3派的开发板，并且准备好电源线、SD卡、读卡器、串口模块等必要的配件，当然还需要有一台操作的电脑啦。 硬件都准备好之后，就可以进入第二步，给旭日X3派下载并安装Ubuntu系统镜像，这是TogetherROS系统运行必要的底层环境。 第三步，就可以开始安装TogetherROS啦。 安装完成后，我们还需要进一步完成一些配置工作，可以也让旭日X3派板卡上的各项功能都运行起来，保证TogetherROS的顺利运行。 最后一步，就是体验TogetherROS出厂自带的一些例程啦，确定一切安装顺利，为后续机器人开发最好准备。 接下来，我们就按照这个流程，开始操作。","text_tokens":["一起","ubuntu","第二步","后续","就","建议","三步","，","串口","机器","最后","工作","出厂","配件","并且"," ","这个","了解","各项","必要","环境","电源线","开始","完成","流程","给","镜像","安装","先","找到","之后","这是","保证","都","派","功能","：","板卡","机器人","就是","来","配置","。","整体","让","后","sd","按照","开发","确定","一块","第三","二步","一切","跟随","togetherros","起来","系统","顺利","第一步","也","例程","、","读卡器","可以","我们","第三步","的","底层","体验","一台","卡","准备","自带","上","进入","接下来","手上","当然","一下","旭日","硬件","大家","等","一些","下来","在","的话","第二","啦","x3","一步","电源","读卡","模块","下载","要","并","为","进一步","操作","如果","接下","电脑","有","第一","开发板","还","运行","需要","好","最好"],"title":"TogetherROS系统安装","title_tokens":["安装","togetherros","系统"]},{"location":"hhp/2.2_TogetherROS%E7%B3%BB%E7%BB%9F%E5%AE%89%E8%A3%85/#_1","text":"先来完成硬件准备： 找到一块旭日X3派的板卡，准备好一套5V3A的电源和TypeC电源线，稍后会连接到这里的电源接口，给板卡供电。 然后准备好一张8GB以上的SD卡和读卡器，下一步我们会在上边烧写系统镜像。 接下来使用一个串口模块，连接旭日X3派和笔记本电脑，便于下一步看到系统镜像的启动信息。 如果大家有网线和HDMI显示器的话，也可以先准备好，在之后的操作中用的上，如果没有也没关系，不影响TogetherROS系统的基本使用。 硬件准备齐全之后，就可以进入第二步了。","text_tokens":["烧写","第二步","看到","就","稍后","，","串口"," ","了","电源线","上边","完成","给","镜像","先","供电","找到","之后","关系","会","齐全","一个","派","：","板卡","网线","来","。","基本","电源接口","sd","使用","一块","5v3a","二步","笔记本电脑","一张","typec","没有","便于","togetherros","接口","系统","一套","也","没关系","读卡器","可以","我们","显示器","的","8gb","启动","hdmi","卡","影响","准备","上","以上","进入","接下来","信息","旭日","硬件","大家","这里","下来","在","的话","下","显示","第二","笔记本","到","和","x3","电源","读卡","然后","一步","模块","连接","不","操作","笔记","如果","接下","电脑","有","没关","中用","好"],"title":"硬件准备","title_tokens":["准备","硬件"]},{"location":"hhp/2.2_TogetherROS%E7%B3%BB%E7%BB%9F%E5%AE%89%E8%A3%85/#ubuntu","text":"我们来给旭日X3派安装Ubuntu系统，关于系统镜像和烧写工具，都可以在 地平线AI社区 中找到。","text_tokens":["给","镜像","安装","ai","烧","找到","系统","关于","ubuntu","在","写","地平线","工具","都","派","地平","和","x3","，","可以","我们","来","中","社区","。"," ","旭日"],"title":"安装Ubuntu系统","title_tokens":["ubuntu","安装","系统"]},{"location":"hhp/2.2_TogetherROS%E7%B3%BB%E7%BB%9F%E5%AE%89%E8%A3%85/#sd","text":"首先登录地平线AI社区，点击”产品中心——资源中心“， 进入页面后下拉至”X3派资料包“专区，其中有两个镜像，点击下载其中的”旭日X3派系统镜像（服务版）“，会有一个压缩包，把它保存到当前电脑桌面。 此外，我们稍后将镜像烧写到SD卡里，需要用到烧写小工具，如果大家电脑上没有合适的工具，可以下拉到”工具“专区，点击下载”烧录 工具rufus\"。 下载完后我们来看一下两个压缩文件中的内容： 其中一个是烧写X3派镜像文件的工具，压缩包中有两个文件，一个是system_sdcard.img文件，是我们稍后会用于烧写SD卡的镜像文件；另一个是disk_nand.img文件，用于烧写旭日X3派中的flash文件，大多数情况下都用不到； 另一个压缩包里是我们稍后用于烧写镜像的rufus工具。 我们把两个压缩包都解压出来，然后把SD卡放进读卡器、插到电脑端 接下来就可以开始烧写SD卡镜像。","text_tokens":["下拉至","服务","内容","烧写","桌面","页面","它","里","img","首先","就","地平线","工具","稍后","解压","，","多数","放进"," ","中心","压缩包","来看","大多","开始","\"",".","disk","镜像","ai","完后","拉到","会","sdcard","插","一个","都","地平","派","：","中有","system","。","下拉到","“","flash","后","sd","卡里","压缩文件","；","电脑桌","保存","没有","点击","中","（","电脑桌面","合适","包","烧","系统","烧录","此外","其中","小","、","读卡器","rufus","）","把","可以","我们","大多数","的","卡","下拉","是","上","两个","将","进入","接下来","用到","出来","情况","一下","旭日","另","nand","大家","资料","—","下来","资源","_","”","写","下","用","到","x3","用于","读卡","然后","下载","社区","端","如果","版","镜像文件","接下","产品","电脑","专区","有","不到","文件","当前","需要","登录","压缩"],"title":"下载SD卡镜像","title_tokens":["sd","下载","镜像","卡"]},{"location":"hhp/2.2_TogetherROS%E7%B3%BB%E7%BB%9F%E5%AE%89%E8%A3%85/#sd_1","text":"运行解压出来的烧写工具rufus。启动后需要确认几个参数： 第一个是确定烧写到哪个磁盘上。工具软件会默认搜索当前读取到的SD卡，下图所示磁盘名称，就是演示时插好的16GB的SD卡。 下一步我们点击“选择”，找到需要烧写的镜像文件。演示中已经把需要的system_sdcrd.img文件放在了桌面上，选中它点击“打开”； 下面的内容就可以用默认的配置，点击“开始”会弹出警告告诉我们将把磁盘里的所有文件都清除掉，这没有问题，我们点击“选择“，就开始烧写SD卡镜像了。 进度条显示“准备就绪”后，点击“关闭”，此时你的SD卡镜像就已经烧写完成了，我们把SD卡的读卡器拔出来。","text_tokens":["参数","内容","烧写","桌面","它","清除","里","选中","img","就","工具","解压","会弹","，","选择","准备就绪","掉","你","出"," ","了","几个","开始","完成",".","镜像","软件","找到","哪个","问题","告诉","会","搜索","这","插","警告","一个","都","：","就是","放在","system","配置","。","“","后","读取","sd","第一个","下图","；","确定","所示","拔出","默认","16gb","进度","点击","中","没有","烧","名称","演示","读卡器","rufus","把","可以","我们","的","启动","卡","是","准备","上","将","出来","确认","磁盘","面上","sdcrd","_","”","写","下","打开","显示","拔出来","时","用","桌面上","就绪","到","一步","已经","读卡","进度条","下面","镜像文件","关闭","第一","此时","工具软件","所有","文件","运行","当前","需要","好"],"title":"烧写SD卡镜像","title_tokens":["sd","镜像","烧写","卡"]},{"location":"hhp/2.2_TogetherROS%E7%B3%BB%E7%BB%9F%E5%AE%89%E8%A3%85/#_2","text":"接下来把SD卡插到旭日X3派上。 把串口模块连接到电脑的USB上。 连接好串口模块后，为了确保串口已经跟电脑连接成功、并且安装好了驱动，我们可以右键“我的电脑”图标、选择“管理”，在打开的”计算机管理“界面中找到”设备管理器——端口“，检查一下你的USB串口是否已经显示出了对应的设备。演示中的端口号为COM6,说明串口已经成功驱动了。 如果没有看到自己的设备号、或者设备号前有一个叹号或者问号标记，说明你的驱动没有安装好，可以搜索网络上的技术博客，来完成串口模块的驱动安装。 关闭“计算机管理”窗口，接下来就要通过串口与旭日X3派进行连接了。这里我们需要用到一个串口小工具，大家可以使用自己常用的工具。 演示中使用的串口工具是MobaXterm,十分推荐大家使用这个工具，里面集成了开发过程中需要使用的各种小工具，我们后续的串口通讯、SSH网络通讯，都会使用这些工具完成。 打开MobaXterm,点击左上角的\"Session\"； 找到里面的“Serial\"串口选项，点击打开；串口号选择本机连接到旭日X3派的相应端口，演示中为COM6; 波特率选择921600。选项好后点击“OK”。 现在串口已经连接成功了，但当前旭日X3派的板子还没有上电，所以没有任何信息弹出。 我们把电源线与旭日X3派连接好。 可以看到弹出了日志提醒：“当前系统正在启动”。等待系统加载完成。 现在可以看到系统已经加载成功了。","text_tokens":["mobaxterm","网络通讯","选项","好后","后续","看到","口号","com6","进行","工具","为了","前","提醒","串口","，","板子","usb","选择",";","推荐","叹","并且","计算机","你","波特","出"," ","驱动","这个","了","等待","本","端口","标记","电源线","通过","完成","\"","安装","各种","对应","找到","现在","会","搜索","插","ok","一个","都","弹出","派","与","：","ssh","技术","通讯","计算机管理","来","博客","。","加载","“","弹","后","sd","我","开发","里面","使用","；","号","中为","正在","窗口","没有","中","点击","管理器","相应","上电","系统","演示","任何","小","端口号","、","921600","检查","机","串","把","可以","我们","的","十分","理器","启动","检查一下","卡","图标","集成","是","计算","上","接下来","用到","左上","自己","信息","日志","设备","一下","旭日","过程","跟","所以","大家","界面","左上角","这里","—","下来","在","这些","是否","”","打开","显示","上角","到","x3","已经","电源","模块","管理","就要","问号","成功","连接",",","说明","网络","确保","为","或者","如果","serial","关闭","session","接下","电脑","有","还","波特率","但","当前","需要","右键","好","算机","常用"],"title":"连接串口","title_tokens":["串口","连接"]},{"location":"hhp/2.2_TogetherROS%E7%B3%BB%E7%BB%9F%E5%AE%89%E8%A3%85/#_3","text":"接下来我们需要登录系统。我们有两个账号可以用来登录： 账号1：用户名为root，密码也为root； 账号2：用户名为storise，密码也为storise； 这里演示使用root用户来登录。输入用户名、密码，回车，需要等待大约1分钟，因为第一次登录需要展开一些系统必要的安装软件，安装好后系统会自动重启。 系统自动重启后，再次使用root用户登录。现在你的UBUNTU系统就已经安装好了。 我们可以使用LINUX系统常用的一些命令行进行查看和设置，比如ls查看当前命令，pwd查看当前路径，还可以使用mkdir命令创建文件夹，比如这里,一个test文件夹就创建成功了。 到这里为止，旭日X3派上的Ubuntu系统就安装成功啦，我们继续下一步。","text_tokens":["大约","名为","ubuntu","查看","好后","就","命令行","pwd","进行","，","你","2","展开","账号"," ","了","等待","再次","必要","比如","安装","软件","为止","现在","重启","用户","会","一个","ls","派","：","1","来","root","。","storise","后","；","使用","设置","系统","用来","也","演示","test","、","密码","分钟","可以","我们","的","命令","路径","文件夹","上","两个","接下来","因为","一次","旭日","回车","一些","这里","下来","自动","linux","下","用户名","啦","到","和","x3","已经","一步","mkdir","输入","成功",",","户名","件夹","为","创建","接下","有","第一","第一次","继续","还","文件","当前","需要","登录","好","常用"],"title":"串口登录系统","title_tokens":["登录","串口","系统"]},{"location":"hhp/2.2_TogetherROS%E7%B3%BB%E7%BB%9F%E5%AE%89%E8%A3%85/#togetherros_1","text":"安装TogetherROS系统。 为了达到更好的通信效率，我们后续使用有线网络连接旭日X3派，这里大家可以拿出一根网线，直接连接电脑和旭日X3派的网口。 旭日X3派中出厂已经配置好了静态IP地址，是192.168.1.10，我们将使用的电脑也配置到同一网段即可。","text_tokens":["达到","安装","togetherros","效率","大家","地址","系统","同一","更好","这里","网口","静态","也","后续","即可","为了","派","到","和","x3","网线","通信","，","可以","已经","我们","出厂","网络连接","的","网段","中","配置","192.168","。","有线","连接","直接","网络","ip地址"," ","了","使用","是","电脑","将","拿出","1.10","一根","好","旭日","."],"title":"安装TogetherROS系统","title_tokens":["安装","togetherros","系统"]},{"location":"hhp/2.2_TogetherROS%E7%B3%BB%E7%BB%9F%E5%AE%89%E8%A3%85/#_4","text":"接下来请大家拿一根网线，连接旭日X3派和电脑。 然后，在电脑端打开控制面板，找到“查看网络状态和任务”。 找到已经连接成功的以太网，点击它； 会弹出一个窗口，我们点击“属性”。 再次弹出窗口，我们双击选择“Internet协议版本4”。 然后会弹出一个配置IP地址的窗口，我们勾选”使用下面的IP地址“。 按照如下信息填入： IP地址：192.168.1.100 子网掩码：255.255.255.0 默认网关：192.168.1.1 我们使用的旭日X3派的板子IP为192.168.1.10，所以IP后三位除了.10和网关.1以外，大家可以选用1-255之间的任意数字，这里使用.100； 填写完在所有窗口点击“确定”，最后关闭窗口。现在网络的配置就完成了，此时电脑端的静态IP就是192.168.1.100,我们通过这个IP与旭日X3派产生连接。","text_tokens":["子网掩码","地址","1.1","它","静态","查看","双击","就","填写","会弹","，","板子","最后","192.168","选择","出"," ","这个","了","再次","状态","-","通过","完成",".","找到","拿","之间","现在","一个","协议","派","完在","与","：","网线","控制","1","掩码","就是","以外","配置","。","“","弹","后","按照","端的","；","使用","100","确定","子网","1.10","任务","窗口","默认","点击","制面","255.0","产生","1.100","除了","属性","可以","internet","我们","勾选","的","ip","三位","版本","ip地址","选用","填入","接下来","以太","信息","旭日","任意","所以","大家","请","控制面板","这里","下来","在","如下","”","打开","数字","和","x3","已经","255.255","然后","成功","连接",",","网络","网关","为","端","255","面板","下面","关闭","接下","以太网","电脑","此时","所有","10","一根","4"],"title":"配置有线网络","title_tokens":["网络","有线","配置"]},{"location":"hhp/2.2_TogetherROS%E7%B3%BB%E7%BB%9F%E5%AE%89%E8%A3%85/#ssh","text":"我们再次打开MobaXterm软件,点击左上角的\"Session\"，找到里面的\"SSH\",输入 旭日X3派板子的IP192.168.1.10，点击”OK“。 弹出登录窗口，我们用root账户登录：用户名为root，密码为root。这里会弹窗询问是否保存登录密码，如果需要保存就点“YES”，不需要保存就点“NO”。 现在我们就成功通过网络SSH协议登录到了旭日X3派板子上，和之前我们用串口登录的效果几乎是一样的，但现在我们是用网络通讯，所以现在通讯的效率和传输的速度会更高。 配置完成网络通讯后，我们来正式安装TogetherROS。","text_tokens":["mobaxterm","名为","弹窗","网络通讯","yes","就","，","板子","串口","账户","出"," ","了","效果","再次","通过","完成","\"",".","安装","软件","找到","现在","ip192.168","用户","会","ok","协议","派","：","ssh","通讯","高","来","root","配置","。","“","一样","弹","后","里面","之前","1.10","窗口","保存","点击","togetherros","密码","传输","我们","的","速度","是","上","就点","左上","旭日","效率","所以","左上角","这里","是否","”","打开","用","上角","到","和","x3","输入","成功","更",",","不","网络","为","几乎","no","如果","session","询问","但","需要","登录","正式"],"title":"SSH远程登录","title_tokens":["登录","ssh","远程"]},{"location":"hhp/2.2_TogetherROS%E7%B3%BB%E7%BB%9F%E5%AE%89%E8%A3%85/#togetherros_2","text":"","text_tokens":[],"title":"下载TogetherROS安装包","title_tokens":["安装包","下载","安装","togetherros"]},{"location":"hhp/2.2_TogetherROS%E7%B3%BB%E7%BB%9F%E5%AE%89%E8%A3%85/#_5","text":"我们打开地平线社区的网站，在“产品中心”页面下拉到“机器人平台”，这里面都是TogetherROS相关的资源。 我们找到其中的\"TogetherROS DEB安装包\"，点击下载到电脑端。大概有300多兆的文件大小，很快就能下载完成。 这里我们先使用DEB安装包，来直接安装编译好的二进制文件。未来课程中我们会介绍如何通过源码编译的方式进行安装。 接下来我们进行TogetherROS镜像文件的复制安装。","text_tokens":["镜像","togetherros","安装","先","\"","找到","300","大小","页面","拉到","这里","大概","资源","在","编译","很快","会","这","”","其中","就","打开","地平线","都","进行","地平","到","机器人","，","机器","我们","来","下载","的","课程","如何","deb","中","社区","能","。","下拉到","安装包","直接","“","未来","进制","介绍","相关"," ","下拉","端","复制","平台","多兆","里面","是","文件大小","使用","源码","接下","产品","电脑","下来","有","二进制","镜像文件","中心","接下来","方式","文件","通过","好","完成","点击","网站"],"title":"拷贝安装包","title_tokens":["安装包","安装","拷贝"]},{"location":"hhp/2.2_TogetherROS%E7%B3%BB%E7%BB%9F%E5%AE%89%E8%A3%85/#togetherros_3","text":"首先我们需要把电脑端的TogetherROS镜像文件，拷贝到旭日X3派板端。 大家可以在电脑上右键打开一个终端，并使用scp命令进行文件拷贝，命令格式为：scp + 空格 + .\\ + <要拷贝的文件名> + 用户名 + @ + 旭日X3派的IP地址 + :/ +旭日X3派上的文件目录名。 演示中使用的命令如下： $ scp . \\t ros_debV1_20220607894835.0.deb root@192.169.1.10:/userdata 这样就可以将TogetherROS镜像文件从电脑端拷贝到旭日X3派的userdata目录下。 除了这种拷贝方法，大家还可以使用MobaXterm软件，它提供了一种基于SCP命令的可视化的文件复制方式。 大家可以点击MobaXterm软件页面左侧的“SSH browser”，左边显示的目录就是旭日X3派板子上的文件目录结构。 我们找到板子上对应的userdata文件夹，双击打开它。 使用MobaXterm软件，可以把togetherROS镜像文件从电脑本机上直接拖到板子的文件目录底下。 现在TogetherROS安装包已经传输完成。我们在命令行中进入板子的userdata文件夹下，再确认安装包已经存放到了文件夹。命令行： $ cd /userdata/ $ ls 确认完毕后，我们用LINUX命令行dpkg进行安装，命令格式为:\"dpkg -i <要安装的包的名称>“，大家根据自己实际的版本号进行安装。此处使用命令为： $ dpkg -i tros_debV1_20220607094835.0.deb 等待安装完成，我们用命令“cd /opt\"进入opt文件夹，用ls命令检查一下该路径下的文件，可以看到opt文件夹下有一个tros文件夹，这个文件夹里就是我们刚刚安装好的TogetherROS的所有系统文件了。 如果觉得终端里看不方便，也可以使用MobaXterm软件的可视化浏览器来查看。 大家可以点击/opt/tros文件夹，看看其中的文件结构。 /include文件夹里，是我们后续会用到的关于系统的头文件的调用路径； /lib文件夹里面是库文件； /share文件夹里是安装好的功能包的路径； /src文件夹里是后续会用到的代码； /tools文件夹里是一些小工具。 除此之外，还有很多.bat,.sh脚本文件，它们是用来设置环境变量的。这是因为，你的LINUX系统不知道你安装包的路径在哪，所以需要通过环境变量的脚本来告诉系统，如何找到对应的TogetherROS的功能包、和功能包里的命令工具。 环境变量在我们后续操作里会频繁地使用到，我们会使用到一个”source\"命令来配置环境变量，例如： $ source /opt/tros/setup.bash 运行上面这行命令，就会把当前环境变量设置到系统里去；下次再运行ROS2、TogetherROS指令时，就能找到功能包的路径了。 到这里，TogetherROS也安装完成，下一节我们将对开发板和TogetherROS进行配置。","text_tokens":["地址","左边","左侧",":","mobaxterm","browser","它","一种","页面","包里","dpkg","频繁","查看","双击","此处","里","可视","后续","首先","就","命令行","看到","工具","进行","文件名","从","头文件","，","userdata","板子","行","如何","deb","库","浏览器","你","哪"," ","这个","拷贝","了","等待","目录","去","代码","它们","-","192.169","本","环境","名","20220607894835.0","提供","tros","t","完成","通过","这样",".","\"","镜像","之外","安装","对应","软件","找到","现在","关于","用户","告诉","会","这","完毕","一个","派","ls","功能","派板","：","ssh","就是","浏览","来","对","root","配置","脚本","。","看看","看","“","再","i","后","终端","开发","debv1","里面","端的","使用","\\","；","还有","scp","里会","1.10","变量","点击","中","存放","opt","togetherros","觉得","包","设置","方法","系统","share","用来","名称","也","拷贝到","演示","其中","小","是因为","除了","、","地","例如","检查","把","可以","传输","我们","拖","的","上面","命令","能","安装包","src","除此","路径","检查一下","系统文件","文件夹","版本","ip地址","<","复制","空格",">","是","环境变","上","setup","将","进入","调用","用到","ros2","确认","除此之外","自己","一节","下次","因为","这种","旭日","一下","所以","大家","$","+","一些","bat","这里","/","在","如下","结构","_","linux","”","很多","下","打开","用户名","显示","机上","知道","ros","用","指令","tools","时","到","和","x3","已经","格式","该","sh","方便","要",",","基于","直接","户名","件夹","底下","不","并","根据","include","为","端","文件目录","@","lib","20220607094835.0","可视化","如果","镜像文件","刚刚","操作","电脑","有","cd","环境变量","开发板","还","方式","版本号","所有","文件","运行","bash","需要","source","右键","实际","当前","好"],"title":"安装TogetherROS","title_tokens":["安装","togetherros"]},{"location":"hhp/2.3_TogetherROS%E7%B3%BB%E7%BB%9F%E9%85%8D%E7%BD%AE/","text":"TogetherROS系统配置 无论是旭日X3派，还是TogetherROS，在正式使用之前，都还需要进行一些必要的配置，完善必要的功能模块，提供完整的算力支持，达到最佳状态。 网络连接 第一个配置，是无线网络连接。 当然，大家也可以直接用网线连接旭日X3派和一个可以上网的路由器，不过更多时候，我们还是会使用无线网络来上网。 我们打开MobaXterm,选择SSH，使用root用户登录板卡；如果之前登录过板卡、还没有关闭的话，也可以继续使用。 现在我们可以通过命令行搜索周边环境有哪些WIFI信号，命令如下： $ sudo nmcli device wifi rescan #扫描当前环境里所有WIFI名称，但扫描结果不会显示 $ nmcli device wifi list #显示扫描到的WIFI名称 $ sudo nmcli device wifi connect <账号> password <密码> #连接WIFI $ sudo vim /etc/network/interfaces #修改DHCP配置 比如，我的办公室里wifi的名称是psmicro,我们就可以使用“sudo nmcli device wifi connect psmicro password <密码>”来连接。 等到终端返回信息“successfully activated\",就说明WIFI连接成功； 我们可以Ping古月居的网址，来检查一下连接。如果能够Ping通，就说明网络已经连接成功，现在就可以成功连接到互联网，进行后续的软件下载和更新了。 网络配置完成后，在后续开发中，大家就可以直接下载或更新各种软件包了。 系统更新 第二个配置，是更新当前旭日X3派所使用的Ubuntu镜像，和在电脑上使用的命令相同。 我们更新一下当前的系统镜像： $ sudo apt update #会按照当前软件源的域名设置去连接远程软件源 $ sudo apt full-upgrade #升级所有可以升级的软件包 弹出如下对话，我们选择“Y”，回车； 这样我们就完成了对系统更新的检查，并安装好了更新包。 CPU调频策略 第三个配置，设置CPU的调频策略，这是一个可选项，大家了解之后，在未来需要使用的时候进行配置即可。 动态调频 $ echo > ondemand /sys/devices/system/cpu/cpufreq/policy0/scaling_governor #让系统根据当前负载，动态调整CPU频率 满频模式 $ echo > performance /sys/devices/system/cpu/cpufreq/policy0/scaling_governor #让CPU始终以满频，也就1.2GHz的频率工作 打开超频 $ echo 1 > /sys/devices/system/cpu/cpufreq/boost #使CPU以超频，也就是1.5GHz的频率工作 关闭超频 $ echo 0 > /sys/devices/system/cpu/cpufreq/boost 这里CPU频率为，满频模式：1.2GHz，超频模式：1.5GHz。 大家需要注意，默认的系统配置是关闭超频、并且动态调频的配置。这样可以比较好地保证功率最优。 安装ROS2功能包 接下来，还有一个很重要的配置，那就是安装ROS2功能包，我们说TogetherROS是基于ROS2深度优化的，很多模块还是会复用ROS2中的功能，所有ROS2的原生功能也可以支持，这里我们就把ROS2必要的功能包都安装一下，让系统的功能模块更加完整。 熟悉ROS2的同学，应该对这些指令并不陌生，和ROS2官方手册中的安装步骤一致，不过还是建议大家跟着课程的步骤一起来安装一下。 添加ROS2源 第一步我们需要更新系统软件源，并安装必要的下载工具。 $ sudo apt update && sudo apt install curl gnupg lsb-release #更新软件源 $ sudo curl -sSL https://raw.githubusercontent.com/ros/rosdistro/master/ros.key -o /usr/share/keyrings/ros-archive-keyring.gpg #设置ROS2软件源秘钥 $ echo \"deb [arch= $( dpkg --print-architecture ) signed-by=/usr/share/keyrings/ros-archive-keyring.gpg] http://packages.ros.org/ros2/ubuntu $( source /etc/os-release && echo $UBUNTU_CODENAME ) main\" | sudo tee /etc/apt/sources.list.d/ros2.list > /dev/null #设置ROS2软件源 Attention 大部分国内开发者在这都会遇到同一个问题：网址无法连接。解决方案可以参考古月居官网上的这篇帖子： 《解决”Failed to connect to raw.githubusercontent.com“报错》 安装ROS2包 $ sudo apt update #更新软件源 $ sudo apt install ros-foxy-ros-base ros-foxy-demo-nodes-cpp # 安装ROS2功能包 时间会有些长，需要稍微等待一下。 现在ROS2就安装完成了。 大家可以使用同样的命令，继续安装ROS2中的更多功能包。 这里推荐大家先安装ROS2之后会使用到的编译器，比如python3-colcon-common-extensions。我们后续一些TogetherROS功能包的编译，也会使用python3-colcon-common的命令来安装。 $ sudo apt install python3-colcon-common-extensions # ROS2编译器 另外，我们推荐大家安装一个git工具，大家可以通过它下载GitHub、GitLab上的软件包，我们后续也会用到。安装命令为本小节代码第四行。 $ sudo apt install git # 安装git工具 到这里，我们常用的软件和功能包就安装完成了。我们可以看到，在旭日X3派文件目录/opt底下，除了之前的/tros文件夹外，还多出来一个/ros文件夹，里面就是我们刚才安装好的ros-foxy版本的所有系统文件。 如果大家要使用ROS2的功能包，也需要source里面的.bash或者.bat脚本文件。 建立软链接 为了方便我们在TogetherROS系统李调用ROS2的功能，在TogetherROS里提供了一个叫create_soft_link创建软链接的脚本，它而已通过软链接，把ROS2的环境变量链接到当前TogetherROS的环境包里来。执行以下命令： $ cd /opt/tros ## 使用/opt/tros目录下的create_soft_link.py创建ROS package至TogetherROS的软链接 $ python3 create_soft_link.py --foxy /opt/ros/foxy/ --tros /opt/tros 这样设置以后，假如你source了TogetherROS的环境变量，那么同样的配置也会对ROS2生效。 好啦，到这里为止，所有必要的配置项我们都做完了，是不是有点迫不及待想要使用TogetherROS了呢？","text_tokens":["soft","周边环境","tee","dpkg","里","activated","后续","就","以后","是不是","线网","网址","，","？","有点","attention","重要","ping","|","状态","通过","create","上网","安装","各种","1.5","d","问题","这是","搜索","by","网上","无线","一个","usr","返回","可选项","：","相同","无线网络","来","课程","root","脚本","应该","同样","后","我","[","使用","源","第四","colcon","外","没有","中","达到","模式","设置","包","系统","最优","系统软件","第一步","也","完善","深度","对系统","可以","把","命令","o","sys","未来","系统文件","链接","版本","办公室","archive","不是","跟着","策略","--","那么","旭日","叫","长","$","回车","一些","生效","nodes","呢","官方","超频","很多","很","http","cpufreq","信号","优化","cpu","方便","]","软件包","基于","说明","根据","https","governor","如果","关闭","接下","电脑","熟悉","继续","cd","文件","做","三个","source","》","第三个","方案","稍微","执行","能够","raw","=","mobaxterm","这篇","wifi","ubuntu","等到","工具","gitlab","to","原生","(","选择","软","手册","了","等待","代码","nmcli","编译器","必要","或","master","达到最佳","完成","\"","这样",".","那","比如","packages","报错","&&","软件","为止","org","用户","编译","会","域名","保证","都","##","codename","派","1","配置","system","rosdistro","。","device","完","install","无法","按照","第一个","base","；","还有","py","默认","四行","添加","opt","package","y","负载","起来","share","同一","地","古月","null","os","开发者","结果","文件夹","gpg","系统配置","环境变","迫不及待","接下来","用到","为本","出来","当然","可选","路由器","psmicro","更加","秘钥","路由","/","下来","_","频率","步骤","下","打开","下载工具","list","公室","用","啦","到","和","x3","已经","模块","升级","ssl","要","成功","dev","底下","不","com","网络","并","lsb","foxy","二个","环境变量","还","但","第二个","远程","而已","successfully","常用","devices","所",":","国内","它","包里","算力","满频","不过","注意","看到","进行","为了","建立","功能模块","deb","0","推荐","不及","同一个","动态","统配","包都","出","cpp","common","目录","有些","了解","环境","另外","功率","policy0","哪些","现在",")","network","解决","git","网线","ssh","板卡","就是","第四行","对","full","让","弹","etc","开发","里面","第三","之前","调频","togetherros","以","无线网","时间","一致","update","#","rescan","除了","一","apt","互联网","参考","居官","<","假如","办公","是",">","上","完整","系统配","vim","performance","无论","无论是","即可","ghz","demo","大家","key","李","第二","解决方案","ros","githubusercontent","过","一步","下载","陌生","始终","更","件夹","大部分","signed","扫描","第一","支持","当前","bash","好","周边","正式","复用","echo","多功能","选项","命令行","建议","最佳","sources","大部","网络连接","sudo","工作","至","并且","你","账号","刚才"," ","《","去","以下","-","提供","tros","github","镜像","failed","项","先","之后","boost","arch","keyrings","这","通","多","功能","architecture","link","互联","小节","“","更新包","终端","upgrade","print","password","变量","1.2","gnupg","时候","名称","联网","extensions","main","、","密码","检查","遇到","keyring","release","比较","dhcp","不会","我们","以满频","的","connect","curl","检查一下","同学","还是","调用","想要","ros2","调整","信息","ondemand","一下","帖子","bat","这里","在","如下","这些","部分","的话","”","指令","显示","python3","对话","使","interfaces","连接",",","直接","scaling","为","文件目录","或者","创建","更新","有","修改","居","所有","需要","登录","说"],"title":"系统配置","title_tokens":["统配","系统","系统配","系统配置","配置"]},{"location":"hhp/2.3_TogetherROS%E7%B3%BB%E7%BB%9F%E9%85%8D%E7%BD%AE/#togetherros","text":"无论是旭日X3派，还是TogetherROS，在正式使用之前，都还需要进行一些必要的配置，完善必要的功能模块，提供完整的算力支持，达到最佳状态。","text_tokens":["达到","togetherros","提供","一些","在","算力","完善","都","进行","最佳","派","功能","x3","，","模块","的","功能模块","配置","。","使用","还是","无论是","状态","之前","还","必要","完整","支持","需要","无论","达到最佳","旭日","正式"],"title":"TogetherROS系统配置","title_tokens":["togetherros","统配","系统","系统配","系统配置","配置"]},{"location":"hhp/2.3_TogetherROS%E7%B3%BB%E7%BB%9F%E9%85%8D%E7%BD%AE/#_1","text":"第一个配置，是无线网络连接。 当然，大家也可以直接用网线连接旭日X3派和一个可以上网的路由器，不过更多时候，我们还是会使用无线网络来上网。 我们打开MobaXterm,选择SSH，使用root用户登录板卡；如果之前登录过板卡、还没有关闭的话，也可以继续使用。 现在我们可以通过命令行搜索周边环境有哪些WIFI信号，命令如下： $ sudo nmcli device wifi rescan #扫描当前环境里所有WIFI名称，但扫描结果不会显示 $ nmcli device wifi list #显示扫描到的WIFI名称 $ sudo nmcli device wifi connect <账号> password <密码> #连接WIFI $ sudo vim /etc/network/interfaces #修改DHCP配置 比如，我的办公室里wifi的名称是psmicro,我们就可以使用“sudo nmcli device wifi connect psmicro password <密码>”来连接。 等到终端返回信息“successfully activated\",就说明WIFI连接成功； 我们可以Ping古月居的网址，来检查一下连接。如果能够Ping通，就说明网络已经连接成功，现在就可以成功连接到互联网，进行后续的软件下载和更新了。 网络配置完成后，在后续开发中，大家就可以直接下载或更新各种软件包了。","text_tokens":["周边环境","能够","mobaxterm","wifi","不过","里","activated","后续","命令行","就","等到","进行","线网","网址","，","sudo","选择","账号"," ","了","ping","nmcli","环境","或","通过","完成","\"","比如","上网","各种","软件","哪些","现在","用户","会","搜索","network","无线","一个","通","多","派","返回","：","网线","ssh","板卡","无线网络","来","root","配置","互联","。","device","“","etc","我","终端","第一个","后","开发","使用","；","之前","password","没有","中","无线网","时候","名称","联网","#","也","rescan","、","密码","古月","检查","可以","dhcp","不会","我们","互联网","的","connect","命令","结果","检查一下","<","办公室","办公","是",">","还是","当然","vim","信息","旭日","一下","路由器","psmicro","大家","$","路由","/","在","如下","的话","”","打开","显示","list","公室","用","信号","到","和","interfaces","x3","过","已经","下载","成功","连接","更",",","软件包","直接","网络","说明","扫描","如果","关闭","更新","第一","继续","有","修改","还","居","所有","但","当前","登录","周边","successfully"],"title":"网络连接","title_tokens":["网络连接","连接","网络"]},{"location":"hhp/2.3_TogetherROS%E7%B3%BB%E7%BB%9F%E9%85%8D%E7%BD%AE/#_2","text":"第二个配置，是更新当前旭日X3派所使用的Ubuntu镜像，和在电脑上使用的命令相同。 我们更新一下当前的系统镜像： $ sudo apt update #会按照当前软件源的域名设置去连接远程软件源 $ sudo apt full-upgrade #升级所有可以升级的软件包 弹出如下对话，我们选择“Y”，回车； 这样我们就完成了对系统更新的检查，并安装好了更新包。","text_tokens":["镜像","安装","所","设置","$","软件","y","回车","系统","这样","update","ubuntu","在","#","会","域名","如下","”","就","第二","对系统","派","apt","对话","和","：","x3","相同","，","可以","检查","我们","升级","的","sudo","命令","配置","选择","。","连接","full","软件包","“","并","弹","出","更新包","二个"," ","按照","upgrade","是","使用","；","源","去","了","更新","电脑","上","-","所有","第二个","一下","当前","远程","好","完成","旭日"],"title":"系统更新","title_tokens":["更新","系统"]},{"location":"hhp/2.3_TogetherROS%E7%B3%BB%E7%BB%9F%E9%85%8D%E7%BD%AE/#cpu","text":"第三个配置，设置CPU的调频策略，这是一个可选项，大家了解之后，在未来需要使用的时候进行配置即可。 动态调频 $ echo > ondemand /sys/devices/system/cpu/cpufreq/policy0/scaling_governor #让系统根据当前负载，动态调整CPU频率 满频模式 $ echo > performance /sys/devices/system/cpu/cpufreq/policy0/scaling_governor #让CPU始终以满频，也就1.2GHz的频率工作 打开超频 $ echo 1 > /sys/devices/system/cpu/cpufreq/boost #使CPU以超频，也就是1.5GHz的频率工作 关闭超频 $ echo 0 > /sys/devices/system/cpu/cpufreq/boost 这里CPU频率为，满频模式：1.2GHz，超频模式：1.5GHz。 大家需要注意，默认的系统配置是关闭超频、并且动态调频的配置。这样可以比较好地保证功率最优。","text_tokens":["devices","echo","选项","满频","注意","就","进行","，","工作","0","动态","并且","统配"," ","了解","这样","1.5","功率","policy0","之后","boost","好","这是","保证","一个","可选项","：","1","就是","配置","system","。","让","使用","第三","调频","默认","1.2","模式","设置","以","负载","系统","最优","时候","#","也","、","地","可以","以满频","比较","的","sys","未来",">","系统配置","是","调整","系统配","performance","ondemand","策略","可选","即可","ghz","大家","$","这里","/","在","_","频率","超频","打开","cpufreq","使","cpu","始终","scaling","根据","governor","为","关闭","三个","需要","当前","第三个"],"title":"CPU调频策略","title_tokens":["cpu","策略","调频"]},{"location":"hhp/2.3_TogetherROS%E7%B3%BB%E7%BB%9F%E9%85%8D%E7%BD%AE/#ros2","text":"接下来，还有一个很重要的配置，那就是安装ROS2功能包，我们说TogetherROS是基于ROS2深度优化的，很多模块还是会复用ROS2中的功能，所有ROS2的原生功能也可以支持，这里我们就把ROS2必要的功能包都安装一下，让系统的功能模块更加完整。 熟悉ROS2的同学，应该对这些指令并不陌生，和ROS2官方手册中的安装步骤一致，不过还是建议大家跟着课程的步骤一起来安装一下。","text_tokens":["那","复用","安装","togetherros","更加","大家","包","起来","系统","一致","这里","下来","也","会","这些","官方","很多","很","就","深度","指令","一个","步骤","不过","建议","一","原生","功能","优化","和","，","就是","可以","把","我们","模块","的","对","课程","功能模块","配置","。","陌生","基于","让","不","并","应该","手册","包都","重要"," ","同学","是","还有","接下","熟悉","还是","接下来","ros2","跟着","所有","必要","支持","一下","完整","说","中"],"title":"安装ROS2功能包","title_tokens":["包","安装","ros2","功能"]},{"location":"hhp/2.3_TogetherROS%E7%B3%BB%E7%BB%9F%E9%85%8D%E7%BD%AE/#ros2_1","text":"第一步我们需要更新系统软件源，并安装必要的下载工具。 $ sudo apt update && sudo apt install curl gnupg lsb-release #更新软件源 $ sudo curl -sSL https://raw.githubusercontent.com/ros/rosdistro/master/ros.key -o /usr/share/keyrings/ros-archive-keyring.gpg #设置ROS2软件源秘钥 $ echo \"deb [arch= $( dpkg --print-architecture ) signed-by=/usr/share/keyrings/ros-archive-keyring.gpg] http://packages.ros.org/ros2/ubuntu $( source /etc/os-release && echo $UBUNTU_CODENAME ) main\" | sudo tee /etc/apt/sources.list.d/ros2.list > /dev/null #设置ROS2软件源 Attention 大部分国内开发者在这都会遇到同一个问题：网址无法连接。解决方案可以参考古月居官网上的这篇帖子： 《解决”Failed to connect to raw.githubusercontent.com“报错》","text_tokens":["echo",":","raw","=","国内","tee","这篇","dpkg","ubuntu","工具","to","网址","sources","大部","，","(","sudo","deb","同一个","attention"," ","《","|","-","必要","master","\"",".","报错","packages","安装","&&","d","failed","软件","arch","问题","org","keyrings",")","会","这","by","解决","网上","一个","usr","都","codename","：","architecture","rosdistro","。","“","install","[","etc","无法","开发","源","print","gnupg","设置","系统","share","同一","update","系统软件","第一步","#","main","apt","null","遇到","古月","keyring","release","可以","我们","的","参考","connect","o","os","开发者","居官","curl","archive","gpg",">","ros2","--","秘钥","key","$","帖子","/","在","部分","http","_","”","下载工具","list","解决方案","ros","githubusercontent","一步","ssl","下载","]","dev","连接","com","大部分","并","lsb","signed","https","更新","第一","需要","source","》","方案"],"title":"添加ROS2源","title_tokens":["ros2","源","添加"]},{"location":"hhp/2.3_TogetherROS%E7%B3%BB%E7%BB%9F%E9%85%8D%E7%BD%AE/#ros2_2","text":"$ sudo apt update #更新软件源 $ sudo apt install ros-foxy-ros-base ros-foxy-demo-nodes-cpp # 安装ROS2功能包 时间会有些长，需要稍微等待一下。 现在ROS2就安装完成了。 大家可以使用同样的命令，继续安装ROS2中的更多功能包。 这里推荐大家先安装ROS2之后会使用到的编译器，比如python3-colcon-common-extensions。我们后续一些TogetherROS功能包的编译，也会使用python3-colcon-common的命令来安装。 $ sudo apt install python3-colcon-common-extensions # ROS2编译器 另外，我们推荐大家安装一个git工具，大家可以通过它下载GitHub、GitLab上的软件包，我们后续也会用到。安装命令为本小节代码第四行。 $ sudo apt install git # 安装git工具 到这里，我们常用的软件和功能包就安装完成了。我们可以看到，在旭日X3派文件目录/opt底下，除了之前的/tros文件夹外，还多出来一个/ros文件夹，里面就是我们刚才安装好的ros-foxy版本的所有系统文件。 如果大家要使用ROS2的功能包，也需要source里面的.bash或者.bat脚本文件。","text_tokens":["稍微","多功能","它","后续","就","看到","工具","gitlab","，","sudo","推荐","刚才"," ","cpp","了","等待","common","目录","代码","有些","-","编译器","另外","tros","通过","完成",".","github","比如","安装","先","软件","之后","现在","编译","会","git","一个","多","派","功能","就是","第四行","来","脚本","。","小节","同样","install","base","里面","使用","源","第四","colcon","之前","四行","外","中","opt","togetherros","包","系统","时间","update","extensions","#","也","除了","、","apt","可以","我们","的","命令","系统文件","文件夹","版本","上","用到","ros2","为本","出来","一下","旭日","demo","长","大家","$","一些","bat","这里","/","nodes","在","python3","ros","到","和","x3","下载","要","更","软件包","底下","件夹","foxy","文件目录","或者","如果","更新","继续","还","所有","文件","bash","需要","source","好","常用"],"title":"安装ROS2包","title_tokens":["包","安装","ros2"]},{"location":"hhp/2.3_TogetherROS%E7%B3%BB%E7%BB%9F%E9%85%8D%E7%BD%AE/#_3","text":"为了方便我们在TogetherROS系统李调用ROS2的功能，在TogetherROS里提供了一个叫create_soft_link创建软链接的脚本，它而已通过软链接，把ROS2的环境变量链接到当前TogetherROS的环境包里来。执行以下命令： $ cd /opt/tros ## 使用/opt/tros目录下的create_soft_link.py创建ROS package至TogetherROS的软链接 $ python3 create_soft_link.py --foxy /opt/ros/foxy/ --tros /opt/tros 这样设置以后，假如你source了TogetherROS的环境变量，那么同样的配置也会对ROS2生效。 好啦，到这里为止，所有必要的配置项我们都做完了，是不是有点迫不及待想要使用TogetherROS了呢？","text_tokens":["soft","执行","它","包里","里","以后","是不是","为了","，","？","有点","至","软","不及","你"," ","了","目录","以下","必要","环境","tros","提供","通过","这样","create",".","项","为止","会","一个","##","都","功能","：","link","来","对","配置","脚本","。","完","同样","使用","py","变量","opt","togetherros","设置","package","系统","也","把","我们","的","命令","链接","假如","不是","环境变","迫不及待","调用","想要","ros2","那么","--","叫","$","李","生效","这里","/","在","呢","_","下","python3","ros","啦","到","方便","foxy","创建","cd","环境变量","所有","做","当前","而已","source","好"],"title":"建立软链接","title_tokens":["链接","软","建立"]},{"location":"hhp/2.4_TogetherROS%E7%A4%BA%E4%BE%8B%E8%BF%90%E8%A1%8C/","text":"TogetherROS示例运行 接下来，我们就在安装配置好TogetherROS的旭日X3派上，试一试系统自带的一些例程，确保整个系统已经可以正常运行。 通信测试 先来测试一下TogetherROS系统的通信功能。 我们需要启动两个终端，分别连接到旭日X3派上，并分别按以下命令配置环境变量。 终端1： $ source /opt/tros/local_setup.bash $ ros2 run examples_rclcpp_minimal_publisher publisher_member_function 终端2： $ source /opt/tros/local_setup.bash $ ros2 run examples_rclcpp_minimal_subscriber subscriber_member_function 接下来，我们用ros2 run命令运行节点： 运行第一个例程： ros2 run example_rclcpp_minimal_publisher publisher_member_function 这是一个用C++写的最小化的发布者程序，其中节点叫publisher_member+function，按回车运行该节点。 可以看到这个节点开始不断循环发布信息，每次发布的信息为字符串形式，内容是“Hello,world! +数字”。 同样，在终端2的命令行窗口，输入以下命令并回车开启订阅者节点。 ros2 run examples_rclcpp_minimal_subscriber subscriber_member_function 这个订阅者节点会获取到、并显示出刚才发布者节点发布的信息。 通过这样一个例程，我们验证了两个节点之间的通信没有问题。这这是一个基于DDS的话题通信。 按CTRL+C可以关闭该例程。 通信系统没有问题了，如果你是一个ROS2的开发者，可能对刚才我们使用的ROS2命令比较熟悉，这时你可能也会产生一个问题：我们之前也安装了ROS2系统，那ROS2的原生功能还可以正常运行么？ 我们再来试一试ROS2中自带的一个例程。 和刚才一样打开两个终端，这里我们需要source一下ROS里的环境变量。该环境变量我们刚才已经设置了过软连接，所以配置过程中它也会配置ROS2的功能包路径。 在终端1输入命令： $ source /opt/tros/local_setup.bash 在终端2，也输入同样的命令，配置环境变量的脚本： 接下来运行两个ROS2的节点。 这两个节点的功能包是属于ROS2里的功能包,可以直接调用到。我们来尝试一下输入命令ros2 run，再输入功能包名称，如果按Tab自动补全文件名，说明可以找到对应的这个功能包： ros2 run demo_nodes_cpp talker talker也是一个发布者节点。按回车运行，可以看到终端1的发布者节点以每秒1次的频率发布消息。 同样，我们到终端2中打开订阅者节点： ros2 run demo_nodes_cpp listener 回车运行，很快两个终端间就建立了通讯。 这样就使用ROS2里的例程实现了话题通信连接，只不过这里我们使用的就是ROS2原生的功能包了，而不是TogetherROS的功能。 通信系统已经没问题了，但看上去似乎还不太直观。 目标检测 没问题，接下来，我们就运行一个更为直观的案例——目标检测。 在这个案例中，需要大家找一个USB的相机，连接到旭日X3拍的USB接口上。 在运行这个例程之前，需要确认两点：1.有一个USB相机已经连接到了旭日X3派板子上；2.有一个HDMI的显示器也连接到了旭日X3派板子上，它主要用于显示后续的图像检测的效果。 要确认USB相机已经正确连接到开发板，可以在终端输入命令“ls - dv\"查看当前设备号，默认把USB相机识别为vedio8，如果当前列表里能找到vedio8就说明相机被成功识别到了。 输入以下命令运行例程： $ cd /app/ai_inference/02_usb_camera_sample/ $ python3 ./usb_camera_fcos.py 代码第一行，02例程的功能是通过相机动态采集图像，并对图像里的目标物体进行实时识别。 代码第二行，我们用python3来运行例程usb_camera_fcos.py，它的目标识别的功能是通过我们板卡中CPU的AI引擎来实现的。 我们输入以上两行代码，就开始驱动相机、并对相机里的图像做动态识别了。 此时如果有连接HDMI的显示器，就可以在显示器里看到动态识别的效果。 我们可以调整USB相机镜头的范围，去拍一些杯子、电脑、显示器等等，都可以把对应的目标物体识别到，并把对应的物体用彩色框给框出来；在框的左上角，就是识别到物体的名称、以及它识别的概率值了。 几个示例程序都可以正常运行了，说明当前的软硬件系统都已经准备就绪，到这里，我们才算是可以正式开始机器人开发了。","text_tokens":["才","不断","概率","获取","hello","里","分别","后续","就","两点","，","？","usb","准备就绪","识别","试一试","listener","两行","么","通过","发布者","安装","ai","找到","问题","目标","案例","这是","框给","一个","ls","：","来","拍","脚本","同样","ctrl","使用","没有","中","设置","包","系统","也","正确","软硬件","可以","把","显示器","命令","能","路径","太","正常","不是","而","两个","以上","tab","example","找","旭日","叫","所以","尝试","$","回车","+","实时","一些","nodes","自动","整个","写","数字","话题","subscriber","cpu","物体","基于","说明","引擎","如果","关闭","接下","电脑","熟悉","此时","cd","文件","做","这时","source","内容","examples","原生","等等","软","2","驱动","了","代码","包是","这样",".","\"","那","最小","对应","sample","杯子","02","会","都","派","1","配置","。","再","第一个","；","号","py","默认","opt","minimal","fcos","看上","其中","节点","次","开发者","框出","启动","自带","环境变","检测","接下来","出来","过程","实现","/","下来","_","频率","打开","用","到","和","x3","已经","c++","要","成功","不","并","确保","字符","环境变量","还","但","function","app","看上去","!","它","没","local","不过","看到","进行","循环","以及","只不过","镜头","建立","最小化","动态","出","发布","cpp","值","效果","run","环境","camera","开始","订阅","程序","之间","属于","更为","板卡","通讯","就是","机器人","对","vedio8","按","一样","publisher","开发","补全","之前","第二行","二行","togetherros","包了","接口","以","算是","rclcpp","是","准备","上","setup","设备","硬件","demo","大家","似乎","左上角","—","第二","验证","ros","上角","就绪","通信","过","用于","输入","形式","上去","第一","范围","框","运行","bash","当前","好","c","正式","inference","查看","命令行","图像","文件名","板子","机器","你","刚才","每秒"," ","dds","这个","主要","去","以下","-","被","几个","开启","tros","示例","测试","列表","先","这","采集","功能","每次","“","member","终端","框出来","talker","窗口","变量","第一行","dv","名称","间","很快","产生","例程","、","可能","比较","我们","的","彩色","hdmi","消息","者","字符串","调用","ros2","确认","调整","左上","信息","一下","软硬","一行","这里","在","”","显示","python3","该","相机","连接",",","直接","为","直观","world","有","开发板","需要"],"title":"示例运行","title_tokens":["示例","运行"]},{"location":"hhp/2.4_TogetherROS%E7%A4%BA%E4%BE%8B%E8%BF%90%E8%A1%8C/#togetherros","text":"接下来，我们就在安装配置好TogetherROS的旭日X3派上，试一试系统自带的一些例程，确保整个系统已经可以正常运行。","text_tokens":["安装","togetherros","系统","一些","下来","在","整个","就","例程","派","x3","，","已经","可以","我们","的","配置","。","正常","确保","试一试","接下","自带","上","接下来","运行","好","旭日"],"title":"TogetherROS示例运行","title_tokens":["示例","togetherros","运行"]},{"location":"hhp/2.4_TogetherROS%E7%A4%BA%E4%BE%8B%E8%BF%90%E8%A1%8C/#_1","text":"先来测试一下TogetherROS系统的通信功能。 我们需要启动两个终端，分别连接到旭日X3派上，并分别按以下命令配置环境变量。 终端1： $ source /opt/tros/local_setup.bash $ ros2 run examples_rclcpp_minimal_publisher publisher_member_function 终端2： $ source /opt/tros/local_setup.bash $ ros2 run examples_rclcpp_minimal_subscriber subscriber_member_function 接下来，我们用ros2 run命令运行节点： 运行第一个例程： ros2 run example_rclcpp_minimal_publisher publisher_member_function 这是一个用C++写的最小化的发布者程序，其中节点叫publisher_member+function，按回车运行该节点。 可以看到这个节点开始不断循环发布信息，每次发布的信息为字符串形式，内容是“Hello,world! +数字”。 同样，在终端2的命令行窗口，输入以下命令并回车开启订阅者节点。 ros2 run examples_rclcpp_minimal_subscriber subscriber_member_function 这个订阅者节点会获取到、并显示出刚才发布者节点发布的信息。 通过这样一个例程，我们验证了两个节点之间的通信没有问题。这这是一个基于DDS的话题通信。 按CTRL+C可以关闭该例程。 通信系统没有问题了，如果你是一个ROS2的开发者，可能对刚才我们使用的ROS2命令比较熟悉，这时你可能也会产生一个问题：我们之前也安装了ROS2系统，那ROS2的原生功能还可以正常运行么？ 我们再来试一试ROS2中自带的一个例程。 和刚才一样打开两个终端，这里我们需要source一下ROS里的环境变量。该环境变量我们刚才已经设置了过软连接，所以配置过程中它也会配置ROS2的功能包路径。 在终端1输入命令： $ source /opt/tros/local_setup.bash 在终端2，也输入同样的命令，配置环境变量的脚本： 接下来运行两个ROS2的节点。 这两个节点的功能包是属于ROS2里的功能包,可以直接调用到。我们来尝试一下输入命令ros2 run，再输入功能包名称，如果按Tab自动补全文件名，说明可以找到对应的这个功能包： ros2 run demo_nodes_cpp talker talker也是一个发布者节点。按回车运行，可以看到终端1的发布者节点以每秒1次的频率发布消息。 同样，我们到终端2中打开订阅者节点： ros2 run demo_nodes_cpp listener 回车运行，很快两个终端间就建立了通讯。 这样就使用ROS2里的例程实现了话题通信连接，只不过这里我们使用的就是ROS2原生的功能包了，而不是TogetherROS的功能。 通信系统已经没问题了，但看上去似乎还不太直观。","text_tokens":["function","看上去","!","不断","内容","它","examples","获取","hello","没","local","分别","里","不过","看到","命令行","就","文件名","原生","循环","，","只不过","建立","最小化","？","软","你","2","刚才","出","每秒"," ","发布","dds","这个","试一试","cpp","listener","了","run","以下","么","环境","包是","开启","tros","通过","开始","发布者","这样",".","那","测试","安装","最小","先","订阅","对应","找到","程序","之间","属于","问题","这是","会","这","一个","派","功能","：","1","通讯","就是","来","对","配置","脚本","。","每次","按","“","再","一样","member","同样","终端","publisher","第一个","ctrl","开发","补全","使用","talker","之前","窗口","变量","没有","中","opt","togetherros","minimal","包了","设置","包","以","系统","名称","间","也","很快","产生","看上","其中","例程","、","可能","节点","可以","比较","次","我们","的","命令","rclcpp","开发者","启动","路径","太","正常","消息","者","是","不是","而","自带","环境变","上","两个","setup","字符串","接下来","调用","ros2","tab","信息","example","旭日","一下","过程","实现","叫","demo","所以","尝试","$","回车","似乎","+","这里","/","下来","nodes","在","_","自动","”","写","频率","打开","显示","数字","验证","用","话题","ros","subscriber","到","和","x3","通信","已经","过","该","c++","输入","连接",",","基于","直接","不","并","说明","形式","为","直观","如果","world","关闭","上去","接下","熟悉","第一","字符","环境变量","还","文件","但","运行","bash","需要","source","这时","c"],"title":"通信测试","title_tokens":["通信","测试"]},{"location":"hhp/2.4_TogetherROS%E7%A4%BA%E4%BE%8B%E8%BF%90%E8%A1%8C/#_2","text":"没问题，接下来，我们就运行一个更为直观的案例——目标检测。 在这个案例中，需要大家找一个USB的相机，连接到旭日X3拍的USB接口上。 在运行这个例程之前，需要确认两点：1.有一个USB相机已经连接到了旭日X3派板子上；2.有一个HDMI的显示器也连接到了旭日X3派板子上，它主要用于显示后续的图像检测的效果。 要确认USB相机已经正确连接到开发板，可以在终端输入命令“ls - dv\"查看当前设备号，默认把USB相机识别为vedio8，如果当前列表里能找到vedio8就说明相机被成功识别到了。 输入以下命令运行例程： $ cd /app/ai_inference/02_usb_camera_sample/ $ python3 ./usb_camera_fcos.py 代码第一行，02例程的功能是通过相机动态采集图像，并对图像里的目标物体进行实时识别。 代码第二行，我们用python3来运行例程usb_camera_fcos.py，它的目标识别的功能是通过我们板卡中CPU的AI引擎来实现的。 我们输入以上两行代码，就开始驱动相机、并对相机里的图像做动态识别了。 此时如果有连接HDMI的显示器，就可以在显示器里看到动态识别的效果。 我们可以调整USB相机镜头的范围，去拍一些杯子、电脑、显示器等等，都可以把对应的目标物体识别到，并把对应的物体用彩色框给框出来；在框的左上角，就是识别到物体的名称、以及它识别的概率值了。 几个示例程序都可以正常运行了，说明当前的软硬件系统都已经准备就绪，到这里，我们才算是可以正式开始机器人开发了。","text_tokens":["才","app","inference","它","概率","查看","没","里","后续","就","图像","看到","进行","以及","两点","，","板子","镜头","机器","等等","usb","准备就绪","识别","动态","2"," ","驱动","这个","主要","了","值","效果","去","代码","两行","以下","-","被","camera","几个","通过","开始","\"",".","示例","列表","ai","sample","对应","找到","程序","杯子","问题","案例","目标","02","更为","框给","一个","都","派","ls","采集","功能","：","1","板卡","就是","机器人","来","拍","对","。","vedio8","“","终端","开发","框出来","；","之前","号","第二行","py","默认","二行","中","第一行","接口","系统","dv","fcos","名称","也","正确","例程","、","软硬件","可以","把","我们","显示器","的","命令","算是","能","彩色","框出","hdmi","正常","是","准备","检测","上","以上","接下来","出来","确认","调整","左上","找","设备","旭日","软硬","实现","硬件","大家","$","一行","实时","一些","左上角","这里","—","/","下来","在","_","显示","第二","python3","用","上角","就绪","到","x3","cpu","已经","用于","相机","输入","要","成功","连接","物体","说明","并","引擎","为","直观","如果","接下","电脑","有","第一","cd","此时","开发板","范围","框","运行","当前","需要","做","正式"],"title":"目标检测","title_tokens":["检测","目标"]},{"location":"hhp/3.1_%E5%A4%9A%E8%8A%82%E7%82%B9%E8%AF%9D%E9%A2%98%E9%80%9A%E4%BF%A1/","text":"多节点话题通信 节点实现了机器人各种各样的功能，但这些功能并不是独立的，之间会有千丝万缕的联系，其中最重要的一种联系方式就是话题，它是 节点间传递数据的桥梁 。 通信模型 以两个机器人节点为例。A节点的功能是驱动相机这个硬件设备，获取得到相机拍摄的图像信息，B节点的功能是视频监控，将相机拍摄到的图像实时显示给用户查看。 大家可以想一下，这两个节点是不是必然存在某种关系？没错，节点A要将获取的图像数据传输给节点B，有了数据，节点B才能做这样可视化的渲染。 此时从节点A到节点B传递图像数据的方式，在ROS中，我们就称之为 话题 ，它作为一个桥梁，实现了节点之间某一个方向上的数据传输。 发布/订阅模型 从话题本身的实现角度来看，使用了基于DDS的 发布/订阅模型 ，什么叫发布和订阅呢？ 话题数据传输的特性是从一个节点到另外一个节点，发送数据的对象称之为 发布者 ，接收数据的对象称之为 订阅者 ，每一个话题都需要有一个名字，传输的数据也需要有固定的数据类型。 打一个比方，大家平时应该也会看微信公众号，比如有一个公众号，它的名字叫做“古月居”，这个古月居就是话题名称，公众号的发布者是古月居的小编，他会把组织好的机器人知识排版成要求格式的公众号文章，发布出去，这个文章格式，就是话题的数据类型。如果大家对这个话题感兴趣，就可以订阅“古月居”，成为订阅者之后自然就可以收到古月居的公众号文章，没有订阅的话，也就无法收到。 类似这样的发布/订阅模型在生活中随处可见，比如订阅报纸、订阅杂志等等。 多对多通信 大家再仔细想下这些可以订阅的东西，是不是并不是唯一的，我们每个人可以订阅很多公众号、报纸、杂志，这些公众号、报纸、杂志也可以被很多人订阅，没错，ROS里的话题也是一样，发布者和订阅者的数量并不是唯一的，可以称之为是多对多的通信模型。 因为话题是多对多的模型，发布控制指令的摇杆可以有一个，也可以有2个、3个，订阅控制指令的机器人可以有1个，也可以有2个、3个，大家可以想象一下这个画面，似乎还是挺魔性的，如果存在多个发送指令的节点，建议大家要 注意区分优先级 ，不然机器人可能不知道该听谁的了。 异步通信 话题通信还有一个特性，那就是异步，这个词可能有同学是第一次听说？所谓异步，只要是指发布者发出数据后，并不知道订阅者什么时候可以收到，类似古月居公众号发布一篇文章，你什么时候阅读的，古月居根本不知道，报社发出一份报纸，你什么时候收到，报社也是不知道的。这就叫做异步。 异步的特性也让话题更适合用于一些周期发布的数据，比如传感器的数据，运动控制的指令等等，如果某些逻辑性较强的指令，比如修改某一个参数，用话题传输就不太合适了。 消息接口 最后，既然是数据传输，发布者和订阅者就得统一数据的描述格式，不能一个说英文，一个理解成了中文。在ROS中，话题通信数据的描述格式称之为消息，对应编程语言中数据结构的概念。比如这里的一个图像数据，就会包含图像的长宽像素值、每个像素的RGB等等，在ROS中都有标准定义。 消息是ROS中的一种接口定义方式 ，与编程语言无关，我们也可以通过 .msg 后缀的文件自行定义，有了这样的接口，各种节点就像积木块一样，通过各种各样的接口进行拼接，组成复杂的机器人系统。 编程方法 了解了话题的基本原理，接下来我们就要开始编写代码啦。 创建工作空间 请大家先按照这个流程创建工作空间、下载课程的例程代码，并进行编译。 $ mkdir –p dev_ws/src $ cd /userdata/dev_ws/src $ git clone https://gitee.com/guyuehome/togetherros_tutorials.git $ cd /userdata/dev_ws/ $ colcon build 运行示例程序 编译成功后，我们尝试运行话题通信的Hello World例程，在这个例程中，我们会先创建一个发布者，发布话题“chatter”，周期发送“Hello World”这个字符串，消息类型是ROS中标准定义的String，再创建一个订阅者，订阅“chatter”这个话题，从而接收到“Hello World”这个字符串。 $ source /opt/tros/local_setup.bash $ source install/local_setup.bash $ ros2 run learning_topic_cpp talker $ ros2 run learning_topic_cpp listener 这就是TogetherROS系统中话题通信的方法，依然沿用了ROS2中话题通信的完整流程。 代码解析 发布者的实现方法publisher_member_function.cpp： #include <chrono> #include <functional> #include <memory> #include <string> #include \"rclcpp/rclcpp.hpp\" #include \"std_msgs/msg/string.hpp\" using namespace std :: chrono_literals ; /* This example creates a subclass of Node and uses std::bind() to register a * member function as a callback from the timer. */ class MinimalPublisher : public rclcpp :: Node { public : MinimalPublisher () : Node ( \"minimal_publisher\" ), count_ ( 0 ) { publisher_ = this -> create_publisher < std_msgs :: msg :: String > ( \"topic\" , 10 ); timer_ = this -> create_wall_timer ( 500 ms , std :: bind ( & MinimalPublisher :: timer_callback , this )); } private : void timer_callback () { auto message = std_msgs :: msg :: String (); message . data = \"Hello, world! \" + std :: to_string ( count_ ++ ); RCLCPP_INFO ( this -> get_logger (), \"Publishing: '%s'\" , message . data . c_str ()); publisher_ -> publish ( message ); } rclcpp :: TimerBase :: SharedPtr timer_ ; rclcpp :: Publisher < std_msgs :: msg :: String >:: SharedPtr publisher_ ; size_t count_ ; }; int main ( int argc , char * argv []) { rclcpp :: init ( argc , argv ); rclcpp :: spin ( std :: make_shared < MinimalPublisher > ()); rclcpp :: shutdown (); return 0 ; } 订阅者的实现方法subscriber_member_function.cpp： #include <memory> #include \"rclcpp/rclcpp.hpp\" #include \"std_msgs/msg/string.hpp\" using std :: placeholders :: _1 ; class MinimalSubscriber : public rclcpp :: Node { public : MinimalSubscriber () : Node ( \"minimal_subscriber\" ) { subscription_ = this -> create_subscription < std_msgs :: msg :: String > ( \"topic\" , 10 , std :: bind ( & MinimalSubscriber :: topic_callback , this , _1 )); } private : void topic_callback ( const std_msgs :: msg :: String :: SharedPtr msg ) const { RCLCPP_INFO ( this -> get_logger (), \"I heard: '%s'\" , msg -> data . c_str ()); } rclcpp :: Subscription < std_msgs :: msg :: String >:: SharedPtr subscription_ ; }; int main ( int argc , char * argv []) { rclcpp :: init ( argc , argv ); rclcpp :: spin ( std :: make_shared < MinimalSubscriber > ()); rclcpp :: shutdown (); return 0 ; }","text_tokens":["像素","获取","hello","视频","里","bind","就","是不是","数据结构","，","感兴趣","后缀","？","必然","msgs","register","指","称之为","重要","listener","概念","角度","class","creates","通过","发布者","create","听","build","各种","千丝","关系","随处","一个","：","课程","基本","topic","应该","i","后","[","使用","colcon","没有","中","合适","什么","魔性","系统","–","中文","也","可以","把","spin","src","太","无关","subscription","本身","不是","两个","and","example","理解","叫","尝试","$","要求","+","实时","一些","literals","请","组成","呢","模型","很多","callback","兴趣","区分","知道","话题","argc","subscriber","接收","就要","成为","文章","]","基于","include","https","'","成","const","如果","发送","接下","此时","想下","cd","init","方式","文件","做","得到","source","公众","逻辑","得","=","可视","sharedptr","to","听说","userdata","等等","(","b","所谓","2","count","驱动","固定","了","阅读","as","private","代码","of","渲染","据传","来看","流程","这样",".","给","那","比如","\"","publishing","wall","对应","using","用户","编译","会","打","都","与","1","。","再","install","叫做","无法","按照","挺","还有","号","void","heard","opt","异步","minimal","方法","类型","info","其中","人","古月","节点","namespace","argv","他会","++","将","万缕","接下来","存在","组织","一份","根本","因为","方向","小编","一次","实现","感器","shutdown","统一","不能","谁","/","下来","_","随处可见","平时","传感","用","啦","到","和","逻辑性","才能","ws","str","要","桥梁","minimalpublisher","%","dev","成功","s","通信模型","不","com","并","3","string","个","public","可视化","tutorials","字符","报社","知识","但","10","p","function","!",":","它","}","注意","基本原理","local","{","timerbase","进行","并不知道","从","较强","最后","块",";","0","联系","生活","发布","编程","cpp","值","可见","run","了解","对象","发送数据","另外","控制指令","uses","开始","t","标准","ms","订阅","词","多个","程序","timer","之间","沿用","自然",")","placeholders","git","&","语言","数据类型","想","return","机器人","控制","就是","对","传递数据","原理","让","一样","int","排版","优先","编程语言","publisher","摇杆","learning","*","微信","数据传输","在生活中","英文","node","500","积木","togetherros","接口","千丝万缕","以","画面","#","get","空间","this","报纸","感兴","rclcpp","char","发出","<","编写","hpp","subclass","是",">","上","setup","完整","适合","设备","依然","硬件","唯一","data","大家","似乎","size","数据","msg","杂志","某种","ros","通信","用于","下载","拼接","独立","更","比方","gitee","接收数据","从而","第一","第一次","logger","memory","运行","bash","from","好","c","拍摄","参数","publish","包含","一种","查看","传递","定义","图像","建议","周期","复杂","机器","只要","工作","解析","联系方式","你"," ","dds","这个","东西","rgb","-","被","chrono","出去","tros","示例","shared","仔细","先","之后","会先","各种各样","之为","这","多","功能","各样","没错","不然","某些","类似","a","看","“","member","运动","接口定义","clone","描述","每","talker","std","一篇","最","不知","是从","监控","长宽","像","名称","时候","间","例程","main","、","优先级","可能","传输","我们","的","名字","既然","特性","收到","消息","者","同学","还是","字符串","ros2","信息","某","functional","数量","一下","想象","为例","每个","这里","在","结构","这些","”","的话","指令","显示","minimalsubscriber","the","自行","本原","格式","该","相机","作为","mkdir","message","chatter",",","auto","make","world","创建","有","传感器","guyuehome","修改","居","需要","说"],"title":"多节点话题通信","title_tokens":["多","节点","通信","话题"]},{"location":"hhp/3.1_%E5%A4%9A%E8%8A%82%E7%82%B9%E8%AF%9D%E9%A2%98%E9%80%9A%E4%BF%A1/#_1","text":"节点实现了机器人各种各样的功能，但这些功能并不是独立的，之间会有千丝万缕的联系，其中最重要的一种联系方式就是话题，它是 节点间传递数据的桥梁 。","text_tokens":["实现","最","各种","千丝万缕","千丝","之间","它","一种","数据","间","各种各样","会","这些","传递","其中","话题","功能","各样","机器人","节点","机器","，","就是","的","传递数据","独立","联系方式","桥梁","。","并","联系","重要"," ","不是","了","是","有","万缕","方式","但"],"title":"多节点话题通信","title_tokens":["多","节点","通信","话题"]},{"location":"hhp/3.1_%E5%A4%9A%E8%8A%82%E7%82%B9%E8%AF%9D%E9%A2%98%E9%80%9A%E4%BF%A1/#_2","text":"以两个机器人节点为例。A节点的功能是驱动相机这个硬件设备，获取得到相机拍摄的图像信息，B节点的功能是视频监控，将相机拍摄到的图像实时显示给用户查看。 大家可以想一下，这两个节点是不是必然存在某种关系？没错，节点A要将获取的图像数据传输给节点B，有了数据，节点B才能做这样可视化的渲染。 此时从节点A到节点B传递图像数据的方式，在ROS中，我们就称之为 话题 ，它作为一个桥梁，实现了节点之间某一个方向上的数据传输。","text_tokens":["它","获取","查看","视频","传递","可视","图像","就","是不是","从","，","机器","b","？","必然","称之为"," ","驱动","这个","了","渲染","据传","这样","给","关系","之间","用户","之为","这","一个","想","功能","没错","机器人","。","a","数据传输","中","以","监控","节点","可以","传输","我们","的","不是","是","上","两个","将","存在","信息","某","方向","设备","一下","硬件","实现","大家","为例","实时","数据","在","显示","某种","话题","ros","到","相机","作为","才能","要","桥梁","可视化","有","此时","方式","做","得到","拍摄"],"title":"通信模型","title_tokens":["模型","通信模型","通信"]},{"location":"hhp/3.1_%E5%A4%9A%E8%8A%82%E7%82%B9%E8%AF%9D%E9%A2%98%E9%80%9A%E4%BF%A1/#_3","text":"从话题本身的实现角度来看，使用了基于DDS的 发布/订阅模型 ，什么叫发布和订阅呢？ 话题数据传输的特性是从一个节点到另外一个节点，发送数据的对象称之为 发布者 ，接收数据的对象称之为 订阅者 ，每一个话题都需要有一个名字，传输的数据也需要有固定的数据类型。 打一个比方，大家平时应该也会看微信公众号，比如有一个公众号，它的名字叫做“古月居”，这个古月居就是话题名称，公众号的发布者是古月居的小编，他会把组织好的机器人知识排版成要求格式的公众号文章，发布出去，这个文章格式，就是话题的数据类型。如果大家对这个话题感兴趣，就可以订阅“古月居”，成为订阅者之后自然就可以收到古月居的公众号文章，没有订阅的话，也就无法收到。 类似这样的发布/订阅模型在生活中随处可见，比如订阅报纸、订阅杂志等等。","text_tokens":["它","就","从","，","机器","感兴趣","等等","？","称之为","生活"," ","发布","dds","这个","固定","了","角度","来看","据传","发送数据","对象","出去","另外","发布者","这样","比如","订阅","之后","自然","随处","之为","会","打","一个","数据类型","都","机器人","就是","对","类似","。","看","“","应该","排版","叫做","无法","每","使用","号","微信","数据传输","在生活中","没有","是从","什么","名称","类型","也","、","古月","节点","把","可以","传输","的","报纸","感兴","名字","本身","他会","特性","收到","者","是","组织","小编","实现","叫","大家","要求","数据","/","呢","模型","”","的话","平时","兴趣","随处可见","杂志","话题","到","和","格式","接收","成为","文章","基于","比方","接收数据","成","如果","发送","有","居","知识","需要","可见","好","公众"],"title":"发布/订阅模型","title_tokens":["/","发布","订阅","模型"]},{"location":"hhp/3.1_%E5%A4%9A%E8%8A%82%E7%82%B9%E8%AF%9D%E9%A2%98%E9%80%9A%E4%BF%A1/#_4","text":"大家再仔细想下这些可以订阅的东西，是不是并不是唯一的，我们每个人可以订阅很多公众号、报纸、杂志，这些公众号、报纸、杂志也可以被很多人订阅，没错，ROS里的话题也是一样，发布者和订阅者的数量并不是唯一的，可以称之为是多对多的通信模型。 因为话题是多对多的模型，发布控制指令的摇杆可以有一个，也可以有2个、3个，订阅控制指令的机器人可以有1个，也可以有2个、3个，大家可以想象一下这个画面，似乎还是挺魔性的，如果存在多个发送指令的节点，建议大家要 注意区分优先级 ，不然机器人可能不知道该听谁的了。","text_tokens":["注意","里","建议","是不是","，","机器","2","称之为"," ","发布","这个","了","东西","被","控制指令","发布者","听","仔细","订阅","多个","之为","一个","多","没错","机器人","控制","1","对","不然","。","再","一样","优先","挺","摇杆","号","画面","魔性","也","、","人","优先级","可能","节点","可以","我们","的","报纸","不是","是","者","还是","存在","因为","数量","一下","想象","唯一","大家","似乎","谁","每个","这些","模型","很多","杂志","指令","区分","知道","话题","ros","和","通信","该","要","通信模型","不","并","3","个","如果","发送","有","想下","公众"],"title":"多对多通信","title_tokens":["多","对","通信"]},{"location":"hhp/3.1_%E5%A4%9A%E8%8A%82%E7%82%B9%E8%AF%9D%E9%A2%98%E9%80%9A%E4%BF%A1/#_5","text":"话题通信还有一个特性，那就是异步，这个词可能有同学是第一次听说？所谓异步，只要是指发布者发出数据后，并不知道订阅者什么时候可以收到，类似古月居公众号发布一篇文章，你什么时候阅读的，古月居根本不知道，报社发出一份报纸，你什么时候收到，报社也是不知道的。这就叫做异步。 异步的特性也让话题更适合用于一些周期发布的数据，比如传感器的数据，运动控制的指令等等，如果某些逻辑性较强的指令，比如修改某一个参数，用话题传输就不太合适了。","text_tokens":["参数","逻辑","就","并不知道","听说","周期","，","较强","只要","等等","？","所谓","你","指"," ","发布","这个","了","阅读","发布者","那","比如","订阅","词","这","一个","控制","就是","某些","类似","。","让","运动","后","叫做","还有","一篇","号","合适","不知","异步","什么","时候","也","古月","可能","可以","传输","的","报纸","太","发出","特性","收到","同学","是","者","适合","一份","根本","某","一次","感器","一些","数据","指令","知道","话题","传感","用","逻辑性","通信","用于","文章","更","不","如果","有","第一","第一次","传感器","报社","居","修改","公众"],"title":"异步通信","title_tokens":["通信","异步"]},{"location":"hhp/3.1_%E5%A4%9A%E8%8A%82%E7%82%B9%E8%AF%9D%E9%A2%98%E9%80%9A%E4%BF%A1/#_6","text":"最后，既然是数据传输，发布者和订阅者就得统一数据的描述格式，不能一个说英文，一个理解成了中文。在ROS中，话题通信数据的描述格式称之为消息，对应编程语言中数据结构的概念。比如这里的一个图像数据，就会包含图像的长宽像素值、每个像素的RGB等等，在ROS中都有标准定义。 消息是ROS中的一种接口定义方式 ，与编程语言无关，我们也可以通过 .msg 后缀的文件自行定义，有了这样的接口，各种节点就像积木块一样，通过各种各样的接口进行拼接，组成复杂的机器人系统。","text_tokens":["得","包含","像素","一种","定义","就","图像","进行","数据结构","复杂","，","机器","等等","最后","后缀","块","称之为"," ","发布","编程","了","值","概念","rgb","据传","通过","发布者","这样",".","比如","各种","标准","对应","订阅","各种各样","之为","会","语言","一个","都","与","各样","机器人","。","一样","接口定义","编程语言","描述","数据传输","英文","中","积木","接口","系统","长宽","像","中文","也","、","节点","可以","传输","我们","的","既然","无关","消息","者","是","理解","统一","不能","每个","数据","这里","msg","组成","在","结构","话题","ros","自行","和","通信","格式","拼接","成","有","方式","文件","说"],"title":"消息接口","title_tokens":["消息","接口"]},{"location":"hhp/3.1_%E5%A4%9A%E8%8A%82%E7%82%B9%E8%AF%9D%E9%A2%98%E9%80%9A%E4%BF%A1/#_7","text":"了解了话题的基本原理，接下来我们就要开始编写代码啦。","text_tokens":["下来","基本原理","话题","啦","本原","，","我们","的","就要","原理","。","基本","编写","了","接下","代码","了解","接下来","开始"],"title":"编程方法","title_tokens":["编程","方法"]},{"location":"hhp/3.1_%E5%A4%9A%E8%8A%82%E7%82%B9%E8%AF%9D%E9%A2%98%E9%80%9A%E4%BF%A1/#_8","text":"请大家先按照这个流程创建工作空间、下载课程的例程代码，并进行编译。 $ mkdir –p dev_ws/src $ cd /userdata/dev_ws/src $ git clone https://gitee.com/guyuehome/togetherros_tutorials.git $ cd /userdata/dev_ws/ $ colcon build","text_tokens":["togetherros","build","大家","先","$",":","请","–","/","编译","_","例程","git","、","进行","空间","，","userdata","下载","工作","的","课程","mkdir","ws","。","dev","src","gitee","com","并","https"," ","按照","clone","这个","创建","代码","tutorials","colcon","guyuehome","cd","p","流程","."],"title":"创建工作空间","title_tokens":["空间","创建","工作"]},{"location":"hhp/3.1_%E5%A4%9A%E8%8A%82%E7%82%B9%E8%AF%9D%E9%A2%98%E9%80%9A%E4%BF%A1/#_9","text":"编译成功后，我们尝试运行话题通信的Hello World例程，在这个例程中，我们会先创建一个发布者，发布话题“chatter”，周期发送“Hello World”这个字符串，消息类型是ROS中标准定义的String，再创建一个订阅者，订阅“chatter”这个话题，从而接收到“Hello World”这个字符串。 $ source /opt/tros/local_setup.bash $ source install/local_setup.bash $ ros2 run learning_topic_cpp talker $ ros2 run learning_topic_cpp listener 这就是TogetherROS系统中话题通信的方法，依然沿用了ROS2中话题通信的完整流程。","text_tokens":["opt","togetherros","标准","尝试","订阅","$","系统","方法","会先","沿用","/","类型","在","hello","编译","local","_","”","定义","例程","这","依然","一个","话题","ros","到","周期","，","通信","就是","我们","的","接收","chatter","。","成功","流程","topic","“","再","install","string","后"," ","发布","消息","这个","cpp","者","是","world","创建","从而","发送","talker","listener","run","字符串","setup","字符","learning","ros2","了","完整","运行","bash","source","tros","发布者","中","."],"title":"运行示例程序","title_tokens":["运行","示例","程序"]},{"location":"hhp/3.1_%E5%A4%9A%E8%8A%82%E7%82%B9%E8%AF%9D%E9%A2%98%E9%80%9A%E4%BF%A1/#_10","text":"发布者的实现方法publisher_member_function.cpp： #include <chrono> #include <functional> #include <memory> #include <string> #include \"rclcpp/rclcpp.hpp\" #include \"std_msgs/msg/string.hpp\" using namespace std :: chrono_literals ; /* This example creates a subclass of Node and uses std::bind() to register a * member function as a callback from the timer. */ class MinimalPublisher : public rclcpp :: Node { public : MinimalPublisher () : Node ( \"minimal_publisher\" ), count_ ( 0 ) { publisher_ = this -> create_publisher < std_msgs :: msg :: String > ( \"topic\" , 10 ); timer_ = this -> create_wall_timer ( 500 ms , std :: bind ( & MinimalPublisher :: timer_callback , this )); } private : void timer_callback () { auto message = std_msgs :: msg :: String (); message . data = \"Hello, world! \" + std :: to_string ( count_ ++ ); RCLCPP_INFO ( this -> get_logger (), \"Publishing: '%s'\" , message . data . c_str ()); publisher_ -> publish ( message ); } rclcpp :: TimerBase :: SharedPtr timer_ ; rclcpp :: Publisher < std_msgs :: msg :: String >:: SharedPtr publisher_ ; size_t count_ ; }; int main ( int argc , char * argv []) { rclcpp :: init ( argc , argv ); rclcpp :: spin ( std :: make_shared < MinimalPublisher > ()); rclcpp :: shutdown (); return 0 ; } 订阅者的实现方法subscriber_member_function.cpp： #include <memory> #include \"rclcpp/rclcpp.hpp\" #include \"std_msgs/msg/string.hpp\" using std :: placeholders :: _1 ; class MinimalSubscriber : public rclcpp :: Node { public : MinimalSubscriber () : Node ( \"minimal_subscriber\" ) { subscription_ = this -> create_subscription < std_msgs :: msg :: String > ( \"topic\" , 10 , std :: bind ( & MinimalSubscriber :: topic_callback , this , _1 )); } private : void topic_callback ( const std_msgs :: msg :: String :: SharedPtr msg ) const { RCLCPP_INFO ( this -> get_logger (), \"I heard: '%s'\" , msg -> data . c_str ()); } rclcpp :: Subscription < std_msgs :: msg :: String >:: SharedPtr subscription_ ; }; int main ( int argc , char * argv []) { rclcpp :: init ( argc , argv ); rclcpp :: spin ( std :: make_shared < MinimalSubscriber > ()); rclcpp :: shutdown (); return 0 ; }","text_tokens":["function","!",":","=","publish","}","hello","bind","{","timerbase","to","(",";","0","msgs","register","count"," ","发布","cpp","private","as","-","of","class","chrono","creates","uses","t","发布者","create","\"",".","publishing","shared","wall","using","ms","订阅","timer",")","placeholders","&","：","return","1","a","topic","int","member","i","[","publisher","std","void","*","heard","500","node","minimal","方法","#","get","info","main","namespace","的","this","spin","rclcpp","char","argv","subscription","<","hpp","++","subclass","者",">","and","functional","example","实现","data","shutdown","+","size","literals","msg","/","_","callback","minimalsubscriber","argc","the","subscriber","message","str","minimalpublisher","%","s","]",",","include","auto","make","string","'","const","public","world","init","logger","memory","10","from","sharedptr","c"],"title":"代码解析","title_tokens":["解析","代码"]},{"location":"hhp/3.2_%E5%A4%9A%E8%8A%82%E7%82%B9%E6%9C%8D%E5%8A%A1%E9%80%9A%E4%BF%A1/","text":"多节点服务通信 话题通信可以实现多个ROS节点之间数据的单向传输，使用这种异步通信机制，发布者无法准确知道订阅者是否收到消息，本讲我们将一起学习ROS另外一种常用的通信方法—— 服务 ，可以实现类似 你问我答的同步通信 效果。 通信模型 在之前的课程中，我们通过一个节点驱动相机，发布图像话题，另外一个节点订阅图像话题，并实现对其中红色物体的识别，此时我们可以按照图像识别的频率，周期得到物体的位置。 这个位置信息可以继续发给机器人的上层应用使用，比如可以跟随目标运动，或者运动到目标位置附近。此时，我们并不需要这么高的频率一直订阅物体的位置，而是更希望在需要这个数据的时候，发一个查询的请求，然后尽快得到此时目标的最新位置。 这样的通信模型和话题单向传输有所不同，变成了发送一个请求，反馈一个应答的形式，好像是你问我答一样，这种通信机制在ROS中成为 服务，Service 。 客户端/服务器模型 从服务的实现机制上来看，这种你问我答的形式叫做 客户端/服务器模型 ，简称为CS模型，客户端在需要某些数据的时候，针对某个具体的服务，发送请求信息，服务器端收到请求之后，就会进行处理并反馈应答信息。 这种通信机制在生活中也很常见，比如我们经常浏览的各种网页，此时你的电脑浏览器就是客户端，通过域名或者各种操作，向网站服务器发送请求，服务器收到之后返回需要展现的页面数据。 同步通信 这个过程一般要求越快越好，假设服务器半天没有反应，你的浏览器一直转圈圈，那有可能是服务器宕机了，或者是网络不好，所以相比话题通信，在服务通信中，客户端可以通过接收到的应答信息，判断服务器端的状态，我们也称之为同步通信。 一对多通信 比如古月居这个网站，服务器是唯一存在的，并没有多个完全一样的古月居网站，但是可以访问古月居网站的客户端是不唯一的，大家每一个人都可以看到同样的界面。所以服务通信模型中，服务器端唯一，但客户端可以不唯一。 服务接口 和话题通信类似，服务通信的核心还是要传递数据，数据变成了两个部分，一个 请求的数据 ，比如请求苹果位置的命令，还有一个 反馈的数据 ，比如反馈苹果坐标位置的数据，这些数据和话题消息一样，在ROS中也是要标准定义的，话题使用.msg文件定义，服务使用的是.srv文件定义，后续我们会给大家介绍定义的方法。 编程方法 了解了服务通信的原理，接下来我们就要开始编写代码啦，我们尝试通过服务实现一个加法求解器的功能。 运行示例程序 当我们需要计算两个加数的求和结果时，就通过客户端节点，将两个加数封装成请求数据，针对服务“add_two_ints”发送出去，提供这个服务的服务器端节点，收到请求数据后，开始进行加法计算，并将求和结果封装成应答数据，反馈给客户端，之后客户端就可以得到想要的结果啦。 我们一起操作下这个例程。 $ source /opt/tros/local_setup.bash $ source install/local_setup.bash $ ros2 run learning_service_cpp server $ ros2 run learning_service_cpp client 2 3 话题和服务是最为常用的两种数据通信方法，前者适合传感器、控制指令等周期性、单向传输的数据，后者适合一问一答，同步性要求更高的数据，比如获取机器视觉识别到的目标位置。 代码解析 服务器端add_two_ints_server.cpp： #include \"rclcpp/rclcpp.hpp\" #include \"learning_service_cpp/srv/add_two_ints.hpp\" #include <memory> void add ( const std::shared_ptr<learning_service_cpp::srv::AddTwoInts::Request> request, std::shared_ptr<learning_service_cpp::srv::AddTwoInts::Response> response ) { response->sum = request->a + request->b ; RCLCPP_INFO ( rclcpp::get_logger ( \"rclcpp\" ) , \"Incoming request\\na: %ld\" \" b: %ld\" , request->a, request->b ) ; RCLCPP_INFO ( rclcpp::get_logger ( \"rclcpp\" ) , \"sending back response: [%ld]\" , ( long int ) response->sum ) ; } int main ( int argc, char **argv ) { rclcpp::init ( argc, argv ) ; std::shared_ptr<rclcpp::Node> node = rclcpp::Node::make_shared ( \"add_two_ints_server\" ) ; rclcpp::Service<learning_service_cpp::srv::AddTwoInts>::SharedPtr service = node->create_service<learning_service_cpp::srv::AddTwoInts> ( \"add_two_ints\" , & add ) ; RCLCPP_INFO ( rclcpp::get_logger ( \"rclcpp\" ) , \"Ready to add two ints.\" ) ; rclcpp::spin ( node ) ; rclcpp::shutdown () ; } 客户端add_two_ints_client.cpp： #include \"rclcpp/rclcpp.hpp\" #include \"learning_service_cpp/srv/add_two_ints.hpp\" #include <chrono> #include <cstdlib> #include <memory> using namespace std :: chrono_literals ; int main ( int argc , char ** argv ) { rclcpp :: init ( argc , argv ); if ( argc != 3 ) { RCLCPP_INFO ( rclcpp :: get_logger ( \"rclcpp\" ), \"usage: add_two_ints_client X Y\" ); return 1 ; } std :: shared_ptr < rclcpp :: Node > node = rclcpp :: Node :: make_shared ( \"add_two_ints_client\" ); rclcpp :: Client < learning_service_cpp :: srv :: AddTwoInts >:: SharedPtr client = node -> create_client < learning_service_cpp :: srv :: AddTwoInts > ( \"add_two_ints\" ); auto request = std :: make_shared < learning_service_cpp :: srv :: AddTwoInts :: Request > (); request -> a = atoll ( argv [ 1 ]); request -> b = atoll ( argv [ 2 ]); while ( ! client -> wait_for_service ( 1 s )) { if ( ! rclcpp :: ok ()) { RCLCPP_ERROR ( rclcpp :: get_logger ( \"rclcpp\" ), \"Interrupted while waiting for the service. Exiting.\" ); return 0 ; } RCLCPP_INFO ( rclcpp :: get_logger ( \"rclcpp\" ), \"service not available, waiting again...\" ); } auto result = client -> async_send_request ( request ); // Wait for the result. if ( rclcpp :: spin_until_future_complete ( node , result ) == rclcpp :: FutureReturnCode :: SUCCESS ) { RCLCPP_INFO ( rclcpp :: get_logger ( \"rclcpp\" ), \"Sum: %ld\" , result . get () -> sum ); } else { RCLCPP_ERROR ( rclcpp :: get_logger ( \"rclcpp\" ), \"Failed to call service add_two_ints\" ); } rclcpp :: shutdown (); return 0 ; }","text_tokens":["希望","图像识别","获取","后续","就","complete","，","好像","识别","称之为","async","状态","本","usage","同步","通过","发布者","create","各种","目标","判断","一个","返回","附近","：","课程","同样","后","我","[","interrupted","\\","使用","没有","中","也","客户端","而是","可以","前者","命令","spin","越快越好","有所","not","介绍","ints","应答","计算","两个","答","应用","这种","周期性","所以","尝试","$","要求","+","literals","发","two","务器","数据通","模型","很","知道","话题","cs","argc","...","接收","就要","成为","]","物体","include","成","const","发送","接下","电脑","此时","继续","init","上层","文件","得到","有所不同","source","until","=","to","两种","(","b","while","2","驱动","位置","了","相比","代码","来看","机制","最为","\"","这样","网站",".","给","比如","using","加数","求和","waiting","尽快","圈圈","会","域名","ok","都","1","。","install","叫做","无法","按照","还有","void","学习","单向","变成","opt","ld","异步","不同","y","方法","ptr","加法","info","其中","request","add","人","古月","节点","success","again","namespace","那有","但是","argv","结果","发给","client","服务器发送","将","接下来","存在","na","过程","实现","感器","shutdown","界面","越好","器","/","下来","_","是否","频率","下","传感","时","最新","假设","到","和","啦","要","%","s","核心","通信模型","不","坐标","并","网络","3","wait","send","操作","但","服务器端","常用","服务","!",":","苹果","}","local","{","看到","进行","从","网页","if",";","0","完全","incoming","生活","发布","编程","cpp","效果","具体","run","了解","available","另外","控制指令","开始","封装","标准","订阅","多个","程序","之间",")","常见","视觉","针对","&","越快","for","return","机器人","控制","就是","高","浏览","对","展现","传递数据","原理","一样","int","后者","exiting","请求","result","srv","learning","之前","*","并不需要","在生活中","向","cstdlib","sum","node","服务器","跟随","接口","futurereturncode","back","#","get","future","数据通信","处理","这么","rclcpp","char","hpp","编写","<","宕机","是",">","上","setup","适合","唯一","大家","service","数据","msg","—","ros","response","通信","准确","更","访问","简称","形式","logger","memory","运行","bash","ready","一起","某个","一种","页面","传递","定义","图像","求解","周期","半天","机器","else","x","解析","浏览器","你","讲","call"," ","这个","转圈","-","chrono","出去","addtwoints","提供","tros","示例","failed","shared","之后","不好","之为","多","功能","某些","类似","a","红色","“","sending","运动","每","std","一般","同步性","当","反馈","经常","时候","客户","例程","main","、","反应","可能","long","传输","我们","问","的","一问一答","error","收到","消息","者","server","还是","想要","ros2","信息","atoll","等","一直","在","部分","这些","”","指令","the","然后","相机","一对",",","auto","转圈圈","make","或者","为","传感器","居","查询","需要","sharedptr"],"title":"多节点服务通信","title_tokens":["服务","多","节点","通信"]},{"location":"hhp/3.2_%E5%A4%9A%E8%8A%82%E7%82%B9%E6%9C%8D%E5%8A%A1%E9%80%9A%E4%BF%A1/#_1","text":"话题通信可以实现多个ROS节点之间数据的单向传输，使用这种异步通信机制，发布者无法准确知道订阅者是否收到消息，本讲我们将一起学习ROS另外一种常用的通信方法—— 服务 ，可以实现类似 你问我答的同步通信 效果。","text_tokens":["实现","单向","异步","服务","订阅","多个","一起","方法","之间","数据","一种","—","是否","知道","话题","ros","通信","可以","节点","传输","，","准确","我们","的","问","类似","。","你","讲","无法","发布","收到","消息"," ","我","者","使用","效果","将","本","机制","同步","另外","答","这种","发布者","学习","常用"],"title":"多节点服务通信","title_tokens":["服务","多","节点","通信"]},{"location":"hhp/3.2_%E5%A4%9A%E8%8A%82%E7%82%B9%E6%9C%8D%E5%8A%A1%E9%80%9A%E4%BF%A1/#_2","text":"在之前的课程中，我们通过一个节点驱动相机，发布图像话题，另外一个节点订阅图像话题，并实现对其中红色物体的识别，此时我们可以按照图像识别的频率，周期得到物体的位置。 这个位置信息可以继续发给机器人的上层应用使用，比如可以跟随目标运动，或者运动到目标位置附近。此时，我们并不需要这么高的频率一直订阅物体的位置，而是更希望在需要这个数据的时候，发一个查询的请求，然后尽快得到此时目标的最新位置。 这样的通信模型和话题单向传输有所不同，变成了发送一个请求，反馈一个应答的形式，好像是你问我答一样，这种通信机制在ROS中成为 服务，Service 。","text_tokens":["服务","希望","图像识别","图像","周期","，","机器","好像","识别","你"," ","发布","驱动","位置","这个","了","机制","另外","通过","这样","比如","订阅","目标","尽快","一个","附近","机器人","高","对","课程","。","红色","一样","运动","请求","按照","我","使用","之前","并不需要","中","跟随","单向","变成","反馈","不同","时候","其中","而是","节点","可以","传输","我们","问","的","这么","有所","发给","是","应答","信息","应用","答","这种","实现","service","一直","发","数据","在","频率","模型","话题","最新","ros","到","和","通信","然后","相机","成为","物体","更","通信模型","并","形式","或者","发送","此时","继续","上层","查询","得到","需要","有所不同"],"title":"通信模型","title_tokens":["模型","通信模型","通信"]},{"location":"hhp/3.2_%E5%A4%9A%E8%8A%82%E7%82%B9%E6%9C%8D%E5%8A%A1%E9%80%9A%E4%BF%A1/#_3","text":"从服务的实现机制上来看，这种你问我答的形式叫做 客户端/服务器模型 ，简称为CS模型，客户端在需要某些数据的时候，针对某个具体的服务，发送请求信息，服务器端收到请求之后，就会进行处理并反馈应答信息。 这种通信机制在生活中也很常见，比如我们经常浏览的各种网页，此时你的电脑浏览器就是客户端，通过域名或者各种操作，向网站服务器发送请求，服务器收到之后返回需要展现的页面数据。","text_tokens":["实现","比如","各种","反馈","服务","之后","经常","时候","数据","某个","/","务器","页面","在","客户","会","也","模型","常见","很","针对","就","域名","cs","进行","客户端","返回","从","，","通信","就是","问","我们","浏览","的","网页","某些","展现","处理","。","在生活中","向","服务器端","浏览器","你","简称","并","形式","生活","叫做"," ","我","为","请求","收到","或者","操作","服务器发送","发送","应答","具体","上","此时","电脑","来看","机制","需要","信息","答","通过","这种","网站","服务器"],"title":"客户端/服务器模型","title_tokens":["模型","服务","客户端","/","务器","客户","服务器"]},{"location":"hhp/3.2_%E5%A4%9A%E8%8A%82%E7%82%B9%E6%9C%8D%E5%8A%A1%E9%80%9A%E4%BF%A1/#_4","text":"这个过程一般要求越快越好，假设服务器半天没有反应，你的浏览器一直转圈圈，那有可能是服务器宕机了，或者是网络不好，所以相比话题通信，在服务通信中，客户端可以通过接收到的应答信息，判断服务器端的状态，我们也称之为同步通信。","text_tokens":["所以","服务","越好","要求","一直","不好","判断","务器","圈圈","在","客户","也","之为","话题","反应","越快","客户端","假设","可能","到","半天","，","通信","可以","我们","浏览","的","接收","那有","。","越快越好","浏览器","你","网络","信息","称之为","转圈圈","过程","或者","这个","宕机","是","了","相比","应答","转圈","状态","同步","一般","通过","服务器端","没有","中","服务器"],"title":"同步通信","title_tokens":["同步","通信"]},{"location":"hhp/3.2_%E5%A4%9A%E8%8A%82%E7%82%B9%E6%9C%8D%E5%8A%A1%E9%80%9A%E4%BF%A1/#_5","text":"比如古月居这个网站，服务器是唯一存在的，并没有多个完全一样的古月居网站，但是可以访问古月居网站的客户端是不唯一的，大家每一个人都可以看到同样的界面。所以服务通信模型中，服务器端唯一，但客户端可以不唯一。","text_tokens":["唯一","比如","所以","大家","服务","界面","多个","务器","客户","模型","看到","一个","都","人","古月","客户端","，","可以","通信","的","中","但是","。","完全","访问","通信模型","不","并","一样","同样","这个","每","是","居","但","存在","服务器端","没有","网站","服务器"],"title":"一对多通信","title_tokens":["多","通信","一对"]},{"location":"hhp/3.2_%E5%A4%9A%E8%8A%82%E7%82%B9%E6%9C%8D%E5%8A%A1%E9%80%9A%E4%BF%A1/#_6","text":"和话题通信类似，服务通信的核心还是要传递数据，数据变成了两个部分，一个 请求的数据 ，比如请求苹果位置的命令，还有一个 反馈的数据 ，比如反馈苹果坐标位置的数据，这些数据和话题消息一样，在ROS中也是要标准定义的，话题使用.msg文件定义，服务使用的是.srv文件定义，后续我们会给大家介绍定义的方法。","text_tokens":["给","变成","比如","反馈","服务","标准","大家","方法","苹果","数据","msg","在","也","部分","传递","这些","会","定义","后续","一个","话题","ros","和","，","通信","我们","的","传递数据","类似","命令","要","。","核心","坐标","一样","介绍"," ","请求","位置","消息","了","是","还有","使用","还是","两个","srv","文件","中","."],"title":"服务接口","title_tokens":["服务","接口"]},{"location":"hhp/3.2_%E5%A4%9A%E8%8A%82%E7%82%B9%E6%9C%8D%E5%8A%A1%E9%80%9A%E4%BF%A1/#_7","text":"了解了服务通信的原理，接下来我们就要开始编写代码啦，我们尝试通过服务实现一个加法求解器的功能。","text_tokens":["实现","服务","尝试","器","加法","下来","一个","啦","求解","功能","通信","，","我们","的","就要","原理","。","编写","了","接下","代码","了解","接下来","通过","开始"],"title":"编程方法","title_tokens":["编程","方法"]},{"location":"hhp/3.2_%E5%A4%9A%E8%8A%82%E7%82%B9%E6%9C%8D%E5%8A%A1%E9%80%9A%E4%BF%A1/#_8","text":"当我们需要计算两个加数的求和结果时，就通过客户端节点，将两个加数封装成请求数据，针对服务“add_two_ints”发送出去，提供这个服务的服务器端节点，收到请求数据后，开始进行加法计算，并将求和结果封装成应答数据，反馈给客户端，之后客户端就可以得到想要的结果啦。 我们一起操作下这个例程。 $ source /opt/tros/local_setup.bash $ source install/local_setup.bash $ ros2 run learning_service_cpp server $ ros2 run learning_service_cpp client 2 3 话题和服务是最为常用的两种数据通信方法，前者适合传感器、控制指令等周期性、单向传输的数据，后者适合一问一答，同步性要求更高的数据，比如获取机器视觉识别到的目标位置。","text_tokens":["服务","一起","获取","local","就","进行","两种","周期","，","机器","识别","2"," ","cpp","这个","位置","run","出去","同步","控制指令","tros","提供","开始","通过","最为",".","给","比如","封装","加数","求和","之后","目标","视觉","针对","控制","高","。","“","install","后者","后","请求","learning","同步性","服务器","单向","当","opt","反馈","方法","加法","客户","例程","add","、","客户端","节点","可以","前者","传输","我们","的","数据通信","一问一答","结果","收到","client","是","ints","应答","计算","server","两个","将","setup","想要","ros2","适合","周期性","感器","等","$","service","要求","two","数据","/","务器","数据通","_","”","下","指令","传感","时","话题","啦","到","和","通信","更","并","3","成","操作","发送","传感器","得到","需要","source","bash","服务器端","常用"],"title":"运行示例程序","title_tokens":["运行","示例","程序"]},{"location":"hhp/3.2_%E5%A4%9A%E8%8A%82%E7%82%B9%E6%9C%8D%E5%8A%A1%E9%80%9A%E4%BF%A1/#_9","text":"服务器端add_two_ints_server.cpp： #include \"rclcpp/rclcpp.hpp\" #include \"learning_service_cpp/srv/add_two_ints.hpp\" #include <memory> void add ( const std::shared_ptr<learning_service_cpp::srv::AddTwoInts::Request> request, std::shared_ptr<learning_service_cpp::srv::AddTwoInts::Response> response ) { response->sum = request->a + request->b ; RCLCPP_INFO ( rclcpp::get_logger ( \"rclcpp\" ) , \"Incoming request\\na: %ld\" \" b: %ld\" , request->a, request->b ) ; RCLCPP_INFO ( rclcpp::get_logger ( \"rclcpp\" ) , \"sending back response: [%ld]\" , ( long int ) response->sum ) ; } int main ( int argc, char **argv ) { rclcpp::init ( argc, argv ) ; std::shared_ptr<rclcpp::Node> node = rclcpp::Node::make_shared ( \"add_two_ints_server\" ) ; rclcpp::Service<learning_service_cpp::srv::AddTwoInts>::SharedPtr service = node->create_service<learning_service_cpp::srv::AddTwoInts> ( \"add_two_ints\" , & add ) ; RCLCPP_INFO ( rclcpp::get_logger ( \"rclcpp\" ) , \"Ready to add two ints.\" ) ; rclcpp::spin ( node ) ; rclcpp::shutdown () ; } 客户端add_two_ints_client.cpp： #include \"rclcpp/rclcpp.hpp\" #include \"learning_service_cpp/srv/add_two_ints.hpp\" #include <chrono> #include <cstdlib> #include <memory> using namespace std :: chrono_literals ; int main ( int argc , char ** argv ) { rclcpp :: init ( argc , argv ); if ( argc != 3 ) { RCLCPP_INFO ( rclcpp :: get_logger ( \"rclcpp\" ), \"usage: add_two_ints_client X Y\" ); return 1 ; } std :: shared_ptr < rclcpp :: Node > node = rclcpp :: Node :: make_shared ( \"add_two_ints_client\" ); rclcpp :: Client < learning_service_cpp :: srv :: AddTwoInts >:: SharedPtr client = node -> create_client < learning_service_cpp :: srv :: AddTwoInts > ( \"add_two_ints\" ); auto request = std :: make_shared < learning_service_cpp :: srv :: AddTwoInts :: Request > (); request -> a = atoll ( argv [ 1 ]); request -> b = atoll ( argv [ 2 ]); while ( ! client -> wait_for_service ( 1 s )) { if ( ! rclcpp :: ok ()) { RCLCPP_ERROR ( rclcpp :: get_logger ( \"rclcpp\" ), \"Interrupted while waiting for the service. Exiting.\" ); return 0 ; } RCLCPP_INFO ( rclcpp :: get_logger ( \"rclcpp\" ), \"service not available, waiting again...\" ); } auto result = client -> async_send_request ( request ); // Wait for the result. if ( rclcpp :: spin_until_future_complete ( node , result ) == rclcpp :: FutureReturnCode :: SUCCESS ) { RCLCPP_INFO ( rclcpp :: get_logger ( \"rclcpp\" ), \"Sum: %ld\" , result . get () -> sum ); } else { RCLCPP_ERROR ( rclcpp :: get_logger ( \"rclcpp\" ), \"Failed to call service add_two_ints\" ); } rclcpp :: shutdown (); return 0 ; }","text_tokens":["ready","服务","!",":","=","}","{","to","complete","else","(","x","b","if",";","0","while","incoming","2","call"," ","cpp","async","-","usage","chrono","available","addtwoints","create","\"",".","failed","shared","using","waiting",")","ok","&","：","return","1","for","a","sending","int","exiting","[","interrupted","\\","std","result","learning","srv","void","*","cstdlib","node","sum","服务器","ld","y","futurereturncode","ptr","back","#","get","客户","info","request","add","main","客户端","long","success","again","future","namespace","spin","rclcpp","error","char","argv","not","hpp","<","client",">","ints","server","atoll","na","shutdown","service","+","literals","two","/","务器","_","argc","the","response","...","%","s","]",",","include","3","auto","wait","send","make","const","init","logger","memory","until","sharedptr","服务器端"],"title":"代码解析","title_tokens":["解析","代码"]},{"location":"hhp/3.3_%E5%A4%9A%E8%8A%82%E7%82%B9%E5%8A%A8%E4%BD%9C%E9%80%9A%E4%BF%A1/","text":"多节点动作通信 机器人是一个复杂的智能系统，并不仅仅是键盘遥控运动、识别某个目标这么简单，我们需要实现的是送餐、送货、分拣等满足具体场景需求的机器人。 在这些应用功能的实现中，另外一种ROS通信机制也会被常常用到——那就是 动作 。从这个名字上就可以很好理解这个概念的含义，这种通信机制的目的就是便于 对机器人某一完整行为的流程进行管理 。 通信模型 举个例子，比如我们想让机器人转个圈，这肯定不是一下就可以完成的，机器人得一点一点旋转，直到360度才能结束，假设机器人并不在我们眼前，发出指令后，我们根本不知道机器人到底有没有开始转圈，转到哪里了？ OK，现在我们需要的是一个反馈，比如每隔1s，告诉我们当前转到多少度了，10度、20度、30度，一段时间之后，到了360度，再发送一个信息，表示动作执行完成。 这样一个需要执行一段时间的行为，使用动作的通信机制就更为合适，就像装了一个进度条，我们可以随时把控进度，如果运动过程当中，我们还可以随时发送一个取消运动的命令。 客户端/服务器模型 动作和服务类似，使用的也是客户端和服务器模型，客户端发送动作的目标，想让机器人干什么，服务器端执行动作过程， 控制机器人达到运动的目标，同时周期反馈动作执行过程中的状态。 客户端发送一个运动的目标，想让机器人动起来，服务器端收到之后，就开始控制机器人运动，一边运动，一边反馈当前的状态，如果是一个导航动作，这个反馈可能是当前所处的坐标，如果是机械臂抓取，这个反馈可能又是机械臂的实时姿态。当运动执行结束后，服务器再反馈一个动作结束的信息。整个通信过程就此结束。 一对多通信 和服务一样，动作通信中的客户端可以有多个，大家都可以发送运动命令，但是服务器端只能有一个，毕竟只有一个机器人，先执行完成一个动作，才能执行下一个动作。 同步通信 既然有反馈，那动作也是一种同步通信机制，之前我们也介绍过，动作过程中的数据通信接口，使用.action文件进行定义。 由服务和话题合成 大家再仔细看下上边的动图，是不是还会发现一个隐藏的秘密。 动作的三个通信模块，竟然有两个是服务，一个是话题，当客户端发送运动目标时，使用的是服务的请求调用，服务器端也会反馈一个应带，表示收到命令。动作的反馈过程，其实就是一个话题的周期发布，服务器端是发布者，客户端是订阅者。 没错，动作是一种应用层的通信机制，其底层就是基于话题和服务来实现的。 编程方法 相比之前话题和服务的程序，动作通信的例程相对较长，我们一起来运行并分析一下。 运行示例程序 $ source /opt/tros/local_setup.bash $ source install/local_setup.bash $ ros2 run learning_action_cpp server $ ros2 run learning_action_cpp client 代码解析 动作的服务器fibonacci_action_server.cpp： #include <inttypes.h> #include <memory> #include \"learning_action_cpp/action/fibonacci.hpp\" #include \"rclcpp/rclcpp.hpp\" // TODO(jacobperron): Remove this once it is included as part of 'rclcpp.hpp' #include \"rclcpp_action/rclcpp_action.hpp\" class MinimalActionServer : public rclcpp :: Node { public : using Fibonacci = learning_action_cpp :: action :: Fibonacci ; using GoalHandleFibonacci = rclcpp_action :: ServerGoalHandle < Fibonacci > ; explicit MinimalActionServer ( const rclcpp :: NodeOptions & options = rclcpp :: NodeOptions ()) : Node ( \"minimal_action_server\" , options ) { using namespace std :: placeholders ; this -> action_server_ = rclcpp_action :: create_server < Fibonacci > ( this -> get_node_base_interface (), this -> get_node_clock_interface (), this -> get_node_logging_interface (), this -> get_node_waitables_interface (), \"fibonacci\" , std :: bind ( & MinimalActionServer :: handle_goal , this , _1 , _2 ), std :: bind ( & MinimalActionServer :: handle_cancel , this , _1 ), std :: bind ( & MinimalActionServer :: handle_accepted , this , _1 )); } private : rclcpp_action :: Server < Fibonacci >:: SharedPtr action_server_ ; rclcpp_action :: GoalResponse handle_goal ( const rclcpp_action :: GoalUUID & uuid , std :: shared_ptr < const Fibonacci :: Goal > goal ) { RCLCPP_INFO ( this -> get_logger (), \"Received goal request with order %d\" , goal -> order ); ( void ) uuid ; // Let's reject sequences that are over 9000 if ( goal -> order > 9000 ) { return rclcpp_action :: GoalResponse :: REJECT ; } return rclcpp_action :: GoalResponse :: ACCEPT_AND_EXECUTE ; } rclcpp_action :: CancelResponse handle_cancel ( const std :: shared_ptr < GoalHandleFibonacci > goal_handle ) { RCLCPP_INFO ( this -> get_logger (), \"Received request to cancel goal\" ); ( void ) goal_handle ; return rclcpp_action :: CancelResponse :: ACCEPT ; } void execute ( const std :: shared_ptr < GoalHandleFibonacci > goal_handle ) { RCLCPP_INFO ( this -> get_logger (), \"Executing goal\" ); rclcpp :: Rate loop_rate ( 1 ); const auto goal = goal_handle -> get_goal (); auto feedback = std :: make_shared < Fibonacci :: Feedback > (); auto & sequence = feedback -> sequence ; sequence . push_back ( 0 ); sequence . push_back ( 1 ); auto result = std :: make_shared < Fibonacci :: Result > (); for ( int i = 1 ; ( i < goal -> order ) && rclcpp :: ok (); ++ i ) { // Check if there is a cancel request if ( goal_handle -> is_canceling ()) { result -> sequence = sequence ; goal_handle -> canceled ( result ); RCLCPP_INFO ( this -> get_logger (), \"Goal Canceled\" ); return ; } // Update sequence sequence . push_back ( sequence [ i ] + sequence [ i - 1 ]); // Publish feedback goal_handle -> publish_feedback ( feedback ); RCLCPP_INFO ( this -> get_logger (), \"Publish Feedback\" ); loop_rate . sleep (); } // Check if goal is done if ( rclcpp :: ok ()) { result -> sequence = sequence ; goal_handle -> succeed ( result ); RCLCPP_INFO ( this -> get_logger (), \"Goal Succeeded\" ); } } void handle_accepted ( const std :: shared_ptr < GoalHandleFibonacci > goal_handle ) { using namespace std :: placeholders ; // this needs to return quickly to avoid blocking the executor, so spin up a new thread std :: thread { std :: bind ( & MinimalActionServer :: execute , this , _1 ), goal_handle }. detach (); } }; // class MinimalActionServer int main ( int argc , char ** argv ) { rclcpp :: init ( argc , argv ); auto action_server = std :: make_shared < MinimalActionServer > (); rclcpp :: spin ( action_server ); rclcpp :: shutdown (); return 0 ; } 动作的客户端fibonacci_action_client.cpp： #include <inttypes.h> #include <memory> #include <string> #include <iostream> #include \"learning_action_cpp/action/fibonacci.hpp\" #include \"rclcpp/rclcpp.hpp\" // TODO ( jacobperron ) : Remove this once it is included as part of 'rclcpp.hpp' #include \"rclcpp_action/rclcpp_action.hpp\" class MinimalActionClient : public rclcpp::Node { public: using Fibonacci = learning_action_cpp::action::Fibonacci ; using GoalHandleFibonacci = rclcpp_action::ClientGoalHandle<Fibonacci> ; explicit MinimalActionClient ( const rclcpp::NodeOptions & node_options = rclcpp::NodeOptions ()) : Node ( \"minimal_action_client\" , node_options ) , goal_done_ ( false ) { this->client_ptr_ = rclcpp_action::create_client<Fibonacci> ( this->get_node_base_interface () , this->get_node_graph_interface () , this->get_node_logging_interface () , this->get_node_waitables_interface () , \"fibonacci\" ) ; this->timer_ = this->create_wall_timer ( std::chrono::milliseconds ( 500 ) , std::bind ( & MinimalActionClient::send_goal, this )) ; } bool is_goal_done () const { return this->goal_done_ ; } void send_goal () { using namespace std::placeholders ; this->timer_->cancel () ; this->goal_done_ = false ; if ( !this->client_ptr_ ) { RCLCPP_ERROR ( this->get_logger () , \"Action client not initialized\" ) ; } if ( !this->client_ptr_->wait_for_action_server ( std::chrono::seconds ( 10 ))) { RCLCPP_ERROR ( this->get_logger () , \"Action server not available after waiting\" ) ; this->goal_done_ = true ; return ; } auto goal_msg = Fibonacci::Goal () ; goal_msg.order = 10 ; RCLCPP_INFO ( this->get_logger () , \"Sending goal\" ) ; auto send_goal_options = rclcpp_action::Client<Fibonacci>::SendGoalOptions () ; send_goal_options.goal_response_callback = std::bind ( & MinimalActionClient::goal_response_callback, this, _1 ) ; send_goal_options.feedback_callback = std::bind ( & MinimalActionClient::feedback_callback, this, _1, _2 ) ; send_goal_options.result_callback = std::bind ( & MinimalActionClient::result_callback, this, _1 ) ; auto goal_handle_future = this->client_ptr_->async_send_goal ( goal_msg, send_goal_options ) ; } private: rclcpp_action::Client<Fibonacci>::SharedPtr client_ptr_ ; rclcpp::TimerBase::SharedPtr timer_ ; bool goal_done_ ; void goal_response_callback ( std::shared_future<GoalHandleFibonacci::SharedPtr> future ) { auto goal_handle = future.get () ; if ( !goal_handle ) { RCLCPP_ERROR ( this->get_logger () , \"Goal was rejected by server\" ) ; } else { RCLCPP_INFO ( this->get_logger () , \"Goal accepted by server, waiting for result\" ) ; } } void feedback_callback ( GoalHandleFibonacci::SharedPtr, const std::shared_ptr<const Fibonacci::Feedback> feedback ) { RCLCPP_INFO ( this->get_logger () , \"Next number in sequence received: %\" PRId32, feedback->sequence.back ()) ; } void result_callback ( const GoalHandleFibonacci::WrappedResult & result ) { this->goal_done_ = true ; switch ( result.code ) { case rclcpp_action::ResultCode::SUCCEEDED: break ; case rclcpp_action::ResultCode::ABORTED: RCLCPP_ERROR ( this->get_logger () , \"Goal was aborted\" ) ; return ; case rclcpp_action::ResultCode::CANCELED: RCLCPP_ERROR ( this->get_logger () , \"Goal was canceled\" ) ; return ; default: RCLCPP_ERROR ( this->get_logger () , \"Unknown result code\" ) ; return ; } RCLCPP_INFO ( this->get_logger () , \"Result received\" ) ; for ( auto number : result.result->sequence ) { RCLCPP_INFO ( this->get_logger () , \"%\" PRId32, number ) ; } } } ; // class MinimalActionClient int main ( int argc, char ** argv ) { rclcpp::init ( argc, argv ) ; auto action_client = std::make_shared<MinimalActionClient> () ; while ( !action_client->is_goal_done ()) { rclcpp::spin_some ( action_client ) ; } rclcpp::shutdown () ; return 0 ; }","text_tokens":["某一","由","avoid","bind","就","是不是","inttypes","，","wrappedresult","？","识别","break","sequences","旋转","async","就此","概念","状态","class","up","哪里","同步","was","发布者","create","d","h","不仅","目标","肯定","by","一个","：","milliseconds","就此结束","来","动图","姿态","段时间","sleep","360","i","后","[","例子","使用","rate","没有","中","达到","合适","系统","什么","minimalactionclient","也","还会","客户端","quickly","succeeded","一点一点","可以","把","executor","命令","spin","not","in","需求","介绍","只有","不是","两个","and","应用","这种","同时","理解","some","cancel","jacobperron","$","+","实时","务器","常常","多少","模型","整个","很","callback","知道","话题","argc","行为","]","基于","include","iostream","圈","'","const","如果","发送","init","文件","不仅仅","三个","满足","source","clientgoalhandle","push","得","执行","有没有","=","feedback","needs","to","so","(","动","is","其实","while","控","2","了","相比","as","private","代码","succeed","of","机制","抓取","完成","流程","这样",".","\"","那","比如","done","true","&&","wall","using","waiting","举个","告诉","会","ok","都","1","switch","表示","accepted","。","再","install","options","there","detach","executing","base","毕竟","void","opt","minimal","眼前","起来","方法","ptr","当中","发现","又","canceled","分拣","info","request","送餐","节点","namespace","但是","argv","合成","_-","++","client","智能","送货","用到","uuid","根本","过程","实现","shutdown","rejected","/","case","_","下","时","假设","到","和","模块","进度条","才能","%","s","通信模型","once","不","坐标","并","wait","转个","send","string","false","prid32","public","一点","含义","还","10","结束","服务器端","服务","!",":","reject","动作","}","local","sendgoaloptions","{","timerbase","进行","场景","从","if",";","0","are","发布","编程","cpp","goal","具体","run","todo","available","另外","转","上边","开始","initialized","订阅","多个","程序","goalresponse","servergoalhandle","timer","现在","一边","更为",")","it","placeholders","装","canceling","&","想","多少度","minimalactionserver","for","return","机器人","控制","就是","较长","对","default","让","一样","int","请求","check","number","result","learning","之前","*","应带","logging","node","500","服务器","简单","接口","nodeoptions","execute","时间","update","back","#","get","一","future","this","goalhandlefibonacci","相对","这么","rclcpp","char","发出","臂","<","hpp","是",">","loop","上","一段时间","setup","完整","键盘","秘密","大家","应用层","数据","msg","—","度","that","graph","ros","直到","fibonacci","response","通信","过","隐藏","管理","机械","30","一段","aborted","9000","unknown","explicit","blocking","new","logger","memory","运行","bash","当前","order","好","interface","取消","publish","sequence","某个","一种","after","定义","remove","received","周期","复杂","clock","机器","else","解析","resultcode"," ","这个","转圈","-","被","chrono","tros","included","action","示例","shared","先","仔细","之后","目的","这","多","let","part","功能","没错","到底","类似","handle","cancelresponse","a","随时","看","sending","code","20","运动","thread","std","seconds","next","进度","当","便于","反馈","accept","分析","像","客户","例程","main","、","可能","1s","waitables","我们","的","底层","名字","error","bool","既然","导航","干什么","收到","者","server","调用","其","ros2","over","信息","一下","goaluuid","等","在","这些","通信接口","指令","the","仅仅","一对","所处","每隔","遥控",",","auto","make","有","只能","竟然","需要","with","sharedptr"],"title":"多节点动作通信","title_tokens":["多","通信","节点","动作"]},{"location":"hhp/3.3_%E5%A4%9A%E8%8A%82%E7%82%B9%E5%8A%A8%E4%BD%9C%E9%80%9A%E4%BF%A1/#_1","text":"机器人是一个复杂的智能系统，并不仅仅是键盘遥控运动、识别某个目标这么简单，我们需要实现的是送餐、送货、分拣等满足具体场景需求的机器人。 在这些应用功能的实现中，另外一种ROS通信机制也会被常常用到——那就是 动作 。从这个名字上就可以很好理解这个概念的含义，这种通信机制的目的就是便于 对机器人某一完整行为的流程进行管理 。","text_tokens":["实现","那","某一","便于","简单","等","系统","不仅","某个","目标","一种","—","动作","目的","在","也","这些","分拣","会","常常","很","就","一个","、","ros","送餐","场景","进行","功能","仅仅","复杂","机器人","，","机器","通信","就是","我们","从","可以","的","对","管理","行为","。","这么","遥控","名字","识别","需求","并","运动"," ","这个","智能","是","具体","上","概念","送货","含义","被","用到","机制","不仅仅","键盘","这种","需要","满足","另外","完整","应用","好","流程","中","理解"],"title":"多节点动作通信","title_tokens":["多","通信","节点","动作"]},{"location":"hhp/3.3_%E5%A4%9A%E8%8A%82%E7%82%B9%E5%8A%A8%E4%BD%9C%E9%80%9A%E4%BF%A1/#_2","text":"举个例子，比如我们想让机器人转个圈，这肯定不是一下就可以完成的，机器人得一点一点旋转，直到360度才能结束，假设机器人并不在我们眼前，发出指令后，我们根本不知道机器人到底有没有开始转圈，转到哪里了？ OK，现在我们需要的是一个反馈，比如每隔1s，告诉我们当前转到多少度了，10度、20度、30度，一段时间之后，到了360度，再发送一个信息，表示动作执行完成。 这样一个需要执行一段时间的行为，使用动作的通信机制就更为合适，就像装了一个进度条，我们可以随时把控进度，如果运动过程当中，我们还可以随时发送一个取消运动的命令。","text_tokens":["得","执行","有没有","取消","动作","就","，","机器","？","控"," ","旋转","了","转圈","机制","哪里","转","开始","完成","这样","比如","之后","现在","更为","举个","告诉","装","这","肯定","ok","一个","想","多少度","机器人","到底","表示","。","让","随时","段时间","20","再","360","运动","后","例子","使用","进度","没有","合适","反馈","眼前","时间","像","当中","、","1s","一点一点","可以","把","我们","的","命令","发出","不是","是","一段时间","信息","根本","一下","过程","度","在","多少","指令","知道","假设","直到","到","通信","进度条","才能","行为","每隔","不","30","一段","并","转个","圈","如果","发送","一点","还","当前","需要","10","结束"],"title":"通信模型","title_tokens":["模型","通信模型","通信"]},{"location":"hhp/3.3_%E5%A4%9A%E8%8A%82%E7%82%B9%E5%8A%A8%E4%BD%9C%E9%80%9A%E4%BF%A1/#_3","text":"动作和服务类似，使用的也是客户端和服务器模型，客户端发送动作的目标，想让机器人干什么，服务器端执行动作过程， 控制机器人达到运动的目标，同时周期反馈动作执行过程中的状态。 客户端发送一个运动的目标，想让机器人动起来，服务器端收到之后，就开始控制机器人运动，一边运动，一边反馈当前的状态，如果是一个导航动作，这个反馈可能是当前所处的坐标，如果是机械臂抓取，这个反馈可能又是机械臂的实时姿态。当运动执行结束后，服务器再反馈一个动作结束的信息。整个通信过程就此结束。","text_tokens":["达到","当","反馈","服务","执行","开始","起来","什么","之后","实时","一边","动作","目标","又","务器","客户","也","模型","整个","就","一个","想","客户端","可能","和","周期","机器人","，","机器","控制","通信","就此结束","的","类似","中","动","所处","机械","。","姿态","让","坐标","再","导航","信息","运动","臂","过程","干什么"," ","收到","这个","后","是","使用","如果","发送","就此","状态","抓取","当前","结束","服务器端","同时","服务器"],"title":"客户端/服务器模型","title_tokens":["模型","服务","客户端","/","务器","客户","服务器"]},{"location":"hhp/3.3_%E5%A4%9A%E8%8A%82%E7%82%B9%E5%8A%A8%E4%BD%9C%E9%80%9A%E4%BF%A1/#_4","text":"和服务一样，动作通信中的客户端可以有多个，大家都可以发送运动命令，但是服务器端只能有一个，毕竟只有一个机器人，先执行完成一个动作，才能执行下一个动作。","text_tokens":["大家","服务","先","执行","多个","动作","务器","客户","下","一个","都","客户端","和","机器人","，","通信","可以","机器","的","才能","命令","但是","。","一样","运动","只有","毕竟","发送","有","只能","服务器端","完成","中","服务器"],"title":"一对多通信","title_tokens":["多","通信","一对"]},{"location":"hhp/3.3_%E5%A4%9A%E8%8A%82%E7%82%B9%E5%8A%A8%E4%BD%9C%E9%80%9A%E4%BF%A1/#_5","text":"既然有反馈，那动作也是一种同步通信机制，之前我们也介绍过，动作过程中的数据通信接口，使用.action文件进行定义。","text_tokens":["那","action","反馈","接口","动作","一种","数据","也","通信接口","定义","进行","，","通信","过","我们","的","。","既然",".","介绍","是","使用","有","之前","机制","文件","同步","中","过程"],"title":"同步通信","title_tokens":["同步","通信"]},{"location":"hhp/3.3_%E5%A4%9A%E8%8A%82%E7%82%B9%E5%8A%A8%E4%BD%9C%E9%80%9A%E4%BF%A1/#_6","text":"大家再仔细看下上边的动图，是不是还会发现一个隐藏的秘密。 动作的三个通信模块，竟然有两个是服务，一个是话题，当客户端发送运动目标时，使用的是服务的请求调用，服务器端也会反馈一个应带，表示收到命令。动作的反馈过程，其实就是一个话题的周期发布，服务器端是发布者，客户端是订阅者。 没错，动作是一种应用层的通信机制，其底层就是基于话题和服务来实现的。","text_tokens":["实现","当","大家","服务","仔细","反馈","订阅","应用层","动作","发现","目标","一种","务器","客户","也","会","下","一个","话题","是不是","还会","时","客户端","周期","和","没错","，","通信","表示","就是","模块","来","隐藏","的","动图","命令","底层","。","其实","基于","看","再","运动","过程"," ","请求","收到","发布","不是","是","使用","者","发送","有","两个","应用","调用","其","机制","竟然","三个","应带","秘密","上边","服务器端","发布者","服务器"],"title":"由服务和话题合成","title_tokens":["话题","服务","由","和","合成"]},{"location":"hhp/3.3_%E5%A4%9A%E8%8A%82%E7%82%B9%E5%8A%A8%E4%BD%9C%E9%80%9A%E4%BF%A1/#_7","text":"相比之前话题和服务的程序，动作通信的例程相对较长，我们一起来运行并分析一下。","text_tokens":["服务","起来","程序","分析","动作","例程","话题","一","和","，","通信","我们","较长","的","。","相对","并","相比","之前","运行","一下"],"title":"编程方法","title_tokens":["编程","方法"]},{"location":"hhp/3.3_%E5%A4%9A%E8%8A%82%E7%82%B9%E5%8A%A8%E4%BD%9C%E9%80%9A%E4%BF%A1/#_8","text":"$ source /opt/tros/local_setup.bash $ source install/local_setup.bash $ ros2 run learning_action_cpp server $ ros2 run learning_action_cpp client","text_tokens":["opt","action","$","/","_","local","install"," ","cpp","client","run","setup","learning","server","ros2","bash","source","tros","."],"title":"运行示例程序","title_tokens":["运行","示例","程序"]},{"location":"hhp/3.3_%E5%A4%9A%E8%8A%82%E7%82%B9%E5%8A%A8%E4%BD%9C%E9%80%9A%E4%BF%A1/#_9","text":"动作的服务器fibonacci_action_server.cpp： #include <inttypes.h> #include <memory> #include \"learning_action_cpp/action/fibonacci.hpp\" #include \"rclcpp/rclcpp.hpp\" // TODO(jacobperron): Remove this once it is included as part of 'rclcpp.hpp' #include \"rclcpp_action/rclcpp_action.hpp\" class MinimalActionServer : public rclcpp :: Node { public : using Fibonacci = learning_action_cpp :: action :: Fibonacci ; using GoalHandleFibonacci = rclcpp_action :: ServerGoalHandle < Fibonacci > ; explicit MinimalActionServer ( const rclcpp :: NodeOptions & options = rclcpp :: NodeOptions ()) : Node ( \"minimal_action_server\" , options ) { using namespace std :: placeholders ; this -> action_server_ = rclcpp_action :: create_server < Fibonacci > ( this -> get_node_base_interface (), this -> get_node_clock_interface (), this -> get_node_logging_interface (), this -> get_node_waitables_interface (), \"fibonacci\" , std :: bind ( & MinimalActionServer :: handle_goal , this , _1 , _2 ), std :: bind ( & MinimalActionServer :: handle_cancel , this , _1 ), std :: bind ( & MinimalActionServer :: handle_accepted , this , _1 )); } private : rclcpp_action :: Server < Fibonacci >:: SharedPtr action_server_ ; rclcpp_action :: GoalResponse handle_goal ( const rclcpp_action :: GoalUUID & uuid , std :: shared_ptr < const Fibonacci :: Goal > goal ) { RCLCPP_INFO ( this -> get_logger (), \"Received goal request with order %d\" , goal -> order ); ( void ) uuid ; // Let's reject sequences that are over 9000 if ( goal -> order > 9000 ) { return rclcpp_action :: GoalResponse :: REJECT ; } return rclcpp_action :: GoalResponse :: ACCEPT_AND_EXECUTE ; } rclcpp_action :: CancelResponse handle_cancel ( const std :: shared_ptr < GoalHandleFibonacci > goal_handle ) { RCLCPP_INFO ( this -> get_logger (), \"Received request to cancel goal\" ); ( void ) goal_handle ; return rclcpp_action :: CancelResponse :: ACCEPT ; } void execute ( const std :: shared_ptr < GoalHandleFibonacci > goal_handle ) { RCLCPP_INFO ( this -> get_logger (), \"Executing goal\" ); rclcpp :: Rate loop_rate ( 1 ); const auto goal = goal_handle -> get_goal (); auto feedback = std :: make_shared < Fibonacci :: Feedback > (); auto & sequence = feedback -> sequence ; sequence . push_back ( 0 ); sequence . push_back ( 1 ); auto result = std :: make_shared < Fibonacci :: Result > (); for ( int i = 1 ; ( i < goal -> order ) && rclcpp :: ok (); ++ i ) { // Check if there is a cancel request if ( goal_handle -> is_canceling ()) { result -> sequence = sequence ; goal_handle -> canceled ( result ); RCLCPP_INFO ( this -> get_logger (), \"Goal Canceled\" ); return ; } // Update sequence sequence . push_back ( sequence [ i ] + sequence [ i - 1 ]); // Publish feedback goal_handle -> publish_feedback ( feedback ); RCLCPP_INFO ( this -> get_logger (), \"Publish Feedback\" ); loop_rate . sleep (); } // Check if goal is done if ( rclcpp :: ok ()) { result -> sequence = sequence ; goal_handle -> succeed ( result ); RCLCPP_INFO ( this -> get_logger (), \"Goal Succeeded\" ); } } void handle_accepted ( const std :: shared_ptr < GoalHandleFibonacci > goal_handle ) { using namespace std :: placeholders ; // this needs to return quickly to avoid blocking the executor, so spin up a new thread std :: thread { std :: bind ( & MinimalActionServer :: execute , this , _1 ), goal_handle }. detach (); } }; // class MinimalActionServer int main ( int argc , char ** argv ) { rclcpp :: init ( argc , argv ); auto action_server = std :: make_shared < MinimalActionServer > (); rclcpp :: spin ( action_server ); rclcpp :: shutdown (); return 0 ; } 动作的客户端fibonacci_action_client.cpp： #include <inttypes.h> #include <memory> #include <string> #include <iostream> #include \"learning_action_cpp/action/fibonacci.hpp\" #include \"rclcpp/rclcpp.hpp\" // TODO ( jacobperron ) : Remove this once it is included as part of 'rclcpp.hpp' #include \"rclcpp_action/rclcpp_action.hpp\" class MinimalActionClient : public rclcpp::Node { public: using Fibonacci = learning_action_cpp::action::Fibonacci ; using GoalHandleFibonacci = rclcpp_action::ClientGoalHandle<Fibonacci> ; explicit MinimalActionClient ( const rclcpp::NodeOptions & node_options = rclcpp::NodeOptions ()) : Node ( \"minimal_action_client\" , node_options ) , goal_done_ ( false ) { this->client_ptr_ = rclcpp_action::create_client<Fibonacci> ( this->get_node_base_interface () , this->get_node_graph_interface () , this->get_node_logging_interface () , this->get_node_waitables_interface () , \"fibonacci\" ) ; this->timer_ = this->create_wall_timer ( std::chrono::milliseconds ( 500 ) , std::bind ( & MinimalActionClient::send_goal, this )) ; } bool is_goal_done () const { return this->goal_done_ ; } void send_goal () { using namespace std::placeholders ; this->timer_->cancel () ; this->goal_done_ = false ; if ( !this->client_ptr_ ) { RCLCPP_ERROR ( this->get_logger () , \"Action client not initialized\" ) ; } if ( !this->client_ptr_->wait_for_action_server ( std::chrono::seconds ( 10 ))) { RCLCPP_ERROR ( this->get_logger () , \"Action server not available after waiting\" ) ; this->goal_done_ = true ; return ; } auto goal_msg = Fibonacci::Goal () ; goal_msg.order = 10 ; RCLCPP_INFO ( this->get_logger () , \"Sending goal\" ) ; auto send_goal_options = rclcpp_action::Client<Fibonacci>::SendGoalOptions () ; send_goal_options.goal_response_callback = std::bind ( & MinimalActionClient::goal_response_callback, this, _1 ) ; send_goal_options.feedback_callback = std::bind ( & MinimalActionClient::feedback_callback, this, _1, _2 ) ; send_goal_options.result_callback = std::bind ( & MinimalActionClient::result_callback, this, _1 ) ; auto goal_handle_future = this->client_ptr_->async_send_goal ( goal_msg, send_goal_options ) ; } private: rclcpp_action::Client<Fibonacci>::SharedPtr client_ptr_ ; rclcpp::TimerBase::SharedPtr timer_ ; bool goal_done_ ; void goal_response_callback ( std::shared_future<GoalHandleFibonacci::SharedPtr> future ) { auto goal_handle = future.get () ; if ( !goal_handle ) { RCLCPP_ERROR ( this->get_logger () , \"Goal was rejected by server\" ) ; } else { RCLCPP_INFO ( this->get_logger () , \"Goal accepted by server, waiting for result\" ) ; } } void feedback_callback ( GoalHandleFibonacci::SharedPtr, const std::shared_ptr<const Fibonacci::Feedback> feedback ) { RCLCPP_INFO ( this->get_logger () , \"Next number in sequence received: %\" PRId32, feedback->sequence.back ()) ; } void result_callback ( const GoalHandleFibonacci::WrappedResult & result ) { this->goal_done_ = true ; switch ( result.code ) { case rclcpp_action::ResultCode::SUCCEEDED: break ; case rclcpp_action::ResultCode::ABORTED: RCLCPP_ERROR ( this->get_logger () , \"Goal was aborted\" ) ; return ; case rclcpp_action::ResultCode::CANCELED: RCLCPP_ERROR ( this->get_logger () , \"Goal was canceled\" ) ; return ; default: RCLCPP_ERROR ( this->get_logger () , \"Unknown result code\" ) ; return ; } RCLCPP_INFO ( this->get_logger () , \"Result received\" ) ; for ( auto number : result.result->sequence ) { RCLCPP_INFO ( this->get_logger () , \"%\" PRId32, number ) ; } } } ; // class MinimalActionClient int main ( int argc, char ** argv ) { rclcpp::init ( argc, argv ) ; auto action_client = std::make_shared<MinimalActionClient> () ; while ( !action_client->is_goal_done ()) { rclcpp::spin_some ( action_client ) ; } rclcpp::shutdown () ; return 0 ; }","text_tokens":["服务","interface","!",":","=","reject","publish","sequence","动作","feedback","avoid","}","after","needs","sendgoaloptions","{","bind","timerbase","remove","received","to","so","inttypes","clock","else","(","wrappedresult","if","is",";","0","while","resultcode","break","are","2","sequences"," ","cpp","goal","private","as","async","succeed","-","of","class","todo","up","chrono","available","was","create","\"","included",".","done","action","true","&&","shared","d","using","wall","initialized","h","waiting","goalresponse","servergoalhandle","timer",")","it","canceling","placeholders","ok","&","by","let","part","minimalactionserver","：","return","1","push","for","milliseconds","switch","handle","accepted","cancelresponse","default","a","code","sending","sleep","int","options","i","there","detach","[","executing","base","thread","check","std","seconds","number","result","next","learning","void","*","rate","logging","node","500","服务器","minimal","nodeoptions","accept","execute","ptr","minimalactionclient","canceled","back","update","#","get","客户","info","request","main","客户端","quickly","succeeded","waitables","future","namespace","executor","的","this","spin","goalhandlefibonacci","rclcpp","error","char","argv","bool","not","in","_-","<","hpp","++","client",">","loop","server","over","uuid","and","some","cancel","jacobperron","shutdown","goaluuid","rejected","+","msg","/","务器","that","case","_","callback","graph","argc","the","fibonacci","response","%","s","]",",","once","order","include","iostream","auto","wait","send","make","string","'","aborted","9000","const","false","prid32","public","explicit","unknown","blocking","new","init","logger","memory","clientgoalhandle","10","with","sharedptr"],"title":"代码解析","title_tokens":["解析","代码"]},{"location":"hhp/3.4_.%E9%9B%B6%E6%8B%B7%E8%B4%9D%E6%95%B0%E6%8D%AE%E4%BC%A0%E8%BE%93/","text":"零拷贝数据传输 在传统操作系统的数据传输过程中，系统内部会在磁盘、内存、缓存中多次进行数据拷贝，每次都会占用CPU的资源，数据量小的时候还好，随着数据量的增加，CPU的开销也会持续增加，尤其是在机器人图像数据的应用中 ，经常会发生这种问题，导致CPU都在做数据拷贝，没有时间处理其他的应用功能了，直接的感觉就是处理卡顿。 零拷贝技术 针对这种问题，零拷贝技术应运而生。 零拷贝主要的任务就是避免CPU将数据从一块存储拷贝到另外一块存储，避免让CPU做大量的数据拷贝任务，减少不必要的拷贝，或者让别的组件来做这一类简单的数据传输任务，让CPU解脱出来专注于别的任务。这样就可以让系统资源的利用更加有效。 TogetherROS中就提供了灵活、高效的零拷贝功能，可以显著降低大尺寸数据的通信延时和CPU占用，具体有多显著呢，我们不妨进行一个测试。 TogetherROS零拷贝性能测试 我们使用TogetherROS系统内部集成的性能测试工具——performance_test，来评估下开启零拷贝前后的性能差异，这里我们传输的样本数据量是4M。 未开启零拷贝进行数据传输 $ ros2 run performance_test perf_test --reliable --keep-last --history-depth 10 -s 1 -m Array4m -r 100 --max-runtime 30 #未开启 开启零拷贝数据传输： $ ros2 run performance_test perf_test --zero-copy --reliable --keep-last --history-depth 10 -s 1 -m Array4m -r 100 --max-runtime 30 #开启 好的，测试已经跑完了，我们把结果放到这里，来分析一下。 在这个测试中，关键有四个指标： 时延，也就是消息从发布者到订阅者的传输时间。不开启零拷贝的情况下，平均为0.004912s，开启零拷贝之后，速度快了差不多40倍，平均为0.000180s。 CPU使用率，表示通信活动所占用的CPU时间，大家可以看这个utime指标，开启零拷贝之后时间有显著的提升，消耗CPU的资源少了。 驻留内存，包括通信过程中分配的内存和共享内存，是这个maxrss中的数据，开启零拷贝之后，占用的内存也更少。 样本统计，包括测试中发送、接收以及丢失的消息数量，是这组数据，依然是开启零拷贝之后性能更好。 通过测试，对于大数据通信来讲，零拷贝在CPU消耗、内存占用以及通信延迟抖动方面的性能都会更好。 这里只是便于大家感受零拷贝技术的效果，具体编程中如何使用零拷贝机制呢？ 编程开发 为了方便大家使用，TogetherROS针对零拷贝功能进行了封装，风格类似ROS2中话题通信的接口，还是话题通信一样的流程，我们只需要修改几个函数就可以实现啦。 运行例程 $ source /opt/tros/local_setup.bash $ source install/local_setup.bash $ ros2 run hbmem_pubsub talker $ ros2 run hbmem_pubsub listener 代码解析 发布者publisher_hbmem.cpp： #include <chrono> #include <functional> #include <memory> #include <string> #include \"rclcpp/rclcpp.hpp\" #include \"hbmem_pubsub/msg/sample_message.hpp\" using namespace std :: chrono_literals ; class MinimalHbmemPublisher : public rclcpp :: Node { public : MinimalHbmemPublisher () : Node ( \"minimal_hbmem_publisher\" ), count_ ( 0 ) { // 创建publisher_hbmem，topic为\"topic\"，QOS为KEEPLAST(10)，以及默认的可靠传输 publisher_ = this -> create_publisher_hbmem < hbmem_pubsub :: msg :: SampleMessage > ( \"topic\" , 10 ); // 定时器，每隔40毫秒调用一次timer_callback进行消息发送 timer_ = this -> create_wall_timer ( 40 ms , std :: bind ( & MinimalHbmemPublisher :: timer_callback , this )); } private : // 定时器回调函数 void timer_callback () { // 获取要发送的消息 auto loanedMsg = publisher_ -> borrow_loaned_message (); // 判断消息是否可用，可能出现获取消息失败导致消息不可用的情况 if ( loanedMsg . is_valid ()) { // 引用方式获取实际的消息 auto & msg = loanedMsg . get (); // 获取当前时间，单位为us auto time_now = std :: chrono :: duration_cast < std :: chrono :: microseconds > ( std :: chrono :: steady_clock :: now (). time_since_epoch ()). count (); // 对消息的index和time_stamp进行赋值 msg . index = count_ ; msg . time_stamp = time_now ; // 打印发送消息 RCLCPP_INFO ( this -> get_logger (), \"message: %d\" , msg . index ); publisher_ -> publish ( std :: move ( loanedMsg )); // 注意，发送后，loanedMsg已不可用 // 计数器加一 count_ ++ ; } else { // 获取消息失败，丢弃该消息 RCLCPP_INFO ( this -> get_logger (), \"Failed to get LoanMessage!\" ); } } // 定时器 rclcpp :: TimerBase :: SharedPtr timer_ ; // hbmem publisher rclcpp :: PublisherHbmem < hbmem_pubsub :: msg :: SampleMessage >:: SharedPtr publisher_ ; // 计数器 size_t count_ ; }; int main ( int argc , char * argv []) { rclcpp :: init ( argc , argv ); rclcpp :: spin ( std :: make_shared < MinimalHbmemPublisher > ()); rclcpp :: shutdown (); return 0 ; } 订阅者subscriber_hbmem.cpp： #include <memory> #include \"rclcpp/rclcpp.hpp\" #include \"hbmem_pubsub/msg/sample_message.hpp\" class MinimalHbmemSubscriber : public rclcpp :: Node { public : MinimalHbmemSubscriber () : Node ( \"minimal_hbmem_subscriber\" ) { // 创建subscription_hbmem，topic为\"sample\"，QOS为KEEPLAST(10)，以及默认的可靠传输 // 消息回调函数为topic_callback subscription_ = this -> create_subscription_hbmem < hbmem_pubsub :: msg :: SampleMessage > ( \"topic\" , 10 , std :: bind ( & MinimalHbmemSubscriber :: topic_callback , this , std :: placeholders :: _1 )); } private : // 消息回调函数 void topic_callback ( const hbmem_pubsub :: msg :: SampleMessage :: SharedPtr msg ) const { // 注意，msg只能在回调函数中使用，回调函数返回后，该消息就会被释放 // 获取当前时间 auto time_now = std :: chrono :: duration_cast < std :: chrono :: microseconds > ( std :: chrono :: steady_clock :: now (). time_since_epoch ()) . count (); // 计算延时并打印出来 RCLCPP_INFO ( this -> get_logger (), \"msg %d, time cost %dus\" , msg -> index , time_now - msg -> time_stamp ); } // hbmem subscription rclcpp :: SubscriptionHbmem < hbmem_pubsub :: msg :: SampleMessage >:: SharedPtr subscription_ ; }; int main ( int argc , char * argv []) { rclcpp :: init ( argc , argv ); rclcpp :: spin ( std :: make_shared < MinimalHbmemSubscriber > ()); rclcpp :: shutdown (); return 0 ; } 接口汇总 我们整理一下，与ROS2中的话题通信相比，TogetherROS带有零拷贝机制的话题通信接口是这样的。 在发布者中，我们可以使用PublisherHbmem来创建一个发布者对象，然后通过create_publisher_hbmem发布数据，而在订阅者中，SubscriptionHbmem用来创建一个订阅者对象，通过 create_subscription_hbmem订阅需要的数据，至于底层如何完成零拷贝的过程，都交给TogetherROS即可。","text_tokens":["可用","获取","试工","bind","就","borrow","操作系统","keeplast","，","samplemessage","？","loanmessage","系统资源","风格","拷贝","listener","0.004912","loanedmsg","数据量","class","通过","发布者","create","d","感受","随着","问题","抖动","判断","一个","history","返回","：","reliable","提升","来","至于","topic","一类","毫秒","move","后","[","使用","减少","0.000180","函数","没有","中","time","系统","内部","也","显著","赋值","不妨","尤其","可以","把","增加","r","汇总","spin","qos","subscription","这组","4m","而","计算","降低","应用","这种","--","前后","$","max","literals","资源","数据通","整理","呢","callback","话题","argc","subscriber","cpu","接收","方便","last","统计","]","include","const","发送","少","init","方式","做","depth","source","大","测试工具","只是","array4m","出现","stamp","差不多","平均","=","快","工具","to","(","perf","dus","如何","is","打印","pubsub","count","分配","了","private","相比","代码","据传","必要","机制","完成","流程","多次","这样",".","\"","wall","sample","using","利用","开销","关键","带有","hbmem","会","包括","都","不多","与","1","技术","表示","引用","组件","。","未","单位","完","install","传统","共享内存","void","任务","默认","opt","minimal","用来","minimalhbmemsubscriber","info","test","还好","namespace","评估","差异","microseconds","argv","结果","导致","++","集成","零","将","出来","情况","磁盘","cast","更少","一次","过程","实现","us","更加","shutdown","/","_","是否","下","maxrss","用","啦","到","和","解脱","已经","可靠","要","s","%","index","runtime","不","用率","string","操作","public","10","所","!",":","subscriptionhbmem","方面","加一","活动","}","注意","local","{","timerbase","进行","跑","为了","从","以及","指标","性能","if",";","0","zero","定时","发布","编程","cpp","计数器","效果","倍","应运而生","具体","run","40","对象","另外","t","封装","ms","订阅","timer",")","placeholders","针对","&","回调","return","机器人","就是","有效","对","让","一样","int","高效","publisher","开发","100","定时器","一块","缓存","*","数据传输","node","keep","togetherros","简单","接口","时间","延迟","#","get","四个","不可","this","数据通信","处理","时延","rclcpp","char","速度","<","持续","hpp","是",">","setup","于","计数","并打印","样本","performance","不必要","使用率","依然","即可","大家","来讲","大量","放到","size","更好","数据","msg","—","应运","卡顿","通信","30","valid","驻留","duration","logger","memory","运行","bash","当前","好","内存","不必","publisherhbmem","尺寸","steady","publish","对于","图像","已","交给","clock","机器","else","感觉","解析","避免","m"," ","这个","主要","-","失败","chrono","被","几个","开启","丢失","提供","tros","测试","loaned","failed","shared","之后","共享","这","copy","发生","多","功能","类似","延时","每次","看","since","talker","std","专注","别的","便于","utime","分析","cost","经常","时候","拷贝到","小","例程","main","、","可能","传输","我们","的","底层","灵活","消息","epoch","者","只","还是","调用","释放","ros2","functional","数量","一下","这里","在","通信接口","now","存储","然后","message","该","每隔","消耗",",","直接","其他","auto","make","或者","占用","为","minimalhbmempublisher","创建","有","丢弃","修改","只能","需要","实际","sharedptr"],"title":"零拷贝数据传输","title_tokens":["零","据传","数据传输","数据","传输","拷贝"]},{"location":"hhp/3.4_.%E9%9B%B6%E6%8B%B7%E8%B4%9D%E6%95%B0%E6%8D%AE%E4%BC%A0%E8%BE%93/#_1","text":"在传统操作系统的数据传输过程中，系统内部会在磁盘、内存、缓存中多次进行数据拷贝，每次都会占用CPU的资源，数据量小的时候还好，随着数据量的增加，CPU的开销也会持续增加，尤其是在机器人图像数据的应用中 ，经常会发生这种问题，导致CPU都在做数据拷贝，没有时间处理其他的应用功能了，直接的感觉就是处理卡顿。","text_tokens":["系统","时间","开销","时候","数据","内部","随着","经常","问题","资源","在","也","会","小","图像","还好","操作系统","发生","、","进行","都","尤其","卡顿","功能","cpu","机器人","，","机器","就是","传输","增加","的","感觉","处理","。","每次","直接","多次","其他","导致","持续"," ","占用","拷贝","操作","是","了","传统","数据量","据传","缓存","磁盘","做","数据传输","应用","这种","内存","没有","中","过程"],"title":"零拷贝数据传输","title_tokens":["零","据传","数据传输","数据","传输","拷贝"]},{"location":"hhp/3.4_.%E9%9B%B6%E6%8B%B7%E8%B4%9D%E6%95%B0%E6%8D%AE%E4%BC%A0%E8%BE%93/#_2","text":"针对这种问题，零拷贝技术应运而生。 零拷贝主要的任务就是避免CPU将数据从一块存储拷贝到另外一块存储，避免让CPU做大量的数据拷贝任务，减少不必要的拷贝，或者让别的组件来做这一类简单的数据传输任务，让CPU解脱出来专注于别的任务。这样就可以让系统资源的利用更加有效。 TogetherROS中就提供了灵活、高效的零拷贝功能，可以显著降低大尺寸数据的通信延时和CPU占用，具体有多显著呢，我们不妨进行一个测试。","text_tokens":["不必","尺寸","就","进行","从","，","避免","系统资源"," ","拷贝","主要","了","应运而生","具体","据传","必要","另外","提供","这样","测试","利用","问题","这","针对","一个","多","功能","技术","就是","有效","来","组件","延时","。","让","一类","高效","一块","专注","减少","任务","数据传输","别的","中","togetherros","简单","系统","显著","拷贝到","不妨","、","可以","传输","我们","的","灵活","零","将","于","降低","出来","不必要","这种","更加","大量","数据","资源","呢","应运","存储","和","解脱","cpu","通信","或者","占用","有","做","大"],"title":"零拷贝技术","title_tokens":["零","技术","拷贝"]},{"location":"hhp/3.4_.%E9%9B%B6%E6%8B%B7%E8%B4%9D%E6%95%B0%E6%8D%AE%E4%BC%A0%E8%BE%93/#togetherros","text":"我们使用TogetherROS系统内部集成的性能测试工具——performance_test，来评估下开启零拷贝前后的性能差异，这里我们传输的样本数据量是4M。 未开启零拷贝进行数据传输 $ ros2 run performance_test perf_test --reliable --keep-last --history-depth 10 -s 1 -m Array4m -r 100 --max-runtime 30 #未开启 开启零拷贝数据传输： $ ros2 run performance_test perf_test --zero-copy --reliable --keep-last --history-depth 10 -s 1 -m Array4m -r 100 --max-runtime 30 #开启 好的，测试已经跑完了，我们把结果放到这里，来分析一下。 在这个测试中，关键有四个指标： 时延，也就是消息从发布者到订阅者的传输时间。不开启零拷贝的情况下，平均为0.004912s，开启零拷贝之后，速度快了差不多40倍，平均为0.000180s。 CPU使用率，表示通信活动所占用的CPU时间，大家可以看这个utime指标，开启零拷贝之后时间有显著的提升，消耗CPU的资源少了。 驻留内存，包括通信过程中分配的内存和共享内存，是这个maxrss中的数据，开启零拷贝之后，占用的内存也更少。 样本统计，包括测试中发送、接收以及丢失的消息数量，是这组数据，依然是开启零拷贝之后性能更好。 通过测试，对于大数据通信来讲，零拷贝在CPU消耗、内存占用以及通信延迟抖动方面的性能都会更好。 这里只是便于大家感受零拷贝技术的效果，具体编程中如何使用零拷贝机制呢？","text_tokens":["只是","array4m","所","差不多","平均","方面","对于","快","活动","试工","工具","进行","跑","从","以及","，","指标","perf","如何","性能","？","zero","m"," ","发布","编程","这个","拷贝","分配","了","效果","0.004912","倍","具体","run","数据量","-","40","据传","机制","开启","丢失","通过","发布者","测试","订阅","感受","之后","共享","抖动","关键","会","包括","copy","都","history","不多","：","reliable","1","提升","就是","表示","技术","来","。","未","看","完","使用","100","共享内存","数据传输","0.000180","中","keep","togetherros","便于","utime","系统","时间","分析","内部","延迟","#","也","显著","test","四个","、","把","可以","传输","我们","的","r","数据通信","评估","差异","时延","结果","速度","这组","消息","集成","者","是","零","4m","ros2","情况","样本","performance","使用率","数量","--","前后","一下","过程","更少","依然","大家","$","来讲","max","放到","更好","数据","这里","—","资源","在","数据通","呢","_","下","maxrss","到","和","cpu","已经","通信","接收","last","s","统计","消耗","runtime","30","不","用率","为","占用","发送","有","少","驻留","10","depth","大","好","内存","测试工具"],"title":"TogetherROS零拷贝性能测试","title_tokens":["零","测试","togetherros","拷贝","性能"]},{"location":"hhp/3.4_.%E9%9B%B6%E6%8B%B7%E8%B4%9D%E6%95%B0%E6%8D%AE%E4%BC%A0%E8%BE%93/#_3","text":"为了方便大家使用，TogetherROS针对零拷贝功能进行了封装，风格类似ROS2中话题通信的接口，还是话题通信一样的流程，我们只需要修改几个函数就可以实现啦。","text_tokens":["实现","封装","togetherros","大家","接口","针对","就","话题","进行","为了","啦","功能","，","通信","可以","我们","的","方便","类似","。","一样","风格","拷贝","了","使用","零","只","还是","修改","ros2","几个","需要","函数","流程","中"],"title":"编程开发","title_tokens":["编程","开发"]},{"location":"hhp/3.4_.%E9%9B%B6%E6%8B%B7%E8%B4%9D%E6%95%B0%E6%8D%AE%E4%BC%A0%E8%BE%93/#_4","text":"$ source /opt/tros/local_setup.bash $ source install/local_setup.bash $ ros2 run hbmem_pubsub talker $ ros2 run hbmem_pubsub listener","text_tokens":["talker","opt","_","run","setup","pubsub","$","ros2",".","install","bash","/","source"," ","tros","hbmem","listener","local"],"title":"运行例程","title_tokens":["例程","运行"]},{"location":"hhp/3.4_.%E9%9B%B6%E6%8B%B7%E8%B4%9D%E6%95%B0%E6%8D%AE%E4%BC%A0%E8%BE%93/#_5","text":"发布者publisher_hbmem.cpp： #include <chrono> #include <functional> #include <memory> #include <string> #include \"rclcpp/rclcpp.hpp\" #include \"hbmem_pubsub/msg/sample_message.hpp\" using namespace std :: chrono_literals ; class MinimalHbmemPublisher : public rclcpp :: Node { public : MinimalHbmemPublisher () : Node ( \"minimal_hbmem_publisher\" ), count_ ( 0 ) { // 创建publisher_hbmem，topic为\"topic\"，QOS为KEEPLAST(10)，以及默认的可靠传输 publisher_ = this -> create_publisher_hbmem < hbmem_pubsub :: msg :: SampleMessage > ( \"topic\" , 10 ); // 定时器，每隔40毫秒调用一次timer_callback进行消息发送 timer_ = this -> create_wall_timer ( 40 ms , std :: bind ( & MinimalHbmemPublisher :: timer_callback , this )); } private : // 定时器回调函数 void timer_callback () { // 获取要发送的消息 auto loanedMsg = publisher_ -> borrow_loaned_message (); // 判断消息是否可用，可能出现获取消息失败导致消息不可用的情况 if ( loanedMsg . is_valid ()) { // 引用方式获取实际的消息 auto & msg = loanedMsg . get (); // 获取当前时间，单位为us auto time_now = std :: chrono :: duration_cast < std :: chrono :: microseconds > ( std :: chrono :: steady_clock :: now (). time_since_epoch ()). count (); // 对消息的index和time_stamp进行赋值 msg . index = count_ ; msg . time_stamp = time_now ; // 打印发送消息 RCLCPP_INFO ( this -> get_logger (), \"message: %d\" , msg . index ); publisher_ -> publish ( std :: move ( loanedMsg )); // 注意，发送后，loanedMsg已不可用 // 计数器加一 count_ ++ ; } else { // 获取消息失败，丢弃该消息 RCLCPP_INFO ( this -> get_logger (), \"Failed to get LoanMessage!\" ); } } // 定时器 rclcpp :: TimerBase :: SharedPtr timer_ ; // hbmem publisher rclcpp :: PublisherHbmem < hbmem_pubsub :: msg :: SampleMessage >:: SharedPtr publisher_ ; // 计数器 size_t count_ ; }; int main ( int argc , char * argv []) { rclcpp :: init ( argc , argv ); rclcpp :: spin ( std :: make_shared < MinimalHbmemPublisher > ()); rclcpp :: shutdown (); return 0 ; } 订阅者subscriber_hbmem.cpp： #include <memory> #include \"rclcpp/rclcpp.hpp\" #include \"hbmem_pubsub/msg/sample_message.hpp\" class MinimalHbmemSubscriber : public rclcpp :: Node { public : MinimalHbmemSubscriber () : Node ( \"minimal_hbmem_subscriber\" ) { // 创建subscription_hbmem，topic为\"sample\"，QOS为KEEPLAST(10)，以及默认的可靠传输 // 消息回调函数为topic_callback subscription_ = this -> create_subscription_hbmem < hbmem_pubsub :: msg :: SampleMessage > ( \"topic\" , 10 , std :: bind ( & MinimalHbmemSubscriber :: topic_callback , this , std :: placeholders :: _1 )); } private : // 消息回调函数 void topic_callback ( const hbmem_pubsub :: msg :: SampleMessage :: SharedPtr msg ) const { // 注意，msg只能在回调函数中使用，回调函数返回后，该消息就会被释放 // 获取当前时间 auto time_now = std :: chrono :: duration_cast < std :: chrono :: microseconds > ( std :: chrono :: steady_clock :: now (). time_since_epoch ()) . count (); // 计算延时并打印出来 RCLCPP_INFO ( this -> get_logger (), \"msg %d, time cost %dus\" , msg -> index , time_now - msg -> time_stamp ); } // hbmem subscription rclcpp :: SubscriptionHbmem < hbmem_pubsub :: msg :: SampleMessage >:: SharedPtr subscription_ ; }; int main ( int argc , char * argv []) { rclcpp :: init ( argc , argv ); rclcpp :: spin ( std :: make_shared < MinimalHbmemSubscriber > ()); rclcpp :: shutdown (); return 0 ; }","text_tokens":["出现","stamp","publisherhbmem","steady","!",":","=","publish","subscriptionhbmem","加一","可用","获取","}","注意","{","bind","borrow","timerbase","就","进行","to","已","keeplast","以及","clock","，","samplemessage","else","(","dus","if","is","打印",";","0","pubsub","loanmessage","定时","count"," ","发布","cpp","计数器","private","loanedmsg","-","40","class","chrono","失败","被","t","发布者","create","\"",".","loaned","failed","d","wall","sample","using","ms","shared","订阅","timer","判断",")","hbmem","placeholders","会","&","回调","返回","：","return","1","引用","对","延时","单位","topic","毫秒","move","int","后","[","publisher","since","使用","std","定时器","void","*","默认","函数","node","中","time","minimal","时间","cost","#","get","minimalhbmemsubscriber","info","赋值","main","不可","可能","传输","namespace","的","this","spin","microseconds","rclcpp","char","argv","qos","subscription","导致","<","hpp","++","消息","epoch","者",">","计算","调用","释放","出来","计数","情况","并打印","cast","functional","一次","us","shutdown","size","literals","msg","/","在","_","是否","callback","argc","用","now","subscriber","和","可靠","message","该","要","%","每隔","]",",","index","include","auto","valid","make","string","为","const","minimalhbmempublisher","public","创建","发送","丢弃","duration","init","logger","memory","方式","只能","10","当前","实际","sharedptr"],"title":"代码解析","title_tokens":["解析","代码"]},{"location":"hhp/3.4_.%E9%9B%B6%E6%8B%B7%E8%B4%9D%E6%95%B0%E6%8D%AE%E4%BC%A0%E8%BE%93/#_6","text":"我们整理一下，与ROS2中的话题通信相比，TogetherROS带有零拷贝机制的话题通信接口是这样的。 在发布者中，我们可以使用PublisherHbmem来创建一个发布者对象，然后通过create_publisher_hbmem发布数据，而在订阅者中，SubscriptionHbmem用来创建一个订阅者对象，通过 create_subscription_hbmem订阅需要的数据，至于底层如何完成零拷贝的过程，都交给TogetherROS即可。","text_tokens":["togetherros","publisherhbmem","接口","这样","订阅","subscriptionhbmem","用来","数据","带有","hbmem","整理","在","_","通信接口","一个","话题","都","即可","与","交给","，","通信","可以","然后","我们","来","的","create","如何","底层","至于","。","subscription"," ","发布","publisher","拷贝","者","是","零","相比","使用","创建","而","ros2","对象","机制","一下","需要","通过","完成","发布者","中","过程"],"title":"接口汇总","title_tokens":["接口","汇总"]},{"location":"hhp/3.5_%E5%88%86%E5%B8%83%E5%BC%8F%E9%80%9A%E4%BF%A1%E9%85%8D%E7%BD%AE/","text":"分布式通信配置 智能机器人的功能繁多，全都放在一个计算机里，经常会遇到计算能力不够、处理出现卡顿等情况，如果可以将这些任务拆解，分配到多个计算机中运行岂不是可以减轻压力？ 这就是分布式系统， 可以实现多计算平台上的任务分配。 分布式通信 什么叫分布式？ 机器人功能是由各种节点组成的，这些节点可能位于不同的计算机中，这种结构可以将原本资源消耗较多的任务，分配到不同的平台上，减轻计算压力，这就是分布式通信框架的典型应用之一。 比如在这款机器人系统中，就有两个计算平台。 机器人体积比较小，不适合放一个笔记本电脑在上边，于是采用旭日派作为控制器，主要实现传感器驱动、电机控制、AI应用等功能，此外我们还需要在电脑上监控机器人的传感器信息，并且远程控制机器人运动。 两个计算平台之间的通信，看上去还有点复杂，毕竟相互传输的数据还挺多的，不过TogehterROS都已经为我们准备好了，我们只需要在每一个计算上配置好TogehterROS或者ROS2的环境，功能开发上完全不需要做任何变化，实现非常方便。 接下来，我们就带领大家一起来感受下分布式系统的魅力。 分布式网络搭建 旭日派配置完成后，确保已经和你所使用的电脑连接到了同一个局域网络中。接下来我们打通两个计算平台的通信能力。具体需要做什么呢？ 简而言之，什么都不需要做。我们直接用命令行测试一下话题通信的效果。 $ ros2 run examples_rclcpp_minimal_publisher publisher_member_function # 旭日派端 $ ros2 run examples_rclcpp_minimal_subscriber subscriber_member_function # PC端 神奇的事情就这样发生了，旭日X3派上安装的是TogetherROS，我的电脑上安装的是ROS2，他们只要处于同一网络中，就可以实现通信了，感觉就像在一个电脑里一样。 Attention 如使用虚拟机，请将虚拟机网络修改为 桥接模式 不过这也会带来一个问题，如果一个网络中有很多个计算机，我们并不希望他们都可以互通互联，而是可以分组通信，小组之间是无法实现通信的。 分布式网络分组 没问题，ROS2提供了一个DOMAIN的机制，就类似分组一样，处于同一个DOMAIN中的计算机才能通信，我们可以在电脑和旭日X3派端中加入这样一句配置，即可将两者分配到一个小组中： $ export ROS_DOMAIN_ID = <your_domain_id> 如果分配的ID不同，则两者无法实现通信。 话题分布式通信 之前编写的例程是否可以在不修改任何代码的情况下，直接使用呢？ 以话题通信为例，旭日派作为发布者，发布Hello World字符串，电脑作为订阅者，订阅Hello World字符串，我们看下效果如何。 $ ros2 run learning_topic_cpp talker # 旭日派端 $ ros2 run learning_topic_cpp listener # PC端 好啦，我们在分布式网络中测试了ROS一系列例程，都没有任何问题，在实际的机器人开发中，类似的方法会频繁用到，我们几乎不需要任何配置，代码也不需要做任何修改，一切都会变得如此轻松。","text_tokens":["function","出现","所","由","看上去","桥接","处于","=","典型","希望","放","examples","频繁","没","hello","里","不过","打通","就","命令行","局域","简而言之","他们","复杂","，","机器","id","控制器","只要","感觉","如何","？","压力","体积","有点","your","完全","计算能力","同一个","一系","计算机","并且","你","attention"," ","局域网络","驱动","发布","平台","分配","主要","了","魅力","效果","cpp","listener","代码","具体","run","位于","机制","环境","上边","提供","于是","完成","派端","这样","分组","发布者","比如","测试","安装","各种","ai","局域网","订阅","感受","多个","较","之间","问题","一句","会","这","分布式系统","一个","发生","都","多","派","神奇","功能","：","机器人","控制","就是","中有","一系列","类似","互联","放在","配置","。",">","搭建","看","topic","框架","一样","member","运动","后","我","无法","publisher","挺","每","这款","开发","使用","talker","毕竟","采用","learning","之前","两者","任务","笔记本电脑","虚拟","没有","中","小组","一切","模式","togetherros","minimal","不同","以","监控","系统","什么","起来","带来","分布式","经常","同一","像","虚拟机","加入","此外","看上","#","也","任何","小","例程","、","岂","之一","一","遇到","可能","节点","可以","比较","传输","布式","我们","而是","的","如","减轻","命令","处理","rclcpp","能力","分布","拆解","互通","者","<","编写","不是","智能","是","togehterros","相互","准备","计算","只","上","两个","将","domain","接下来","字符串","方法","ros2","用到","情况","原本","适合","信息","应用","电机","这种","系列","旭日","一下","实现","即可","叫","不够","感器","大家","等","$","繁多","为例","请","组成","数据","下来","资源","在","轻松","这些","结构","呢","_","很多","下","是否","而言","卡顿","传感","话题","用","ros","笔记本","到","和","subscriber","非常","x3","通信","已经","啦","作为","变化","方便","才能","如此","消耗","连接","直接","任务分配","不","带领","则","网络","pc","并","确保","export","变得","为","或者","端","个","几乎","笔记","如果","上去","world","接下","电脑","有","传感器","事情","修改","字符","还","全都","运行","需要","远程","做","实际","好","算机"],"title":"分布式通信配置","title_tokens":["分布","通信","分布式","布式","配置"]},{"location":"hhp/3.5_%E5%88%86%E5%B8%83%E5%BC%8F%E9%80%9A%E4%BF%A1%E9%85%8D%E7%BD%AE/#_1","text":"智能机器人的功能繁多，全都放在一个计算机里，经常会遇到计算能力不够、处理出现卡顿等情况，如果可以将这些任务拆解，分配到多个计算机中运行岂不是可以减轻压力？ 这就是分布式系统， 可以实现多计算平台上的任务分配。","text_tokens":["实现","不够","出现","等","繁多","多个","系统","分布式","经常","会","里","这些","这","分布式系统","一个","卡顿","、","多","岂","遇到","功能","到","机器人","，","机器","可以","就是","布式","的","减轻","放在","压力","？","处理","。","计算能力","计算机","能力","任务分配","拆解","分布"," ","平台","分配","不是","智能","如果","计算","上","将","情况","全都","任务","运行","算机","中"],"title":"分布式通信配置","title_tokens":["分布","通信","分布式","布式","配置"]},{"location":"hhp/3.5_%E5%88%86%E5%B8%83%E5%BC%8F%E9%80%9A%E4%BF%A1%E9%85%8D%E7%BD%AE/#_2","text":"什么叫分布式？ 机器人功能是由各种节点组成的，这些节点可能位于不同的计算机中，这种结构可以将原本资源消耗较多的任务，分配到不同的平台上，减轻计算压力，这就是分布式通信框架的典型应用之一。 比如在这款机器人系统中，就有两个计算平台。 机器人体积比较小，不适合放一个笔记本电脑在上边，于是采用旭日派作为控制器，主要实现传感器驱动、电机控制、AI应用等功能，此外我们还需要在电脑上监控机器人的传感器信息，并且远程控制机器人运动。 两个计算平台之间的通信，看上去还有点复杂，毕竟相互传输的数据还挺多的，不过TogehterROS都已经为我们准备好了，我们只需要在每一个计算上配置好TogehterROS或者ROS2的环境，功能开发上完全不需要做任何变化，实现非常方便。 接下来，我们就带领大家一起来感受下分布式系统的魅力。","text_tokens":["由","看上去","典型","放","不过","就","复杂","，","机器","控制器","？","压力","体积","有点","完全","计算机","并且"," ","驱动","平台","分配","主要","了","魅力","位于","环境","上边","于是","比如","各种","ai","感受","较","之间","这","分布式系统","一个","都","多","派","功能","机器人","控制","就是","配置","。","框架","运动","挺","每","这款","开发","毕竟","采用","任务","笔记本电脑","中","不同","监控","什么","系统","起来","分布式","此外","看上","任何","小","、","一","之一","可能","节点","可以","比较","传输","布式","我们","的","减轻","分布","是","只","togehterros","相互","准备","计算","上","两个","将","接下来","ros2","原本","适合","信息","应用","电机","这种","旭日","实现","叫","感器","大家","等","组成","数据","下来","资源","在","这些","结构","下","传感","笔记本","到","非常","通信","已经","作为","变化","方便","消耗","不","带领","为","或者","笔记","上去","接下","电脑","有","传感器","还","做","需要","远程","好","算机"],"title":"分布式通信","title_tokens":["通信","分布式","布式","分布"]},{"location":"hhp/3.5_%E5%88%86%E5%B8%83%E5%BC%8F%E9%80%9A%E4%BF%A1%E9%85%8D%E7%BD%AE/#_3","text":"旭日派配置完成后，确保已经和你所使用的电脑连接到了同一个局域网络中。接下来我们打通两个计算平台的通信能力。具体需要做什么呢？ 简而言之，什么都不需要做。我们直接用命令行测试一下话题通信的效果。 $ ros2 run examples_rclcpp_minimal_publisher publisher_member_function # 旭日派端 $ ros2 run examples_rclcpp_minimal_subscriber subscriber_member_function # PC端 神奇的事情就这样发生了，旭日X3派上安装的是TogetherROS，我的电脑上安装的是ROS2，他们只要处于同一网络中，就可以实现通信了，感觉就像在一个电脑里一样。 Attention 如使用虚拟机，请将虚拟机网络修改为 桥接模式 不过这也会带来一个问题，如果一个网络中有很多个计算机，我们并不希望他们都可以互通互联，而是可以分组通信，小组之间是无法实现通信的。","text_tokens":["function","所","桥接","处于","希望","examples","里","不过","打通","命令行","就","局域","简而言之","他们","，","只要","感觉","？","同一个","你","计算机","attention"," ","局域网络","平台","了","效果","具体","run","派端","完成","这样","分组","测试","安装","局域网","之间","问题","会","这","一个","发生","都","派","神奇","中有","互联","配置","。","一样","member","后","我","无法","publisher","使用","虚拟","中","小组","模式","togetherros","minimal","带来","什么","同一","像","虚拟机","#","也","而是","可以","我们","的","如","命令","rclcpp","能力","互通","是","计算","上","两个","将","接下来","ros2","一下","旭日","实现","$","请","下来","在","呢","_","很多","而言","话题","用","subscriber","到","和","x3","已经","通信","连接","直接","不","网络","pc","并","确保","为","端","个","如果","接下","电脑","事情","修改","做","需要","算机"],"title":"分布式网络搭建","title_tokens":["搭建","网络","分布","分布式","布式"]},{"location":"hhp/3.5_%E5%88%86%E5%B8%83%E5%BC%8F%E9%80%9A%E4%BF%A1%E9%85%8D%E7%BD%AE/#_4","text":"没问题，ROS2提供了一个DOMAIN的机制，就类似分组一样，处于同一个DOMAIN中的计算机才能通信，我们可以在电脑和旭日X3派端中加入这样一句配置，即可将两者分配到一个小组中： $ export ROS_DOMAIN_ID = <your_domain_id> 如果分配的ID不同，则两者无法实现通信。","text_tokens":["实现","旭日","不同","这样","$","处于","=","同一","问题","加入","一句","没","在","_","就","一个","ros","算机","到","和","：","x3","，","通信","可以","id","我们","的","才能","类似","配置","派端","。","your","同一个","计算机","则","一样","<","export"," ","无法","分配","小组","了",">","如果","计算","电脑","将","domain","ros2","机制","两者","提供","分组","中","即可"],"title":"分布式网络分组","title_tokens":["网络","分布","分布式","布式","分组"]},{"location":"hhp/3.5_%E5%88%86%E5%B8%83%E5%BC%8F%E9%80%9A%E4%BF%A1%E9%85%8D%E7%BD%AE/#_5","text":"之前编写的例程是否可以在不修改任何代码的情况下，直接使用呢？ 以话题通信为例，旭日派作为发布者，发布Hello World字符串，电脑作为订阅者，订阅Hello World字符串，我们看下效果如何。 $ ros2 run learning_topic_cpp talker # 旭日派端 $ ros2 run learning_topic_cpp listener # PC端 好啦，我们在分布式网络中测试了ROS一系列例程，都没有任何问题，在实际的机器人开发中，类似的方法会频繁用到，我们几乎不需要任何配置，代码也不需要做任何修改，一切都会变得如此轻松。","text_tokens":["频繁","hello","，","机器","如何","？","一系"," ","发布","cpp","listener","了","效果","代码","run","派端","发布者","测试","订阅","问题","会","都","派","机器人","一系列","类似","配置","。","看","topic","开发","使用","talker","learning","之前","没有","中","一切","以","方法","分布式","#","也","任何","例程","可以","我们","布式","的","分布","编写","者","字符串","用到","ros2","情况","系列","旭日","$","为例","在","轻松","呢","_","是否","下","话题","ros","啦","通信","作为","如此","直接","不","pc","网络","变得","几乎","端","world","电脑","字符","修改","做","需要","实际","好"],"title":"话题分布式通信","title_tokens":["话题","分布","通信","分布式","布式"]},{"location":"hhp/4.1_%E6%95%B0%E5%AD%97%E8%BE%93%E5%85%A5%E4%B8%8E%E8%BE%93%E5%87%BA/","text":"数字输入与输出 数字输入与输出是最常用的一种外设通信方式，虽然每一个端口只有0和1两种状态，但却可以组合出各种各样的变化。 数字输入与输出原理 数字输入与输出，也称为通用输入输出，全称是General-purpose input/output，大部分情况下，我们都会用简称GPIO GPIO的功能，主要是指这个管脚可以作为数字信号的输入或者输出使用，到底是输入还是输出呢，这需要我们使用系统寄存器来进行配置。 当GPIO被设置为输入模式时，就可以读取这个管脚上的电平高低，从而实现读取外部信号的功能，比如外部按键的信号，就是这样读取的。 当GPIO被设置为输出模式时，我们就可以主动改变管脚的电平高低了，这样就能通过电平的变化，控制外部的设备，比如点亮或者熄灭一个LED灯。 除此之外，一些IO口还可以配置成其他功能，比如PWM输出，串口通信等等。 关于旭日X3派的管脚定义，大家可以参考这张图，他会显示每个管脚具体可以实现什么功能。 这里需要说明一点，旭日X3派的管脚序号定义有三种编码方式： 第一种就是Board编码，这种就是按照主板上管脚排针编号，分别对应1~40号排针。 第二种就是BCM编码，这种方式是参考 Broadcom SOC 的通道编号，侧重CPU寄存器，在使用BCM库或者使用python编程时，常采用的一种编码方式。 第三种就是X3编码，可以理解为是旭日X3派自己的编码方式，在使用旭日派自己的驱动库编程时，会使用到这种编码。 大家在后续编程开发中，需要结合函数接口的说明，使用对应的引脚编号，不然可能会出现意料之外的问题。 引脚复用配置工具 虽然从硬件上看，扩展出来的引脚只有40个，不过大部分引脚还可以配置成多种功能，这样延伸出来变化可就多了，那如何配置引脚的不同功能呢？ 我们可以使用旭日X3派中提供的srpi-config工具进行配置。 直接在终端中输入这个指令，就可以看到这样的窗口，okay配置对应管脚为专用功能，disabled配置对应管脚为GPIO模式，按照自己的需要进行配置即可，配置完成后重启才会生效。 了解了GPIO的概念，接下来我们就要开始编程啦。 数字输入编程 首先我们来看下最基本的数字输入测试，读取一个按键的状态。 硬件接线 我们将按键的一边连接到旭日X3派的38号引脚上，这是一个GPIO的接口，另一边连接到39号引脚，也就是GND。 原理很简单，按键没按下时，导线是断开的，GPIO是默认的状态，按键按下后，导线就会导通，GPIO的状态变成了GND。 这样，我们就可以通过电平的变化，知道按键的状态啦。 运行例程 我们不妨来运行一下，看下实际效果是不是这样。 $ sudo python3 simple_input.py 我们将一个按键开关接到对应的管脚上， 然后连接到旭日X3PI当中，运行刚才的程序。之后我们按下或是松开按键时，他都会打印出对应的电平变化。 按下显示的就是LOW，也就是低电平，松开就是HIGH，也就是高电平。 代码解析 数字输入的功能实现啦，我们来看下代码是如何实现的。 simple_input.py： #!/usr/bin/env python3 import Hobot.GPIO as GPIO import time # 定义使用的GPIO通道为38 input_pin = 38 # BOARD 编码 38 def main (): prev_value = None # 设置管脚编码模式为硬件编号 BOARD GPIO . setmode ( GPIO . BOARD ) # 设置为输入模式 GPIO . setup ( input_pin , GPIO . IN ) print ( \"Starting demo now! Press CTRL+C to exit\" ) try : while True : # 读取管脚电平 value = GPIO . input ( input_pin ) if value != prev_value : if value == GPIO . HIGH : value_str = \"HIGH\" else : value_str = \"LOW\" print ( \"Value read from pin {} : {} \" . format ( input_pin , value_str )) prev_value = value time . sleep ( 1 ) finally : GPIO . cleanup () if __name__ == '__main__' : main () 我们在Python中需要引入X3Pi的GPIO库，从而使用对应的GPIO功能。 主函数里首先需要定义了一个变量来存储这个管脚的电平信号。 进行初始化，设置管脚的编码模式为BOARD模式，之后定义输入用的管脚，这里使用的是BOARD编码，因为他是第38个管脚，所以为38号。 之后的话就会进入到循环当中，这样的一个函数就可以读出当前的电平值。 没有按下按键的时候，38管脚和GND是断开的，他就是高电平，按下按键时，就和GND导通了，这个管脚就会编程低电平。 如果电平值和上一次存储的不一致，后面的判断就会判断出是升高还是降低，最后会把结果打印出来。 松开按键时同理。 数字输出编程 GPIO不止有输入功能，还有输出功能，大家应该经常看到电子设别上的LED灯吧，这就是典型的IO输出控制的设备，我们也来试一试。 硬件接线 我们将一个LED灯的正极连接到了2号引脚，这是5V电源，用来给LED供电的，不过LED电阻小，为了不至于烧坏，我们最好还是在电路中串联一个电阻来限制电流大小。 接下来，当LED的负极接到GND，也就是电源的0V上时，LED两边会因为有电势差而被点亮；当LED的负极也连接到高电平，也就是5V的时候，会因为两边没有电势差，也就不会被点亮。 这个负极的电平信号我们就用GPIO来输出，所以我们把LED的负极连接到任意的GPIO引脚上，比如38号，将这个引脚设置为输出模式，当输出高电平时，灯就会熄灭，输出低电平，灯就会被点亮。 把这两个动作放到一个循环中，就可以实现闪烁的功能啦。 运行示例程序 快来运行例程试一试吧，按照刚才的设置，将实物连接完成，然后连接到X3Pi，运行程序，就可以看到这个LED就会开始闪烁了。 $ sudo python3 simple_input.py 代码解析 simple_out.py： #!/usr/bin/env python3 import Hobot.GPIO as GPIO import time # 定义使用的GPIO通道为38 output_pin = 38 # BOARD 编码 38 def main (): # 设置管脚编码模式为硬件编号 BOARD GPIO . setmode ( GPIO . BOARD ) # 设置为输出模式，并且初始化为高电平 GPIO . setup ( output_pin , GPIO . OUT , initial = GPIO . HIGH ) # 记录当前管脚状态 curr_value = GPIO . HIGH print ( \"Starting demo now! Press CTRL+C to exit\" ) try : # 间隔1秒时间，循环控制LED灯亮灭 while True : time . sleep ( 1 ) GPIO . output ( output_pin , curr_value ) curr_value ^= GPIO . HIGH finally : GPIO . cleanup () if __name__ == '__main__' : main () 数字输入与输出集成 学习了GPIO的输入与输出功能后，我们就可以做一些自动化的功能了。 硬件接线 比如我们同时连接一个按键和LED灯，尝试实现按键被按下，灯被点亮，松开，灯熄灭，这样的功能。 运行示例程序 我们通过这个例程来试一试效果如何？ $ sudo python3 button_led.py 我们来看一下具体的操作，同样的，按照刚才的设置，将实物连接完成，然后连接到X3Pi，运行刚才的程序。按下按键后，就可以看到LED被点亮了，松开之后，LED就熄灭了。 代码解析 button_led.py #!/usr/bin/env python3 import Hobot.GPIO as GPIO import time # 定义使用的GPIO通道： # 36号作为输出，可以点亮一个LED # 38号作为输入，可以接一个按钮 led_pin = 36 # BOARD 编码 36 but_pin = 38 # BOARD 编码 38 # 禁用警告信息 GPIO . setwarnings ( False ) def main (): prev_value = None # Pin Setup: GPIO . setmode ( GPIO . BOARD ) # BOARD pin-numbering scheme GPIO . setup ( led_pin , GPIO . OUT ) # LED pin set as output GPIO . setup ( but_pin , GPIO . IN ) # Button pin set as input # Initial state for LEDs: GPIO . output ( led_pin , GPIO . LOW ) print ( \"Starting demo now! Press CTRL+C to exit\" ) try : while True : curr_value = GPIO . input ( but_pin ) if curr_value != prev_value : GPIO . output ( led_pin , curr_value ) prev_value = curr_value print ( \"Outputting {} to Pin {} \" . format ( curr_value , led_pin )) time . sleep ( 1 ) finally : GPIO . cleanup () # cleanup all GPIO if __name__ == '__main__' : main () 基本的配置还是一样的，引入基本的库，然后设置为BOARD模式，然后初始化两个管脚，一个用来读取按键的通断，一个用来控制LED的亮灭，之后只需要判断按键的状态来做出对应的控制LED的动作就可以了。","text_tokens":["才","里","分别","后续","就","是不是","开关","，","36","low","？","库","指","试一试","二种","概念","状态","通过","各种","供电","问题","输出","判断","这是","prev","setmode","警告","一个","usr","意料之外","三种","第","：","来","leds","延伸","至于","基本","实际效果","读出","sleep","应该","同样","后","ctrl","使用","吧","cleanup","函数","没有","中","time","模式","引脚","设置","系统","什么","exit","实物","也","不妨","自动化","编号","可以","意料","专用","把","能","in","初始化","只有","不是","而","电路","两个","进入","降低","自己","~","这种","旭日","理解","同时","所以","尝试","$","+","high","一些","生效","state","out","呢","自动","很","知道","数字","scheme","信号","cpu","接线","变化","就要","说明","'","__","成","电阻","import","如果","x3pi","接下","方式","board","做","间隔","最好","灭","同理","出现","灯亮","=","典型","pwm","快","首先","工具","to","两种","等等","(","熄灭","如何","打印","while","正极","电平","2","驱动","了","as","代码","button","来看","完成","这样",".","\"","那","比如","之外","true","主","给","对应","会","导通","都","与","派","1","记录","配置","。","上时","按照","；","还有","却","号","py","默认","通道","学习","变成","电势差","不同","改变","用来","当中","限制","but","config","电流","全称","按键","env","松开","除此","结果","他会","可","集成","灯","将","接下来","出来","情况","value","因为","hobot","一次","任意","实现","all","none","input","/","下来","_","两边","下","外部","时","5v","用","啦","到","和","x3","str","不","设别","组合","引入","python","个","烧坏","io","操作","false","一点","def","还","高低","但","接到","常用","read","!",":","press","动作","curr","}","没","不过","{","看到","进行","为了","从","循环","串口","最后","if","另一边","0","bin","结合","name","try","编码","会导通","出","编程","按下","值","效果","具体","了解","40","开始","0v","不至于","程序","一边","闪烁",")","接","负极","for","初始","控制","就是","寄存","原理","主动","按","虽然","一样","读取","开发","okay","或是","采用","亮","第三","简单","接口","starting","时间","一致","soc","broadcom","#","led","出是","参考","导线","format","断开","第一种","是","上","setup","除此之外","不止","设备","硬件","即可","多种","demo","大家","general","放到","低电平","第二","通信","srpi","主板","侧重","输入","pin","output","口","简称","大部分","扩展","从而","第一","禁用","运行","当前","from","38","c","复用","管脚","排针","一种","bcm","finally","定义","numbering","做出","大部","else","sudo","解析","通断","并且","电势","outputting","点亮","刚才"," ","这个","主要","秒","-","被","simple","数字信号","端口","提供","示例","测试","39","setwarnings","之后","关于","重启","各种各样","外设","这","多","功能","各样","到底","不然","张图","看","编码方式","终端","每","purpose","print","窗口","寄存器","变量","最","当","大小","经常","时候","序号","例程","小","main","可能","不会","我们","的","后面","串联","常","只","还是","initial","信息","输入输出","一下","通用","第二种","每个","这里","在","部分","称为","set","的话","指令","显示","python3","now","存储","电源","然后","作为","disabled","升高","连接",",","直接","其他","他","或者","为","第三种","^","gpio","电子","有","高电平","按钮","需要","gnd","实际"],"title":"数字输入与输出","title_tokens":["输出","输入","与","数字"]},{"location":"hhp/4.1_%E6%95%B0%E5%AD%97%E8%BE%93%E5%85%A5%E4%B8%8E%E8%BE%93%E5%87%BA/#_1","text":"数字输入与输出是最常用的一种外设通信方式，虽然每一个端口只有0和1两种状态，但却可以组合出各种各样的变化。","text_tokens":["最","各种","一种","输出","各种各样","外设","一个","数字","与","和","两种","各样","1","通信","，","可以","的","输入","变化","0","。","虽然","组合","出","每","只有","是","却","状态","方式","但","端口","常用"],"title":"数字输入与输出","title_tokens":["输出","输入","与","数字"]},{"location":"hhp/4.1_%E6%95%B0%E5%AD%97%E8%BE%93%E5%85%A5%E4%B8%8E%E8%BE%93%E5%87%BA/#_2","text":"数字输入与输出，也称为通用输入输出，全称是General-purpose input/output，大部分情况下，我们都会用简称GPIO GPIO的功能，主要是指这个管脚可以作为数字信号的输入或者输出使用，到底是输入还是输出呢，这需要我们使用系统寄存器来进行配置。 当GPIO被设置为输入模式时，就可以读取这个管脚上的电平高低，从而实现读取外部信号的功能，比如外部按键的信号，就是这样读取的。 当GPIO被设置为输出模式时，我们就可以主动改变管脚的电平高低了，这样就能通过电平的变化，控制外部的设备，比如点亮或者熄灭一个LED灯。 除此之外，一些IO口还可以配置成其他功能，比如PWM输出，串口通信等等。 关于旭日X3派的管脚定义，大家可以参考这张图，他会显示每个管脚具体可以实现什么功能。 这里需要说明一点，旭日X3派的管脚序号定义有三种编码方式： 第一种就是Board编码，这种就是按照主板上管脚排针编号，分别对应1~40号排针。 第二种就是BCM编码，这种方式是参考 Broadcom SOC 的通道编号，侧重CPU寄存器，在使用BCM库或者使用python编程时，常采用的一种编码方式。 第三种就是X3编码，可以理解为是旭日X3派自己的编码方式，在使用旭日派自己的驱动库编程时，会使用到这种编码。 大家在后续编程开发中，需要结合函数接口的说明，使用对应的引脚编号，不然可能会出现意料之外的问题。","text_tokens":["出现","管脚","排针","一种","bcm","pwm","分别","定义","就","后续","进行","大部","，","串口","等等","熄灭","结合","库","电平","指","编码","点亮"," ","编程","驱动","这个","主要","了","二种","具体","-","40","被","数字信号","通过","这样","比如","之外","对应","问题","关于","输出","会","这","一个","都","意料之外","与","派","三种","功能","：","1","控制","到底","就是","来","不然","寄存","张图","配置","。","主动","编码方式","读取","按照","开发","使用","采用","purpose","第三","号","寄存器","函数","通道","中","当","模式","引脚","设置","接口","系统","改变","什么","soc","broadcom","也","led","序号","全称","可能","编号","可以","意料","我们","的","按键","参考","能","除此","常","他会","第一种","灯","是","上","还是","情况","除此之外","自己","~","输入输出","这种","设备","旭日","理解","实现","通用","大家","第二种","general","一些","每个","这里","input","/","在","部分","称为","呢","下","显示","外部","数字","时","用","第二","信号","到","x3","cpu","通信","作为","主板","输入","变化","侧重","output","口","简称","大部分","说明","其他","或者","为","成","io","python","第三种","从而","gpio","有","一点","第一","还","高低","方式","board","需要"],"title":"数字输入与输出原理","title_tokens":["数字","与","输出","输入","原理"]},{"location":"hhp/4.1_%E6%95%B0%E5%AD%97%E8%BE%93%E5%85%A5%E4%B8%8E%E8%BE%93%E5%87%BA/#_3","text":"虽然从硬件上看，扩展出来的引脚只有40个，不过大部分引脚还可以配置成多种功能，这样延伸出来变化可就多了，那如何配置引脚的不同功能呢？ 我们可以使用旭日X3派中提供的srpi-config工具进行配置。 直接在终端中输入这个指令，就可以看到这样的窗口，okay配置对应管脚为专用功能，disabled配置对应管脚为GPIO模式，按照自己的需要进行配置即可，配置完成后重启才会生效。 了解了GPIO的概念，接下来我们就要开始编程啦。","text_tokens":["才","管脚","不过","就","看到","工具","进行","从","大部","，","如何","？"," ","编程","这个","了","了解","40","-","概念","提供","开始","完成","这样","那","对应","重启","会","多","派","功能","延伸","配置","。","虽然","看","后","按照","终端","okay","使用","窗口","中","模式","引脚","不同","config","专用","可以","我们","的","可","只有","上","接下来","出来","自己","旭日","即可","硬件","多种","生效","下来","在","部分","呢","指令","啦","x3","srpi","输入","变化","就要","disabled","直接","大部分","扩展","为","个","成","接下","gpio","还","需要"],"title":"引脚复用配置工具","title_tokens":["复用","工具","引脚","配置"]},{"location":"hhp/4.1_%E6%95%B0%E5%AD%97%E8%BE%93%E5%85%A5%E4%B8%8E%E8%BE%93%E5%87%BA/#_4","text":"首先我们来看下最基本的数字输入测试，读取一个按键的状态。","text_tokens":["最","。","首先","下","基本","测试","数字","一个","状态","来看","，","我们","读取","的","输入","按键"],"title":"数字输入编程","title_tokens":["编程","输入","数字"]},{"location":"hhp/4.1_%E6%95%B0%E5%AD%97%E8%BE%93%E5%85%A5%E4%B8%8E%E8%BE%93%E5%87%BA/#_5","text":"我们将按键的一边连接到旭日X3派的38号引脚上，这是一个GPIO的接口，另一边连接到39号引脚，也就是GND。 原理很简单，按键没按下时，导线是断开的，GPIO是默认的状态，按键按下后，导线就会导通，GPIO的状态变成了GND。 这样，我们就可以通过电平的变化，知道按键的状态啦。","text_tokens":["变成","39","引脚","简单","接口","这样","一边","这是","没","也","很","下","就","一个","时","知道","派","啦","到","x3","，","就是","可以","我们","按键","的","变化","原理","另一边","。","连接","导线","按","电平","会导通","后"," ","断开","按下","是","了","gpio","上","将","状态","号","默认","gnd","通过","38","旭日"],"title":"硬件接线","title_tokens":["接线","硬件"]},{"location":"hhp/4.1_%E6%95%B0%E5%AD%97%E8%BE%93%E5%85%A5%E4%B8%8E%E8%BE%93%E5%87%BA/#_6","text":"我们不妨来运行一下，看下实际效果是不是这样。 $ sudo python3 simple_input.py 我们将一个按键开关接到对应的管脚上， 然后连接到旭日X3PI当中，运行刚才的程序。之后我们按下或是松开按键时，他都会打印出对应的电平变化。 按下显示的就是LOW，也就是低电平，松开就是HIGH，也就是高电平。","text_tokens":["旭日","对应","$","之后","管脚","程序","high","当中","input","也","会","_","低电平","下","显示","不妨","python3","是不是","一个","时","都","开关","到","，","就是","然后","我们","来","sudo","按键","的","变化","low","打印","。","松开","连接","实际效果","看","电平","刚才","他","出"," ","按下","不是","效果","x3pi","或是","上","将","simple","高电平","py","一下","运行","实际","接到","这样","."],"title":"运行例程","title_tokens":["例程","运行"]},{"location":"hhp/4.1_%E6%95%B0%E5%AD%97%E8%BE%93%E5%85%A5%E4%B8%8E%E8%BE%93%E5%87%BA/#_7","text":"数字输入的功能实现啦，我们来看下代码是如何实现的。 simple_input.py： #!/usr/bin/env python3 import Hobot.GPIO as GPIO import time # 定义使用的GPIO通道为38 input_pin = 38 # BOARD 编码 38 def main (): prev_value = None # 设置管脚编码模式为硬件编号 BOARD GPIO . setmode ( GPIO . BOARD ) # 设置为输入模式 GPIO . setup ( input_pin , GPIO . IN ) print ( \"Starting demo now! Press CTRL+C to exit\" ) try : while True : # 读取管脚电平 value = GPIO . input ( input_pin ) if value != prev_value : if value == GPIO . HIGH : value_str = \"HIGH\" else : value_str = \"LOW\" print ( \"Value read from pin {} : {} \" . format ( input_pin , value_str )) prev_value = value time . sleep ( 1 ) finally : GPIO . cleanup () if __name__ == '__main__' : main () 我们在Python中需要引入X3Pi的GPIO库，从而使用对应的GPIO功能。 主函数里首先需要定义了一个变量来存储这个管脚的电平信号。 进行初始化，设置管脚的编码模式为BOARD模式，之后定义输入用的管脚，这里使用的是BOARD编码，因为他是第38个管脚，所以为38号。 之后的话就会进入到循环当中，这样的一个函数就可以读出当前的电平值。 没有按下按键的时候，38管脚和GND是断开的，他就是高电平，按下按键时，就和GND导通了，这个管脚就会编程低电平。 如果电平值和上一次存储的不一致，后面的判断就会判断出是升高还是降低，最后会把结果打印出来。 松开按键时同理。","text_tokens":["同理","read","!",":","=","管脚","press","finally","}","里","定义","{","首先","就","进行","to","循环","，","else","(","最后","low","如何","if","打印","bin","库","while","name","try","电平","编码"," ","编程","这个","按下","了","值","as","代码","来看","simple","\"",".","这样","true","主","对应","之后","判断",")","prev","会","setmode","导通","一个","usr","第","功能","：","1","初始","就是","来","。","读出","sleep","读取","ctrl","使用","号","cleanup","py","print","变量","函数","没有","通道","中","time","模式","设置","starting","exit","一致","当中","时候","#","main","编号","可以","把","我们","的","env","按键","出是","后面","松开","in","初始化","结果","format","断开","是","上","setup","还是","进入","降低","出来","value","因为","hobot","一次","硬件","实现","demo","所以","+","high","none","input","/","这里","在","低电平","_","的话","下","数字","python3","用","时","啦","now","存储","信号","到","和","pin","输入","str","升高",",","不","引入","他","'","__","为","python","个","import","如果","从而","x3pi","gpio","def","board","高电平","当前","from","需要","gnd","38","c"],"title":"代码解析","title_tokens":["解析","代码"]},{"location":"hhp/4.1_%E6%95%B0%E5%AD%97%E8%BE%93%E5%85%A5%E4%B8%8E%E8%BE%93%E5%87%BA/#_8","text":"GPIO不止有输入功能，还有输出功能，大家应该经常看到电子设别上的LED灯吧，这就是典型的IO输出控制的设备，我们也来试一试。","text_tokens":["大家","典型","经常","输出","led","也","这","看到","功能","，","就是","控制","我们","来","的","输入","。","设别","应该","试一试","io","灯","还有","gpio","电子","上","有","吧","不止","设备"],"title":"数字输出编程","title_tokens":["输出","编程","数字"]},{"location":"hhp/4.1_%E6%95%B0%E5%AD%97%E8%BE%93%E5%85%A5%E4%B8%8E%E8%BE%93%E5%87%BA/#_9","text":"我们将一个LED灯的正极连接到了2号引脚，这是5V电源，用来给LED供电的，不过LED电阻小，为了不至于烧坏，我们最好还是在电路中串联一个电阻来限制电流大小。 接下来，当LED的负极接到GND，也就是电源的0V上时，LED两边会因为有电势差而被点亮；当LED的负极也连接到高电平，也就是5V的时候，会因为两边没有电势差，也就不会被点亮。 这个负极的电平信号我们就用GPIO来输出，所以我们把LED的负极连接到任意的GPIO引脚上，比如38号，将这个引脚设置为输出模式，当输出高电平时，灯就会熄灭，输出低电平，灯就会被点亮。 把这两个动作放到一个循环中，就可以实现闪烁的功能啦。","text_tokens":["动作","不过","就","为了","循环","，","熄灭","正极","电平","电势","2","点亮"," ","这个","了","被","给","比如","0v","供电","不至于","接到","闪烁","输出","这是","负极","会","这","一个","功能","就是","来","至于","。","上时","；","号","没有","中","当","模式","电势差","引脚","设置","大小","用来","时候","限制","led","也","小","电流","把","可以","不会","我们","的","串联","灯","而","电路","上","还是","将","两个","接下来","因为","任意","实现","所以","放到","下来","在","低电平","两边","5v","时","用","信号","到","啦","电源","连接","为","电阻","烧坏","接下","gpio","有","高电平","gnd","38","最好"],"title":"硬件接线","title_tokens":["接线","硬件"]},{"location":"hhp/4.1_%E6%95%B0%E5%AD%97%E8%BE%93%E5%85%A5%E4%B8%8E%E8%BE%93%E5%87%BA/#_10","text":"快来运行例程试一试吧，按照刚才的设置，将实物连接完成，然后连接到X3Pi，运行程序，就可以看到这个LED就会开始闪烁了。 $ sudo python3 simple_input.py","text_tokens":["设置","$","程序","闪烁","input","快","实物","led","会","_","例程","就","看到","python3","到","，","可以","然后","来","的","sudo","。","连接","刚才"," ","按照","试一试","这个","了","x3pi","将","simple","吧","py","运行","开始","完成","."],"title":"运行示例程序","title_tokens":["运行","示例","程序"]},{"location":"hhp/4.1_%E6%95%B0%E5%AD%97%E8%BE%93%E5%85%A5%E4%B8%8E%E8%BE%93%E5%87%BA/#_11","text":"simple_out.py： #!/usr/bin/env python3 import Hobot.GPIO as GPIO import time # 定义使用的GPIO通道为38 output_pin = 38 # BOARD 编码 38 def main (): # 设置管脚编码模式为硬件编号 BOARD GPIO . setmode ( GPIO . BOARD ) # 设置为输出模式，并且初始化为高电平 GPIO . setup ( output_pin , GPIO . OUT , initial = GPIO . HIGH ) # 记录当前管脚状态 curr_value = GPIO . HIGH print ( \"Starting demo now! Press CTRL+C to exit\" ) try : # 间隔1秒时间，循环控制LED灯亮灭 while True : time . sleep ( 1 ) GPIO . output ( output_pin , curr_value ) curr_value ^= GPIO . HIGH finally : GPIO . cleanup () if __name__ == '__main__' : main ()","text_tokens":["灭","!",":","灯亮","=","管脚","press","finally","curr","定义","to","循环","，","(","if","bin","while","name","try","并且","电平","编码"," ","as","秒","状态","simple","\"",".","true","输出",")","setmode","usr","：","初始","1","控制","记录","sleep","ctrl","使用","cleanup","py","print","通道","time","模式","设置","starting","exit","时间","#","led","main","编号","env","的","初始化","setup","initial","value","hobot","硬件","demo","+","high","/","out","_","python3","now","pin",",","output","'","__","为","^","import","gpio","def","board","高电平","当前","间隔","38","c"],"title":"代码解析","title_tokens":["解析","代码"]},{"location":"hhp/4.1_%E6%95%B0%E5%AD%97%E8%BE%93%E5%85%A5%E4%B8%8E%E8%BE%93%E5%87%BA/#_12","text":"学习了GPIO的输入与输出功能后，我们就可以做一些自动化的功能了。","text_tokens":["。","就","gpio","自动化","自动","后","与","我们","功能","，","可以","做","一些","输出","的","输入","学习","了"],"title":"数字输入与输出集成","title_tokens":["数字","与","输出","输入","集成"]},{"location":"hhp/4.1_%E6%95%B0%E5%AD%97%E8%BE%93%E5%85%A5%E4%B8%8E%E8%BE%93%E5%87%BA/#_13","text":"比如我们同时连接一个按键和LED灯，尝试实现按键被按下，灯被点亮，松开，灯熄灭，这样的功能。","text_tokens":["实现","比如","尝试","led","下","一个","和","功能","，","我们","熄灭","按键","的","同时","松开","。","连接","按","点亮","灯","被","这样"],"title":"硬件接线","title_tokens":["接线","硬件"]},{"location":"hhp/4.1_%E6%95%B0%E5%AD%97%E8%BE%93%E5%85%A5%E4%B8%8E%E8%BE%93%E5%87%BA/#_14","text":"我们通过这个例程来试一试效果如何？ $ sudo python3 button_led.py 我们来看一下具体的操作，同样的，按照刚才的设置，将实物连接完成，然后连接到X3Pi，运行刚才的程序。按下按键后，就可以看到LED被点亮了，松开之后，LED就熄灭了。","text_tokens":["设置","$","之后","程序","实物","led","_","例程","就","看到","python3","到","，","可以","然后","我们","来","sudo","的","按键","如何","熄灭","？","。","松开","连接","点亮","同样","刚才","后"," ","按照","试一试","这个","按下","操作","了","效果","x3pi","button","具体","将","被","来看","py","运行","通过","完成","一下","."],"title":"运行示例程序","title_tokens":["运行","示例","程序"]},{"location":"hhp/4.1_%E6%95%B0%E5%AD%97%E8%BE%93%E5%85%A5%E4%B8%8E%E8%BE%93%E5%87%BA/#_15","text":"button_led.py #!/usr/bin/env python3 import Hobot.GPIO as GPIO import time # 定义使用的GPIO通道： # 36号作为输出，可以点亮一个LED # 38号作为输入，可以接一个按钮 led_pin = 36 # BOARD 编码 36 but_pin = 38 # BOARD 编码 38 # 禁用警告信息 GPIO . setwarnings ( False ) def main (): prev_value = None # Pin Setup: GPIO . setmode ( GPIO . BOARD ) # BOARD pin-numbering scheme GPIO . setup ( led_pin , GPIO . OUT ) # LED pin set as output GPIO . setup ( but_pin , GPIO . IN ) # Button pin set as input # Initial state for LEDs: GPIO . output ( led_pin , GPIO . LOW ) print ( \"Starting demo now! Press CTRL+C to exit\" ) try : while True : curr_value = GPIO . input ( but_pin ) if curr_value != prev_value : GPIO . output ( led_pin , curr_value ) prev_value = curr_value print ( \"Outputting {} to Pin {} \" . format ( curr_value , led_pin )) time . sleep ( 1 ) finally : GPIO . cleanup () # cleanup all GPIO if __name__ == '__main__' : main () 基本的配置还是一样的，引入基本的库，然后设置为BOARD模式，然后初始化两个管脚，一个用来读取按键的通断，一个用来控制LED的亮灭，之后只需要判断按键的状态来做出对应的控制LED的动作就可以了。","text_tokens":["灭","!",":","=","press","管脚","动作","finally","curr","}","定义","{","就","numbering","做出","to","，","(","36","low","if","bin","库","while","name","通断","try","outputting","编码","点亮"," ","了","as","button","-","状态","\"",".","true","setwarnings","对应","之后","输出","判断",")","prev","接","setmode","警告","一个","usr","：","for","1","初始","控制","leds","来","配置","。","基本","sleep","一样","读取","ctrl","使用","亮","号","cleanup","py","print","通道","time","模式","设置","starting","exit","用来","#","led","but","main","可以","env","的","按键","in","初始化","format","只","setup","还是","两个","initial","value","信息","hobot","all","demo","+","state","none","input","/","out","_","set","python3","scheme","now","然后","作为","pin","输入",",","output","引入","'","__","为","false","import","gpio","def","board","按钮","禁用","需要","38","c"],"title":"代码解析","title_tokens":["解析","代码"]},{"location":"hhp/4.2_PWM%E8%84%89%E5%86%B2%E5%AE%BD%E5%BA%A6%E8%B0%83%E5%88%B6/","text":"PWM脉冲宽度调制 我们已经可以用GPIO控制LED灯一闪一闪亮晶晶了，这样只有亮和灭的状态似乎还是太简单了，能不能对LED的亮度进行调整呢？ 当然没问题，这就要用到接下来学习的PWM脉冲宽度调制了。 PWM脉冲宽度调制原理 在GPIO的数字输入和输出模式中，只有高低电平，高电平一般是3.3V或者5V，低电平就是0V，如果我想要一个折中一点的电压怎么办呢？PWM大家了解一下。 PWM，全称是脉冲宽度调制 ， 是一种对模拟信号电平进行数字编码的方法，通过高分辨率计数器，调制出一定占空比的方波，通过这种方式对模拟信号的电平进行编码。 通俗点来说，如果我们有一个10W的灯泡，在一个小时中亮了半个小时，那我们宏观来看，它在这一个小时中的功率就是5W，这样就相当于是它的电压被降低了。而我们还可以通过改变这一个小时中，灯泡被点亮的时长，来等效出不同的电压。 然后，我们把一个小时缩短为很小的一个时间，到达一定的微分程度，表现出来的就是电压的变化，而这个很小的时间，就是PWM频率的倒数，被点亮的时间在这个很小的时间中所占的百分比就叫做占空比。 这里大家也要注意，虽然PWM在尽力呈现出模拟信号的样子，但本质还是数字信号，因为在给定的某一任何时刻，引脚只能高电平或者低电平。 通过PWM技术，可以让数字电路产生类似模拟信号的效果，从而实现类似的无级控制，比如风扇的转速，或者屏幕的亮度，很多都是通过PWM技术实现的调节。 PWM编程 接下来我们就来试一试，通过PWM让一个LED实现不同亮度的变化，也就是我们常见的呼吸灯了。 硬件接线 还是用这个LED灯，一端连接电阻，再到5V高电平的引脚，另外一端，接到33号引脚的PWM接口。 运行示例程序 大家先来运行例程，看看效果如何。 $ sudo python3 simple_pwm.py 我们来看一下实物的操作，按照刚才的设置，将实物连接完成，然后连接到X3Pi，运行刚才的程序。就可以看到这样的一个呼吸灯的效果了。 代码解析 simple_pwm.py： #!/usr/bin/env python3 import Hobot.GPIO as GPIO import time # 支持PWM的管脚: 32 and 33, 在使用PWM时，必须确保该管脚没有被其他功能占用 output_pin = 33 def main (): # Pin Setup: # Board pin-numbering scheme GPIO . setmode ( GPIO . BOARD ) # 支持的频率范围： 48KHz ~ 192MHz p = GPIO . PWM ( output_pin , 48000 ) # 初始占空比 25%， 先每0.25秒增加5%占空比，达到100%之后再每0.25秒减少5%占空比 val = 25 incr = 5 p . ChangeDutyCycle ( val ) p . start ( val ) print ( \"PWM running. Press CTRL+C to exit.\" ) try : while True : time . sleep ( 0.25 ) if val >= 100 : incr = - incr if val <= 0 : incr = - incr val += incr p . ChangeDutyCycle ( val ) finally : p . stop () GPIO . cleanup () if __name__ == '__main__' : main () 一样的引入GPIO的库，然后设置管脚编码模式为BOARD，然后创建一个PWM的实例化对象p，同时设置他的频率，之后就可以通过ChangeDutyCycle来改变他的占空比，在循环当中，占空比大于等于100时，就会以5%的梯度减小；当小于等于0时，就会以5%的梯度增大。","text_tokens":["一定","就","，","？","库","到达","100%","试一试","相当于","转速","状态","通过","小时","问题","输出","setmode","一个","usr","：","来","sleep","无级","我","ctrl","使用","灯泡","减少","cleanup","半个","25","没有","中","time","缩短","达到","模式","宽度","引脚","设置","增大","exit","实物","也","可以","5w","把","增加","能","太","只有","而","电路","降低","and","~","这种","同时","3.3","$","+","程度","呢","很多","数字","高分","scheme","信号","5","running","接线","变化","就要","百分比","'","__","一闪","电阻","import","如果","模拟","x3pi","接下","方波","方式","board","灭","=","折中","pwm","倒数","to","10w","宏观","(","如何","while","电平","了","as","0.25","代码","来看","风扇","完成","这样",".","\"","那","比如","true","化","会","都","技术","。","来说","再","叫做","按照","；","号","py","尽力","学习","不同","相当","方法","改变","数字电路","当中","调节","全称","env","呼吸","灯","数字电","辨率","电压","将","接下来","用到","出来","当然","因为","中亮","hobot","必须","实现","不能","/","下来","中所","_","频率","5v","时","用","到","和","已经","当于","呈现出","5%","表现","屏幕","调制","要","亮度","确保","引入","百分","操作","一点","def","还","33","但","p","接到","高分辨率","!",":","press","它","灯一闪","没","注意","看到","进行","脉冲","循环","if","0","bin","模拟信号","name","try","编码","出","计数器","编程","效果","stop","了解","对象","小于","另外","0v","功率","程序","一端",")","常见","样子","微分","初始","控制","就是","高","对","原理","虽然","让","一样","给定","100","亮","简单","时长","接口","以","时间","#","led","任何","32","一","数字编码","等效","很小","changedutycycle","<","是",">","setup","计数","硬件","大家","似乎","低电平","占空比","现出","pin","输入","output","亮晶晶","48000","从而","范围","实例","支持","运行","c","v","管脚","一种","finally","numbering","sudo","解析","incr","点亮","刚才"," ","这个","秒","-","被","simple","数字信号","示例","先","之后","分辨","通俗","这","时刻","等于","功能","类似","看看","每","点","val","本质","print","一般","当","产生","例程","main","分辨率","何时","我们","减小","的","晶晶","25%","还是","想要","调整","怎么","呈现","48khz","某","占","一下","任何时刻","这里","在","梯度","python3","怎么办","然后","该","连接",",","其他","大于","他","或者","占用","为","创建","start","gpio","有","192mhz","高电平","只能"],"title":"PWM脉冲宽度调制","title_tokens":["pwm","宽度","脉冲","调制"]},{"location":"hhp/4.2_PWM%E8%84%89%E5%86%B2%E5%AE%BD%E5%BA%A6%E8%B0%83%E5%88%B6/#pwm","text":"我们已经可以用GPIO控制LED灯一闪一闪亮晶晶了，这样只有亮和灭的状态似乎还是太简单了，能不能对LED的亮度进行调整呢？ 当然没问题，这就要用到接下来学习的PWM脉冲宽度调制了。","text_tokens":["灭","简单","宽度","似乎","不能","问题","下来","pwm","灯一闪","led","呢","没","这","进行","用","脉冲","和","已经","可以","控制","，","我们","的","对","就要","？","能","调制","。","亮度","学习","太","亮晶晶"," ","一闪","晶晶","只有","了","接下","gpio","亮","还是","状态","接下来","用到","调整","当然","这样"],"title":"PWM脉冲宽度调制","title_tokens":["pwm","宽度","脉冲","调制"]},{"location":"hhp/4.2_PWM%E8%84%89%E5%86%B2%E5%AE%BD%E5%BA%A6%E8%B0%83%E5%88%B6/#pwm_1","text":"在GPIO的数字输入和输出模式中，只有高低电平，高电平一般是3.3V或者5V，低电平就是0V，如果我想要一个折中一点的电压怎么办呢？PWM大家了解一下。 PWM，全称是脉冲宽度调制 ， 是一种对模拟信号电平进行数字编码的方法，通过高分辨率计数器，调制出一定占空比的方波，通过这种方式对模拟信号的电平进行编码。 通俗点来说，如果我们有一个10W的灯泡，在一个小时中亮了半个小时，那我们宏观来看，它在这一个小时中的功率就是5W，这样就相当于是它的电压被降低了。而我们还可以通过改变这一个小时中，灯泡被点亮的时长，来等效出不同的电压。 然后，我们把一个小时缩短为很小的一个时间，到达一定的微分程度，表现出来的就是电压的变化，而这个很小的时间，就是PWM频率的倒数，被点亮的时间在这个很小的时间中所占的百分比就叫做占空比。 这里大家也要注意，虽然PWM在尽力呈现出模拟信号的样子，但本质还是数字信号，因为在给定的某一任何时刻，引脚只能高电平或者低电平。 通过PWM技术，可以让数字电路产生类似模拟信号的效果，从而实现类似的无级控制，比如风扇的转速，或者屏幕的亮度，很多都是通过PWM技术实现的调节。","text_tokens":["高分辨率","v","一定","折中","它","一种","pwm","注意","就","进行","倒数","脉冲","10w","，","宏观","？","模拟信号","到达","电平","编码","点亮","出"," ","计数器","这个","相当于","了","效果","转速","了解","被","来看","风扇","数字信号","通过","这样","那","比如","0v","功率","小时","分辨","通俗","输出","这","样子","一个","都","时刻","微分","技术","就是","控制","高","来","对","类似","。","虽然","让","来说","无级","叫做","我","给定","点","灯泡","本质","半个","一般","尽力","中","缩短","模式","宽度","引脚","时长","不同","相当","方法","改变","时间","数字电路","调节","也","产生","任何","分辨率","全称","一","数字编码","何时","5w","可以","把","我们","的","等效","很小","只有","是","而","电路","数字电","辨率","还是","电压","想要","降低","出来","计数","怎么","呈现","某","因为","这种","中亮","占","一下","实现","3.3","大家","任何时刻","程度","这里","中所","在","低电平","呢","频率","很多","占空比","数字","5v","高分","怎么办","信号","和","当于","然后","现出","呈现出","输入","表现","变化","屏幕","调制","要","亮度","百分比","或者","为","百分","如果","模拟","从而","gpio","方波","有","一点","还","方式","高电平","但","只能"],"title":"PWM脉冲宽度调制原理","title_tokens":["宽度","脉冲","pwm","原理","调制"]},{"location":"hhp/4.2_PWM%E8%84%89%E5%86%B2%E5%AE%BD%E5%BA%A6%E8%B0%83%E5%88%B6/#pwm_2","text":"接下来我们就来试一试，通过PWM让一个LED实现不同亮度的变化，也就是我们常见的呼吸灯了。","text_tokens":["实现","不同","pwm","下来","也","led","常见","就","一个","，","就是","我们","来","的","变化","呼吸","。","让","亮度","试一试","灯","了","接下","接下来","通过"],"title":"PWM编程","title_tokens":["编程","pwm"]},{"location":"hhp/4.2_PWM%E8%84%89%E5%86%B2%E5%AE%BD%E5%BA%A6%E8%B0%83%E5%88%B6/#_1","text":"还是用这个LED灯，一端连接电阻，再到5V高电平的引脚，另外一端，接到33号引脚的PWM接口。","text_tokens":["引脚","接口","一端","pwm","led","5v","用","到","，","的","。","连接","电平","再","电阻","这个","灯","还是","号","33","高电平","另外","接到"],"title":"硬件接线","title_tokens":["接线","硬件"]},{"location":"hhp/4.2_PWM%E8%84%89%E5%86%B2%E5%AE%BD%E5%BA%A6%E8%B0%83%E5%88%B6/#_2","text":"大家先来运行例程，看看效果如何。 $ sudo python3 simple_pwm.py 我们来看一下实物的操作，按照刚才的设置，将实物连接完成，然后连接到X3Pi，运行刚才的程序。就可以看到这样的一个呼吸灯的效果了。","text_tokens":["大家","先","设置","$","这样","程序","pwm","实物","_","例程","就","看到","一个","python3","到","，","可以","然后","我们","来","sudo","的","如何","呼吸","。","看看","连接","刚才"," ","按照","操作","灯","了","效果","x3pi","将","simple","来看","py","运行","完成","一下","."],"title":"运行示例程序","title_tokens":["运行","示例","程序"]},{"location":"hhp/4.2_PWM%E8%84%89%E5%86%B2%E5%AE%BD%E5%BA%A6%E8%B0%83%E5%88%B6/#_3","text":"simple_pwm.py： #!/usr/bin/env python3 import Hobot.GPIO as GPIO import time # 支持PWM的管脚: 32 and 33, 在使用PWM时，必须确保该管脚没有被其他功能占用 output_pin = 33 def main (): # Pin Setup: # Board pin-numbering scheme GPIO . setmode ( GPIO . BOARD ) # 支持的频率范围： 48KHz ~ 192MHz p = GPIO . PWM ( output_pin , 48000 ) # 初始占空比 25%， 先每0.25秒增加5%占空比，达到100%之后再每0.25秒减少5%占空比 val = 25 incr = 5 p . ChangeDutyCycle ( val ) p . start ( val ) print ( \"PWM running. Press CTRL+C to exit.\" ) try : while True : time . sleep ( 0.25 ) if val >= 100 : incr = - incr if val <= 0 : incr = - incr val += incr p . ChangeDutyCycle ( val ) finally : p . stop () GPIO . cleanup () if __name__ == '__main__' : main () 一样的引入GPIO的库，然后设置管脚编码模式为BOARD，然后创建一个PWM的实例化对象p，同时设置他的频率，之后就可以通过ChangeDutyCycle来改变他的占空比，在循环当中，占空比大于等于100时，就会以5%的梯度减小；当小于等于0时，就会以5%的梯度增大。","text_tokens":["!",":","管脚","=","press","finally","pwm","就","numbering","to","循环","，","(","if","0","bin","库","while","name","100%","try","incr","编码"," ","as","秒","0.25","stop","-","被","simple","对象","小于","通过","\"",".","true","先","化","之后",")","会","setmode","一个","usr","等于","功能","：","初始","来","。","再","sleep","一样","ctrl","每","使用","100","val","；","减少","cleanup","py","print","25","没有","time","达到","当","模式","设置","以","增大","exit","改变","当中","#","32","main","可以","增加","减小","env","的","changedutycycle","<",">","25%","setup","48khz","and","~","hobot","同时","必须","+","/","在","_","频率","占空比","梯度","python3","时","scheme","5","running","然后","该","pin","5%",",","output","其他","大于","确保","48000","引入","他","'","__","为","占用","import","创建","start","gpio","def","33","范围","board","192mhz","实例","支持","p","c"],"title":"代码解析","title_tokens":["解析","代码"]},{"location":"hhp/4.3_UART%E5%BC%82%E6%AD%A5%E4%B8%B2%E5%8F%A3%E9%80%9A%E4%BF%A1/","text":"UART串口通信 现在的传感器和执行器种类越来越多，需要和控制器传输的数据也是多种多样，只用GPIO来控制和读取的话，只有0和1的状态，未免还是有点麻烦，各种各样的通信方法也层出不穷，UART串口通信绝对是最为常用的一种。 串口通信原理 串行通信是一种通讯协议，也可以简称为串口，可以理解为数据是串成一串的，所以也就只能一位一位的发送，这样传输的速度虽然受到了限制，但是对硬件线路的要求小，只需要一对传输线，一个发送，一个接收，就可以实现双向通信了。 一般情况下，串口模块发送数据的管脚叫做TX，接收数据的管脚叫做RX。发送端发过去的数据，需要对方串口模块的接收端来接收，所以一侧发送端的TX需要连接到另外一侧的接收端RX，接收和发送在两方看来是相对的，所以我们接线的时候，要记住永远是TX引脚连接到RX引脚，接反了数据就传输不了了。 硬件连接 接下来，我们就尝试通过一个串口模块来实现电脑和旭日X3Pi的串口通信。 在接线方面，我们先交叉连接串口模块和旭日X3Pi的RX、TX，同时为了让两边具有相同的参考电平，还要将两者的GND连接到一起，然后再把串口模块连接到电脑就可以了。 运行示例程序 接下来就可以运行串口通信的例程了。 $ sudo python3 test_serial.py 实物接线完成后，在旭日X3派的终端中输入指令启动例程，很快就可以在终端中看到串口向外发送的数据了。 在串口连接的电脑中打开一个串口软件，用来接收和发送数据，设置好端口和波特率，就能看到旭日X3派发过来的数据了。我们再使用电脑的串口软件尝试下发送数据给旭日X3派，输入1234，点击发送，可以看到，X3Pi的终端这边也成功的接收到了数据并且打印出来了。 代码解析 test_serial.py： #!/usr/bin/env python3 import sys import os import time # 导入python串口库 import serial import serial.tools.list_ports def serialTest (): print ( \"List of enabled UART:\" ) os . system ( 'ls /dev/tty[a-zA-Z]*' ) uart_dev = input ( \"请输入需要测试的串口设备名:\" ) baudrate = input ( \"请输入波特率(9600,19200,38400,57600,115200,921600):\" ) try : ser = serial . Serial ( uart_dev , int ( baudrate ), timeout = 1 ) # 1s timeout except Exception as e : print ( \"open serial failed! \\n \" ) print ( ser ) print ( \"Starting demo now! Press CTRL+C to exit\" ) while True : test_data = \"AA55\" write_num = ser . write ( test_data . encode ( 'UTF-8' )) print ( \"Send: \" , test_data ) received_data = ser . read ( write_num ) . decode ( 'UTF-8' ) if received_data : print ( \"Recv: \" , received_data ) time . sleep ( 1 ) ser . close () return 0 if __name__ == '__main__' : if serialTest () != 0 : print ( \"Serial test failed!\" ) else : print ( \"Serial test success!\" ) X3Pi这边如果要使用串口，直接使用serial库就可以了，这里我们先调用系统的库，打印出当前有哪些串口，然后手动输入选择串口的设备名，再输入串口的波特率，就可以进项串口的初始化了，初始化成功之后就会进入循环。 循环中，X3Pi会每隔一秒发送一次AA55，同时还会判断是否接收到了数据，如果接收到了数据也会打印出来。","text_tokens":["就","，","控制器","有点","库","open","状态","交叉","名","通过","za","各种","判断","e","一个","usr","ls","对方","：","相同","来","sleep","后","[","ctrl","端的","使用","\\","点击","中","time","引脚","设置","exit","系统","串行","实物","也","还会","aa55","一侧","可以","把","n","能","sys","初始化","向外","只有","进入","手动","旭日","理解","同时","所以","尝试","$","要求","+","请","接收端","tools","rx","接线","接收","]","种类","'","__","ports","import","serial","如果","x3pi","发送","接下","电脑","过去","执行","=","双向","38400","utf","to","(","打印","选择","ser","while","电平","了","as","代码","of","执行器","最为","完成","这样",".","给","\"","true","软件","会","派","1","system","。","一位","具有","串成","再","encode","多样","叫做","层出不穷","派发","永远","py","接反","方法","用来","限制","test","921600","success","env","但是","tx","os","启动","只用","19200","传输线","将","接下来","出来","8","情况","close","一次","实现","感器","/","input","下来","_","两边","是否","下","打开","传感","list","到","和","x3","模块","要","成功","dev","send","python","uart","def","波特率","常用","read","!",":","press","方面","decode","except","看到","为了","循环","串口","1234","if","0","bin","name","try","波特","出","导入","发送数据","另外","timeout","程序","哪些","现在",")","记住","write","return","初始","控制","通讯","对","原理","tty","虽然","让","int","读取","进项","一秒","两者","*","多种多样","看来","starting","recv","越来越","#","未免","还要","参考","相对","绝对","速度","是","设备","硬件","多种","demo","data","57600","数据","通信","baudrate","输入","简称","接收数据","z","越来","运行","当前","好","c","管脚","一起","一种","received","115200","else","sudo","解析","并且"," ","-","受到","端口","过来","示例","测试","failed","9600","先","之后","两方","各种各样","协议","多","num","各样","exception","一串","a","终端","enabled","print","一般","双向通信","这边","时候","很快","小","例程","main","、","1s","传输","我们","的","麻烦","只","还是","调用","线路","这里","在","的话","指令","python3","now","端发","然后","一对","每隔","连接",",","直接","不了","serialtest","为","gpio","传感器","有","只能","需要","gnd"],"title":"UART异步串口通信","title_tokens":["串口","uart","通信","异步"]},{"location":"hhp/4.3_UART%E5%BC%82%E6%AD%A5%E4%B8%B2%E5%8F%A3%E9%80%9A%E4%BF%A1/#uart","text":"现在的传感器和执行器种类越来越多，需要和控制器传输的数据也是多种多样，只用GPIO来控制和读取的话，只有0和1的状态，未免还是有点麻烦，各种各样的通信方法也层出不穷，UART串口通信绝对是最为常用的一种。","text_tokens":["多种","感器","各种","执行","方法","现在","数据","一种","越来越","各种各样","也","的话","未免","传感","多","和","各样","1","，","控制","通信","传输","控制器","来","串口","的","有点","0","。","种类","麻烦","只用","绝对","多样","读取","层出不穷","只有","是","uart","gpio","传感器","越来","状态","还是","需要","多种多样","执行器","最为","常用"],"title":"UART串口通信","title_tokens":["串口","uart","通信"]},{"location":"hhp/4.3_UART%E5%BC%82%E6%AD%A5%E4%B8%B2%E5%8F%A3%E9%80%9A%E4%BF%A1/#_1","text":"串行通信是一种通讯协议，也可以简称为串口，可以理解为数据是串成一串的，所以也就只能一位一位的发送，这样传输的速度虽然受到了限制，但是对硬件线路的要求小，只需要一对传输线，一个发送，一个接收，就可以实现双向通信了。 一般情况下，串口模块发送数据的管脚叫做TX，接收数据的管脚叫做RX。发送端发过去的数据，需要对方串口模块的接收端来接收，所以一侧发送端的TX需要连接到另外一侧的接收端RX，接收和发送在两方看来是相对的，所以我们接线的时候，要记住永远是TX引脚连接到RX引脚，接反了数据就传输不了了。","text_tokens":["管脚","一种","双向","就","，","串口"," ","了","受到","发送数据","另外","这样","两方","记住","一个","协议","对方","通讯","来","一串","对","。","一位","串成","虽然","叫做","端的","永远","一般","双向通信","接反","引脚","看来","时候","串行","限制","也","小","一侧","可以","传输","我们","的","但是","tx","相对","速度","是","只","传输线","情况","线路","硬件","实现","理解","所以","要求","数据","接收端","在","下","rx","到","和","端发","通信","接线","模块","接收","一对","要","连接","简称","接收数据","不了","为","发送","只能","需要","过去"],"title":"串口通信原理","title_tokens":["串口","通信","原理"]},{"location":"hhp/4.3_UART%E5%BC%82%E6%AD%A5%E4%B8%B2%E5%8F%A3%E9%80%9A%E4%BF%A1/#_2","text":"接下来，我们就尝试通过一个串口模块来实现电脑和旭日X3Pi的串口通信。 在接线方面，我们先交叉连接串口模块和旭日X3Pi的RX、TX，同时为了让两边具有相同的参考电平，还要将两者的GND连接到一起，然后再把串口模块连接到电脑就可以了。","text_tokens":["实现","尝试","先","可以","一起","方面","下来","在","两边","就","一个","、","为了","rx","到","和","相同","，","串口","通信","然后","我们","模块","来","的","接线","参考","还要","。","tx","同时","连接","具有","让","电平","再","把"," ","了","x3pi","接下","电脑","将","接下来","两者","交叉","gnd","通过","旭日"],"title":"硬件连接","title_tokens":["连接","硬件"]},{"location":"hhp/4.3_UART%E5%BC%82%E6%AD%A5%E4%B8%B2%E5%8F%A3%E9%80%9A%E4%BF%A1/#_3","text":"接下来就可以运行串口通信的例程了。 $ sudo python3 test_serial.py 实物接线完成后，在旭日X3派的终端中输入指令启动例程，很快就可以在终端中看到串口向外发送的数据了。 在串口连接的电脑中打开一个串口软件，用来接收和发送数据，设置好端口和波特率，就能看到旭日X3派发过来的数据了。我们再使用电脑的串口软件尝试下发送数据给旭日X3派，输入1234，点击发送，可以看到，X3Pi的终端这边也成功的接收到了数据并且打印出来了。","text_tokens":["给","这边","尝试","设置","$","软件","用来","数据","下来","实物","在","很快","_","也","就","例程","test","指令","python3","看到","打开","一个","下","派","到","和","x3","串口","可以","通信","，","接线","我们","1234","sudo","的","输入","接收","中","打印","能","。","成功","连接","并且","启动","再","向外","波特","后"," ","终端","派发","serial","了","使用","x3pi","接下","发送","电脑","接下来","出来","发送数据","波特率","py","运行","端口","过来","好","完成","点击","旭日","."],"title":"运行示例程序","title_tokens":["运行","示例","程序"]},{"location":"hhp/4.3_UART%E5%BC%82%E6%AD%A5%E4%B8%B2%E5%8F%A3%E9%80%9A%E4%BF%A1/#_4","text":"test_serial.py： #!/usr/bin/env python3 import sys import os import time # 导入python串口库 import serial import serial.tools.list_ports def serialTest (): print ( \"List of enabled UART:\" ) os . system ( 'ls /dev/tty[a-zA-Z]*' ) uart_dev = input ( \"请输入需要测试的串口设备名:\" ) baudrate = input ( \"请输入波特率(9600,19200,38400,57600,115200,921600):\" ) try : ser = serial . Serial ( uart_dev , int ( baudrate ), timeout = 1 ) # 1s timeout except Exception as e : print ( \"open serial failed! \\n \" ) print ( ser ) print ( \"Starting demo now! Press CTRL+C to exit\" ) while True : test_data = \"AA55\" write_num = ser . write ( test_data . encode ( 'UTF-8' )) print ( \"Send: \" , test_data ) received_data = ser . read ( write_num ) . decode ( 'UTF-8' ) if received_data : print ( \"Recv: \" , received_data ) time . sleep ( 1 ) ser . close () return 0 if __name__ == '__main__' : if serialTest () != 0 : print ( \"Serial test failed!\" ) else : print ( \"Serial test success!\" ) X3Pi这边如果要使用串口，直接使用serial库就可以了，这里我们先调用系统的库，打印出当前有哪些串口，然后手动输入选择串口的设备名，再输入串口的波特率，就可以进项串口的初始化了，初始化成功之后就会进入循环。 循环中，X3Pi会每隔一秒发送一次AA55，同时还会判断是否接收到了数据，如果接收到了数据也会打印出来。","text_tokens":["read","!",":","=","press","decode","except","就","received","38400","utf","to","循环","115200","串口","else","，","(","if","打印","选择","0","bin","ser","库","while","name","try","波特","出"," ","导入","了","open","as","-","of","名","timeout","\"",".","za","true","测试","failed","9600","先","之后","哪些","判断",")","e","会","write","usr","num","ls","：","return","1","初始","exception","system","。","tty","a","再","sleep","int","encode","[","ctrl","进项","enabled","\\","使用","一秒","py","*","print","中","time","这边","starting","exit","recv","系统","#","也","test","main","还会","aa55","921600","1s","success","可以","我们","env","的","n","sys","os","初始化","19200","进入","调用","出来","8","手动","设备","close","一次","同时","demo","data","57600","+","请","数据","这里","/","input","_","是否","list","python3","tools","now","到","然后","baudrate","接收","输入","要","]","dev","成功","每隔",",","直接","send","serialtest","'","__","python","ports","import","serial","如果","x3pi","uart","发送","z","有","def","波特率","当前","需要","c"],"title":"代码解析","title_tokens":["解析","代码"]},{"location":"hhp/4.4_SPI%E5%90%8C%E6%AD%A5%E4%B8%B2%E8%A1%8C%E9%80%9A%E4%BF%A1/","text":"SPI同步串行通信 UART串口通信中的数据只能一位一位的传输，如果数据量比较大的时候，传输速率会受到很大影响，此时我们就可以考虑使用同步串行通信了，比如SPI。 SPI通信原理 SPI，全称是Serial Peripheral Interface，也就是串行外设接口，同样是一种通信协议，在很多芯片中都有集成。 相比之前学习的UART串口通信，他多了两根线，其中一个是时钟信号，另一个是设备使能信号，用来控制设备是否启用，所以也产生了主从设备的概念。 MISO ：Master Input Slave Output，主设备数据输入，从设备数据输出； MOSI ：Master Output Slave Input，主设备数据输出，从设备数据输入； SCLK ：Serial Clock，时钟信号，由主设备产生； CS ：Chip Select，从设备使能信号，由主设备控制。 这样，在一组SPI通信的系统中，可以连接多个设备，想要和哪个设备通信时，就使能这个设备，除能其他设备。 我们在开发中常见的SPI设备会有一些传感器，还有电阻屏之类的。 硬件连线 在SPI的通信中，有一个管脚负责发送，另外一个管脚负责接收，如果我们把同一组SPI的发送和接收接到一起，岂不是能接收到自己发送的数据吗？ 我们不妨来试一试，这里使用一个跳线帽直接把19，21两个SPI的通信管脚短接。 运行示例程序 大家来运行例程，看看会发生什么？ $ sudo python3 test_spi.py 在旭日X3派的终端中，输入运行例程的指令，接下来我们就可以看到通过SPI传输并收到的数据啦，相当于是左手传递给右手，自己给自己循环传输数据了。 代码解析 test_spi.py： #!/usr/bin/env python3 import sys import os import time # 导入spidev模块 import spidev def BytesToHex ( Bytes ): return '' . join ([ \"0x %02X \" % x for x in Bytes ]) . strip () def spidevTest (): # 设置spi的bus号（0, 1, 2）和片选(0, 1) spi_bus = input ( \"Please input SPI bus num:\" ) spi_device = input ( \"Please input SPI cs num:\" ) # 创建spidev类的对象以访问基于spidev的Python函数。 spi = spidev . SpiDev () # 打开spi总线句柄 spi . open ( int ( spi_bus ), int ( spi_device )) # 设置 spi 频率为 12MHz spi . max_speed_hz = 12000000 print ( \"Starting demo now! Press CTRL+C to exit\" ) # 发送 [0x55, 0xAA], 接收的数据应该也是 [0x55, 0xAA] try : while True : resp = spi . xfer2 ([ 0x55 , 0xAA ]) print ( BytesToHex ( resp )) time . sleep ( 1 ) except KeyboardInterrupt : spi . close () if __name__ == '__main__' : print ( \"List of enabled spi controllers:\" ) os . system ( 'ls /dev/spidev*' ) spidevTest () 在python中使用spidev这个库，初始化X3Pi的SPI，之后使用xerf2发送数据，同时接收数据，并打印出来，会发现打印出来的就是我们发送的。","text_tokens":["interface","!",":","管脚","一起","=","press","xfer2","一种","通信协议","except","很大","传递","就","看到","to","从","循环","clock","串口","，","(","x","sudo","解析","chip","？","if","0","bin","打印","库","while","启用","0x","name","try","spidev","2"," ","试一试","这个","导入","list","相当于","了","相比","open","代码","数据量","概念","of","受到","对象","0x55","发送数据","同步","slave","另外","两根","master","通过","keyboardinterrupt","这样",".","给","主","比如","示例","\"","由主","true","多个","程序","哪个","之后","bus","12mhz","输出",")","会","join","外设","常见","bytes","屏","一个","发生","协议","都","多","一组","派","usr","spidevtest","num","：","return","for","控制","就是","1","初始","sclk","来","原理","帽","system","。","device","同时","看看","一位","21","xerf2","sleep","int","应该","同样","[","终端","传输速率","开发","ctrl","enabled","0xaa","使用","；","还有","之前","号","芯片","mosi","时钟","py","*","print","函数","学习","中","time","（","接口","设置","以","starting","相当","系统","什么","用来","exit","时候","发现","串行","hz","#","也","产生","总线","其中","例程","peripheral","test","不妨","同","全称","左手","岂","传输数据","main","比较","可以","传输","我们","把","19","的","env","）","resp","考虑","能","除能","sys","os","in","初始化","片选","之类","收到","spi","集成","影响","是","不是","两个","strip","使能","接下来","想要","please","出来","并打印","自己","select","设备","旭日","硬件","另","02x","speed","close","感器","句柄","所以","大家","demo","$","max","+","controllers","吗","一些","数据","这里","input","/","下来","在","_","是否","很多","频率","ls","指令","打开","传感","cs","miso","时","跳线","python3","bytestohex","信号","使","和","到","x3","啦","通信","类","当于","now","连线","模块","接收","输入","短接","%","]","dev","连接",",","访问","直接","output","基于","右手","12000000","并","速率","其他","接收数据","他","'","__","python","电阻","为","import","如果","serial","创建","x3pi","uart","发送","接下","此时","有","线","传感器","def","主从","只能","运行","负责","大","接到","c"],"title":"SPI同步串行通信","title_tokens":["同步","spi","通信","串行"]},{"location":"hhp/4.4_SPI%E5%90%8C%E6%AD%A5%E4%B8%B2%E8%A1%8C%E9%80%9A%E4%BF%A1/#spi","text":"UART串口通信中的数据只能一位一位的传输，如果数据量比较大的时候，传输速率会受到很大影响，此时我们就可以考虑使用同步串行通信了，比如SPI。","text_tokens":["比如","时候","数据","串行","很大","会","就","串口","通信","，","传输","比较","我们","可以","的","考虑","。","一位","速率","传输速率","spi","影响","如果","使用","了","uart","此时","数据量","受到","只能","同步","大","中"],"title":"SPI同步串行通信","title_tokens":["同步","spi","通信","串行"]},{"location":"hhp/4.4_SPI%E5%90%8C%E6%AD%A5%E4%B8%B2%E8%A1%8C%E9%80%9A%E4%BF%A1/#spi_1","text":"SPI，全称是Serial Peripheral Interface，也就是串行外设接口，同样是一种通信协议，在很多芯片中都有集成。 相比之前学习的UART串口通信，他多了两根线，其中一个是时钟信号，另一个是设备使能信号，用来控制设备是否启用，所以也产生了主从设备的概念。 MISO ：Master Input Slave Output，主设备数据输入，从设备数据输出； MOSI ：Master Output Slave Input，主设备数据输出，从设备数据输入； SCLK ：Serial Clock，时钟信号，由主设备产生； CS ：Chip Select，从设备使能信号，由主设备控制。 这样，在一组SPI通信的系统中，可以连接多个设备，想要和哪个设备通信时，就使能这个设备，除能其他设备。 我们在开发中常见的SPI设备会有一些传感器，还有电阻屏之类的。","text_tokens":["interface","一种","通信协议","就","从","clock","，","串口","chip","启用"," ","这个","相比","了","概念","slave","master","两根","这样","主","由主","多个","哪个","输出","会","外设","常见","屏","一个","协议","都","多","一组","：","控制","就是","sclk","。","同样","开发","；","还有","之前","芯片","mosi","时钟","学习","中","接口","系统","用来","串行","也","产生","其中","peripheral","全称","可以","我们","的","能","除能","之类","spi","集成","是","使能","想要","select","设备","另","感器","所以","一些","数据","input","在","是否","很多","传感","cs","miso","时","信号","使","和","通信","输入","连接","output","其他","他","电阻","serial","uart","有","线","传感器","主从"],"title":"SPI通信原理","title_tokens":["spi","通信","原理"]},{"location":"hhp/4.4_SPI%E5%90%8C%E6%AD%A5%E4%B8%B2%E8%A1%8C%E9%80%9A%E4%BF%A1/#_1","text":"在SPI的通信中，有一个管脚负责发送，另外一个管脚负责接收，如果我们把同一组SPI的发送和接收接到一起，岂不是能接收到自己发送的数据吗？ 我们不妨来试一试，这里使用一个跳线帽直接把19，21两个SPI的通信管脚短接。","text_tokens":["管脚","一起","吗","数据","这里","在","一个","同","一组","不妨","岂","跳线","到","和","通信","，","把","我们","来","19","接收","的","？","能","帽","短接","。","21","直接"," ","试一试","spi","不是","如果","使用","发送","有","两个","另外","负责","自己","接到","中"],"title":"硬件连线","title_tokens":["连线","硬件"]},{"location":"hhp/4.4_SPI%E5%90%8C%E6%AD%A5%E4%B8%B2%E8%A1%8C%E9%80%9A%E4%BF%A1/#_2","text":"大家来运行例程，看看会发生什么？ $ sudo python3 test_spi.py 在旭日X3派的终端中，输入运行例程的指令，接下来我们就可以看到通过SPI传输并收到的数据啦，相当于是左手传递给右手，自己给自己循环传输数据了。","text_tokens":["给","大家","$","相当","什么","数据","下来","在","会","_","传递","例程","test","指令","就","发生","python3","看到","左手","传输数据","派","啦","循环","x3","，","可以","当于","传输","我们","来","sudo","的","输入","中","？","。","看看","右手","并"," ","终端","收到","spi","相当于","是","了","接下","接下来","py","运行","自己","通过","旭日","."],"title":"运行示例程序","title_tokens":["运行","示例","程序"]},{"location":"hhp/4.4_SPI%E5%90%8C%E6%AD%A5%E4%B8%B2%E8%A1%8C%E9%80%9A%E4%BF%A1/#_3","text":"test_spi.py： #!/usr/bin/env python3 import sys import os import time # 导入spidev模块 import spidev def BytesToHex ( Bytes ): return '' . join ([ \"0x %02X \" % x for x in Bytes ]) . strip () def spidevTest (): # 设置spi的bus号（0, 1, 2）和片选(0, 1) spi_bus = input ( \"Please input SPI bus num:\" ) spi_device = input ( \"Please input SPI cs num:\" ) # 创建spidev类的对象以访问基于spidev的Python函数。 spi = spidev . SpiDev () # 打开spi总线句柄 spi . open ( int ( spi_bus ), int ( spi_device )) # 设置 spi 频率为 12MHz spi . max_speed_hz = 12000000 print ( \"Starting demo now! Press CTRL+C to exit\" ) # 发送 [0x55, 0xAA], 接收的数据应该也是 [0x55, 0xAA] try : while True : resp = spi . xfer2 ([ 0x55 , 0xAA ]) print ( BytesToHex ( resp )) time . sleep ( 1 ) except KeyboardInterrupt : spi . close () if __name__ == '__main__' : print ( \"List of enabled spi controllers:\" ) os . system ( 'ls /dev/spidev*' ) spidevTest () 在python中使用spidev这个库，初始化X3Pi的SPI，之后使用xerf2发送数据，同时接收数据，并打印出来，会发现打印出来的就是我们发送的。","text_tokens":["!",":","=","press","xfer2","except","to","，","(","x","if","打印","0","bin","库","while","name","0x","try","spidev","2"," ","导入","这个","open","of","对象","0x55","发送数据","keyboardinterrupt","\"",".","true","之后","bus","12mhz",")","join","会","bytes","usr","num","ls","spidevtest","：","return","for","1","初始","就是","system","device","。","xerf2","sleep","int","应该","[","ctrl","enabled","0xaa","使用","号","py","*","print","函数","中","time","（","设置","以","starting","exit","发现","hz","#","也","总线","test","main","）","resp","我们","env","的","sys","os","in","初始化","片选","spi","是","strip","please","出来","并打印","close","同时","02x","speed","demo","句柄","max","+","controllers","数据","/","input","在","_","频率","打开","list","python3","cs","bytestohex","now","和","类","模块","接收","%","]","dev",",","访问","基于","12000000","接收数据","'","__","python","为","import","创建","x3pi","发送","def","c"],"title":"代码解析","title_tokens":["解析","代码"]},{"location":"hhp/4.5_I2C%E5%90%8C%E6%AD%A5%E4%B8%B2%E8%A1%8C%E9%80%9A%E4%BF%A1/","text":"I2C同步串行通信 SPI通信虽然功能更强大了，但是需要4根线做连接，还是有点复杂，接下来I2C的连线就简单很多了。 I2C通信原理 I2C也是一种常用的串行通信方式，和SPI一样可以连接多个设备，重点是它只需要两根线就可以完成。 不过他的两根线和UART不同，不全是传输数据用的，I2C中的一根线是时钟线，另一根才是传输数据的，这根线可以双向的传输数据。 I2C通信中可以有多个主设备或者从设备，只要能通过地址找到彼此的位置即可。 主器件用于启动总线传送数据，并产生时钟给各种从机，此时任何被寻址的器件均被认为是从机。在总线上主和从、发和收的关系不是恒定的，而取决于此时数据传送方向。如果主机要发送数据给从机，主机首先得找到从机的地址，然后主动发送数据过去，最后也得由主机终止数据传送；如果主机要接收从机的数据，同样由主机得找到从机的地址，然后主机接收从器件发送的数据，最后由主机终止接收过程。 因为I2C的特性，使用I2C的设备比SPI多很多，比如图中的紫外线传感器，陀螺仪之类的，都是使用I2C进行通信的。 硬件接线 我们找来一个常用的陀螺仪模块，按照这里的接线图连接到旭日X3派的40PIN接口上，这里除了I2C通信的两根线之外，另外两根是电源线，负责给这个模块供电的，让它正常工作起来。 运行示例程序 接线是挺简单的，我们继续来运行这个例程，看下能否收到数据。 $ sudo python3 mpu6500_i2c.py 在终端启动例程，很快就可以看到通过I2C读取到了大量传感器的数据，这些就是陀螺仪模块的原始数据，收到之后我们就可以进行结算处理啦，这就是我们后续机器人开发的需要解决的问题了。 代码解析 mpu6500_i2c.py： #!/usr/bin/env python3 import smbus , time def MPU6050_start (): # alter sample rate (stability) samp_rate_div = 0 # sample rate = 8 kHz/(1+samp_rate_div) bus . write_byte_data ( MPU6050_ADDR , SMPLRT_DIV , samp_rate_div ) time . sleep ( 0.1 ) # reset all sensors bus . write_byte_data ( MPU6050_ADDR , PWR_MGMT_1 , 0x00 ) time . sleep ( 0.1 ) # power management and crystal settings bus . write_byte_data ( MPU6050_ADDR , PWR_MGMT_1 , 0x01 ) time . sleep ( 0.1 ) #Write to Configuration register bus . write_byte_data ( MPU6050_ADDR , CONFIG , 0 ) time . sleep ( 0.1 ) #Write to Gyro configuration register gyro_config_sel = [ 0b00000 , 0b010000 , 0b10000 , 0b11000 ] # byte registers gyro_config_vals = [ 250.0 , 500.0 , 1000.0 , 2000.0 ] # degrees/sec gyro_indx = 0 bus . write_byte_data ( MPU6050_ADDR , GYRO_CONFIG , int ( gyro_config_sel [ gyro_indx ])) time . sleep ( 0.1 ) #Write to Accel configuration register accel_config_sel = [ 0b00000 , 0b01000 , 0b10000 , 0b11000 ] # byte registers accel_config_vals = [ 2.0 , 4.0 , 8.0 , 16.0 ] # g (g = 9.81 m/s^2) accel_indx = 0 bus . write_byte_data ( MPU6050_ADDR , ACCEL_CONFIG , int ( accel_config_sel [ accel_indx ])) time . sleep ( 0.1 ) # interrupt register (related to overflow of data [FIFO]) bus . write_byte_data ( MPU6050_ADDR , INT_ENABLE , 1 ) time . sleep ( 0.1 ) return gyro_config_vals [ gyro_indx ], accel_config_vals [ accel_indx ] def read_raw_bits ( register ): # read accel and gyro values high = bus . read_byte_data ( MPU6050_ADDR , register ) low = bus . read_byte_data ( MPU6050_ADDR , register + 1 ) # combine higha and low for unsigned bit value value = (( high << 8 ) | low ) # convert to +- value if ( value > 32768 ): value -= 65536 return value def mpu6050_conv (): # raw acceleration bits acc_x = read_raw_bits ( ACCEL_XOUT_H ) acc_y = read_raw_bits ( ACCEL_YOUT_H ) acc_z = read_raw_bits ( ACCEL_ZOUT_H ) # raw temp bits ## t_val = read_raw_bits(TEMP_OUT_H) # uncomment to read temp # raw gyroscope bits gyro_x = read_raw_bits ( GYRO_XOUT_H ) gyro_y = read_raw_bits ( GYRO_YOUT_H ) gyro_z = read_raw_bits ( GYRO_ZOUT_H ) #convert to acceleration in g and gyro dps a_x = ( acc_x / ( 2.0 ** 15.0 )) * accel_sens a_y = ( acc_y / ( 2.0 ** 15.0 )) * accel_sens a_z = ( acc_z / ( 2.0 ** 15.0 )) * accel_sens w_x = ( gyro_x / ( 2.0 ** 15.0 )) * gyro_sens w_y = ( gyro_y / ( 2.0 ** 15.0 )) * gyro_sens w_z = ( gyro_z / ( 2.0 ** 15.0 )) * gyro_sens ## temp = ((t_val)/333.87)+21.0 # uncomment and add below in return return a_x , a_y , a_z , w_x , w_y , w_z # MPU6050 Registers MPU6050_ADDR = 0x68 PWR_MGMT_1 = 0x6B SMPLRT_DIV = 0x19 CONFIG = 0x1A GYRO_CONFIG = 0x1B ACCEL_CONFIG = 0x1C INT_ENABLE = 0x38 ACCEL_XOUT_H = 0x3B ACCEL_YOUT_H = 0x3D ACCEL_ZOUT_H = 0x3F TEMP_OUT_H = 0x41 GYRO_XOUT_H = 0x43 GYRO_YOUT_H = 0x45 GYRO_ZOUT_H = 0x47 # start I2C driver bus = smbus . SMBus ( 0 ) # start comm with i2c bus gyro_sens , accel_sens = MPU6050_start () # instantiate gyro/accel while True : print ( mpu6050_conv ()) 这里我们看一下怎么使用I2C和陀螺仪通信来获取信息。主体上有三个大的函数，而这三个函数的功能都比较单一，第一个函数通过给陀螺仪发送数据来进行初始化的设置，比如配置陀螺仪的电源寄存器，加速度寄存器等；第二个函数则是从陀螺仪读取数据；第三个函数则是将读取到的函数进行计算，从而变成真正的加速度等信息。 具体的读写操作可以看下面的代码片段，也是直接调用函数指定地址和数据就好了。 这里我们也能看到几个关键的参数，比如陀螺仪MPU6050的地址是0x68，通过这个地址才能确认到陀螺仪的存在，然后进行初始化，初始化完成之后进入循环，不停的将数据打印出来。","text_tokens":["才","由","values","主体","原始","4.0","获取","后续","就","，","zout","low","khz","有点","register","取决","degrees","related","|","同步","通过","enable","陀螺","各种","供电","恒定","找到","h","关系","2.0","问题","一个","usr","不停","能否","：","来","sleep","同样","[","使用","线图","rate","configuration","函数","寻址","中","time","设置","串行","结算","32768","w","也","registers","传输数据","机","可以","能","pwr","sec","in","初始化","正常","不是","而","计算","convert","进入","and","找","旭日","$","+","high","out","获取信息","很多","取决于","0x41","接线","接收","]","这根","driver","overflow","import","如果","下面","主机","接下","发送","线","此时","继续","调用函数","uncomment","方式","做","三个","过去","一根","大","第三个","读写操作","地址","得","comm","raw","=","双向","首先","to","(","div","打印","while","2","位置","了","代码","0b010000","of","电源线","真正","完成","强大","dps",".","给","主","比如","之外","true","sample","interrupt","bus","关键","发和收","都","##","派","1","0x1c","传送数据","终止","。","配置","indx","settings","stability","按照","第一个","挺","；","加速","取信","时钟","py","vals","变成","不同","0b10000","y","起来","config","add","彼此","env","0x45","但是","启动","fifo","sensors","均","将","接下来","出来","8","500.0","value","存在","i2c","因为","方向","过程","all","g","感器","器件","gyroscope","/","下来","accel","_","下","mgmt","传感","用","啦","到","和","x3","连线","模块","才能","要","s","below","并","power","紫外线","0b00000","0x43","二个","65536","操作","uart","def","第二个","陀螺仪","接线图","常用","read","!",":","它","不过","看到","进行","从","循环","最后","if","0","bin","1000.0","2000.0","crystal","15.0","xout","具体","发送数据","bit","0x3b","另外","0x01","management","t","比","多个","程序","0x6b",")","0x1a","解决","write","for","return","机器人","+-","就是","初始","紫外","寄存","原理","主动","虽然","让","一样","int","16.0","读取","开发","第三","根线","*","sel","combine","简单","接口","#","外线","总线","任何","除了","333.87","alter","0x68","处理","0.1","原始数据","reset","速度","<","spi","是",">","unsigned","上","单一","temp","higha","设备","即可","硬件","data","大量","数据","0x00","第二","bits","通信","用于","更","则","yout","从而","z","第一","运行","负责","好","参数","conv","0b01000","sens","acc","一种","250.0","复杂","机器","加速度","只要","x","工作","sudo","解析","gyro","0x1b","m","重点"," ","这个","0x47","samp","-","被","几个","两根","0x3d","mpu6500","示例","之后","9.81","这","21.0","8.0","认为","多","功能","a","看","不全是","0x19","终端","val","print","寄存器","是从","图中","上主","0x3f","很快","产生","例程","、","smplrt","传送","instantiate","比较","指定","传输","我们","的","片段","特性","之类","收到","只","还是","调用","确认","怎么","信息","一下","另","40pin","从机","等","这里","在","这些","smbus","acceleration","python3","addr","0x38","0b11000","电源","然后","读写","连接",",","直接","他","或者","^","byte","start","有","传感器","读取数据","mpu6050","需要","with","4"],"title":"I2C同步串行通信","title_tokens":["i2c","同步","通信","串行"]},{"location":"hhp/4.5_I2C%E5%90%8C%E6%AD%A5%E4%B8%B2%E8%A1%8C%E9%80%9A%E4%BF%A1/#i2c","text":"SPI通信虽然功能更强大了，但是需要4根线做连接，还是有点复杂，接下来I2C的连线就简单很多了。","text_tokens":["简单","下来","很多","就","功能","复杂","通信","，","连线","的","有点","但是","。","连接","更","虽然","spi","了","接下","还是","接下来","根线","做","需要","i2c","4","强大"],"title":"I2C同步串行通信","title_tokens":["i2c","同步","通信","串行"]},{"location":"hhp/4.5_I2C%E5%90%8C%E6%AD%A5%E4%B8%B2%E8%A1%8C%E9%80%9A%E4%BF%A1/#i2c_1","text":"I2C也是一种常用的串行通信方式，和SPI一样可以连接多个设备，重点是它只需要两根线就可以完成。 不过他的两根线和UART不同，不全是传输数据用的，I2C中的一根线是时钟线，另一根才是传输数据的，这根线可以双向的传输数据。 I2C通信中可以有多个主设备或者从设备，只要能通过地址找到彼此的位置即可。 主器件用于启动总线传送数据，并产生时钟给各种从机，此时任何被寻址的器件均被认为是从机。在总线上主和从、发和收的关系不是恒定的，而取决于此时数据传送方向。如果主机要发送数据给从机，主机首先得找到从机的地址，然后主动发送数据过去，最后也得由主机终止数据传送；如果主机要接收从机的数据，同样由主机得找到从机的地址，然后主机接收从器件发送的数据，最后由主机终止接收过程。 因为I2C的特性，使用I2C的设备比SPI多很多，比如图中的紫外线传感器，陀螺仪之类的，都是使用I2C进行通信的。","text_tokens":["才","地址","得","由","它","一种","双向","不过","就","首先","进行","从","，","只要","最后","取决","重点"," ","位置","被","发送数据","两根","通过","完成","给","主","比如","陀螺","各种","比","恒定","找到","多个","关系","认为","发和收","多","都","紫外","传送数据","终止","。","主动","一样","不全是","同样","；","使用","时钟","寻址","中","是从","不同","图中","上主","串行","也","外线","总线","产生","任何","传输数据","、","传送","彼此","机","可以","传输","的","能","启动","特性","之类","spi","不是","是","只","均","而","i2c","因为","方向","设备","即可","另","过程","从机","感器","器件","数据","在","很多","取决于","传感","用","和","通信","用于","然后","接收","要","连接","这根","并","紫外线","他","或者","如果","主机","uart","发送","线","有","此时","传感器","方式","需要","过去","陀螺仪","一根","常用"],"title":"I2C通信原理","title_tokens":["i2c","通信","原理"]},{"location":"hhp/4.5_I2C%E5%90%8C%E6%AD%A5%E4%B8%B2%E8%A1%8C%E9%80%9A%E4%BF%A1/#_1","text":"我们找来一个常用的陀螺仪模块，按照这里的接线图连接到旭日X3派的40PIN接口上，这里除了I2C通信的两根线之外，另外两根是电源线，负责给这个模块供电的，让它正常工作起来。","text_tokens":["给","40pin","之外","陀螺","接口","供电","起来","它","这里","一个","除了","派","到","x3","，","通信","电源","接线","我们","来","模块","的","工作","。","连接","让","正常","按照","这个","是","上","线图","线","另外","陀螺仪","接线图","i2c","两根","电源线","找","负责","旭日","常用"],"title":"硬件接线","title_tokens":["接线","硬件"]},{"location":"hhp/4.5_I2C%E5%90%8C%E6%AD%A5%E4%B8%B2%E8%A1%8C%E9%80%9A%E4%BF%A1/#_2","text":"接线是挺简单的，我们继续来运行这个例程，看下能否收到数据。 $ sudo python3 mpu6500_i2c.py 在终端启动例程，很快就可以看到通过I2C读取到了大量传感器的数据，这些就是陀螺仪模块的原始数据，收到之后我们就可以进行结算处理啦，这就是我们后续机器人开发的需要解决的问题了。","text_tokens":["感器","简单","陀螺","$","大量","之后","原始","问题","数据","结算","在","很快","_","这些","这","后续","例程","下","就","看到","python3","传感","进行","解决","能否","啦","到","机器人","，","可以","就是","机器","我们","接线","来","的","sudo","模块","。","处理","看","启动","原始数据"," ","收到","终端","这个","挺","读取","开发","是","了","继续","传感器","py","运行","需要","陀螺仪","i2c","通过","mpu6500","."],"title":"运行示例程序","title_tokens":["运行","示例","程序"]},{"location":"hhp/4.5_I2C%E5%90%8C%E6%AD%A5%E4%B8%B2%E8%A1%8C%E9%80%9A%E4%BF%A1/#_3","text":"mpu6500_i2c.py： #!/usr/bin/env python3 import smbus , time def MPU6050_start (): # alter sample rate (stability) samp_rate_div = 0 # sample rate = 8 kHz/(1+samp_rate_div) bus . write_byte_data ( MPU6050_ADDR , SMPLRT_DIV , samp_rate_div ) time . sleep ( 0.1 ) # reset all sensors bus . write_byte_data ( MPU6050_ADDR , PWR_MGMT_1 , 0x00 ) time . sleep ( 0.1 ) # power management and crystal settings bus . write_byte_data ( MPU6050_ADDR , PWR_MGMT_1 , 0x01 ) time . sleep ( 0.1 ) #Write to Configuration register bus . write_byte_data ( MPU6050_ADDR , CONFIG , 0 ) time . sleep ( 0.1 ) #Write to Gyro configuration register gyro_config_sel = [ 0b00000 , 0b010000 , 0b10000 , 0b11000 ] # byte registers gyro_config_vals = [ 250.0 , 500.0 , 1000.0 , 2000.0 ] # degrees/sec gyro_indx = 0 bus . write_byte_data ( MPU6050_ADDR , GYRO_CONFIG , int ( gyro_config_sel [ gyro_indx ])) time . sleep ( 0.1 ) #Write to Accel configuration register accel_config_sel = [ 0b00000 , 0b01000 , 0b10000 , 0b11000 ] # byte registers accel_config_vals = [ 2.0 , 4.0 , 8.0 , 16.0 ] # g (g = 9.81 m/s^2) accel_indx = 0 bus . write_byte_data ( MPU6050_ADDR , ACCEL_CONFIG , int ( accel_config_sel [ accel_indx ])) time . sleep ( 0.1 ) # interrupt register (related to overflow of data [FIFO]) bus . write_byte_data ( MPU6050_ADDR , INT_ENABLE , 1 ) time . sleep ( 0.1 ) return gyro_config_vals [ gyro_indx ], accel_config_vals [ accel_indx ] def read_raw_bits ( register ): # read accel and gyro values high = bus . read_byte_data ( MPU6050_ADDR , register ) low = bus . read_byte_data ( MPU6050_ADDR , register + 1 ) # combine higha and low for unsigned bit value value = (( high << 8 ) | low ) # convert to +- value if ( value > 32768 ): value -= 65536 return value def mpu6050_conv (): # raw acceleration bits acc_x = read_raw_bits ( ACCEL_XOUT_H ) acc_y = read_raw_bits ( ACCEL_YOUT_H ) acc_z = read_raw_bits ( ACCEL_ZOUT_H ) # raw temp bits ## t_val = read_raw_bits(TEMP_OUT_H) # uncomment to read temp # raw gyroscope bits gyro_x = read_raw_bits ( GYRO_XOUT_H ) gyro_y = read_raw_bits ( GYRO_YOUT_H ) gyro_z = read_raw_bits ( GYRO_ZOUT_H ) #convert to acceleration in g and gyro dps a_x = ( acc_x / ( 2.0 ** 15.0 )) * accel_sens a_y = ( acc_y / ( 2.0 ** 15.0 )) * accel_sens a_z = ( acc_z / ( 2.0 ** 15.0 )) * accel_sens w_x = ( gyro_x / ( 2.0 ** 15.0 )) * gyro_sens w_y = ( gyro_y / ( 2.0 ** 15.0 )) * gyro_sens w_z = ( gyro_z / ( 2.0 ** 15.0 )) * gyro_sens ## temp = ((t_val)/333.87)+21.0 # uncomment and add below in return return a_x , a_y , a_z , w_x , w_y , w_z # MPU6050 Registers MPU6050_ADDR = 0x68 PWR_MGMT_1 = 0x6B SMPLRT_DIV = 0x19 CONFIG = 0x1A GYRO_CONFIG = 0x1B ACCEL_CONFIG = 0x1C INT_ENABLE = 0x38 ACCEL_XOUT_H = 0x3B ACCEL_YOUT_H = 0x3D ACCEL_ZOUT_H = 0x3F TEMP_OUT_H = 0x41 GYRO_XOUT_H = 0x43 GYRO_YOUT_H = 0x45 GYRO_ZOUT_H = 0x47 # start I2C driver bus = smbus . SMBus ( 0 ) # start comm with i2c bus gyro_sens , accel_sens = MPU6050_start () # instantiate gyro/accel while True : print ( mpu6050_conv ()) 这里我们看一下怎么使用I2C和陀螺仪通信来获取信息。主体上有三个大的函数，而这三个函数的功能都比较单一，第一个函数通过给陀螺仪发送数据来进行初始化的设置，比如配置陀螺仪的电源寄存器，加速度寄存器等；第二个函数则是从陀螺仪读取数据；第三个函数则是将读取到的函数进行计算，从而变成真正的加速度等信息。 具体的读写操作可以看下面的代码片段，也是直接调用函数指定地址和数据就好了。 这里我们也能看到几个关键的参数，比如陀螺仪MPU6050的地址是0x68，通过这个地址才能确认到陀螺仪的存在，然后进行初始化，初始化完成之后进入循环，不停的将数据打印出来。","text_tokens":["参数","conv","0b01000","读写操作","read","sens","!","values","acc",":","raw","=","comm","主体","地址","4.0","获取","就","看到","250.0","进行","to","循环","，","zout","(","x","加速度","div","low","khz","if","打印","0","bin","register","while","gyro","1000.0","2000.0","0x1b","2","degrees","m","crystal","related"," ","这个","15.0","xout","0x47","了","samp","代码","具体","0b010000","|","-","of","bit","发送数据","0x3b","几个","0x01","真正","management","t","0x3d","mpu6500","dps",".","enable","true","通过","给","比如","陀螺","sample","h","之后","0x6b","2.0","interrupt","bus","好","关键",")","9.81","21.0","0x1a","8.0","write","这","一个","usr","##","都","不停","功能","：","return","1","for","+-","初始","来","寄存","0x1c","配置","。","a","indx","settings","看","stability","sleep","int","16.0","0x19","[","读取","第一个","使用","；","val","第三","加速","取信","py","*","rate","vals","sel","configuration","print","寄存器","函数","time","变成","combine","是从","0b10000","设置","y","32768","w","0x3f","#","也","registers","config","add","smplrt","instantiate","333.87","比较","可以","我们","指定","env","的","alter","0x45","0x68","pwr","能","完成","0.1","sec","in","初始化","fifo","片段","reset","速度","<","sensors",">","是","而","unsigned","计算","上","convert","将","调用","进入","出来","8","单一","确认","怎么","500.0","value","存在","temp","and","i2c","higha","信息","一下","all","g","data","等","+","high","gyroscope","0x00","这里","/","数据","out","accel","smbus","_","获取信息","acceleration","mgmt","第二","python3","bits","addr","0x38","0b11000","和","到","通信","0x41","电源","读写","然后","才能","below","s","]",",","直接","则","power","driver","0b00000","0x43","二个","overflow","^","byte","65536","import","yout","从而","操作","start","发送","下面","z","有","第一","def","调用函数","uncomment","读取数据","mpu6050","第二个","三个","陀螺仪","with","大","第三个"],"title":"代码解析","title_tokens":["解析","代码"]},{"location":"hhp/4.6_USB%E5%A4%96%E8%AE%BE%E9%A9%B1%E5%8A%A8/","text":"USB外设驱动 在电脑上，我们最常用的接口之一，应该就是USB了，相比之前讲到的外设通信方法，USB更加复杂，速度也更快。 USB通信原理 USB不仅是我们生活中最常用的一种接口，也是一种串行总线的通讯方式。他类似于UART，有两根线用来传输数据。 而且USB还有专门的接口规范，比如我们常听说的USB Type A、Type C。例如这里列出来的USB口，打印机常用的B口，手机上用的C口，都是标准的USB接口。 USB的接口规范，使用广泛，很多成熟的外设都是采用的USB接口。 摄像头驱动 比如USB摄像头。 硬件接线 这里我们使用一个USB摄像头，通过一个相机驱动把它跑起来，并且可以看到图像数据。 方法有很多中，TogetherROS兼容ROS2的所有功能，那我们就先试试ROS2中的标准方法，在旭日X3PI上直接安装一个usb_cam功能包。 ROS2相机驱动 安装与配置 首先安装ROS2的相机驱动包： # 安装功能包 $ sudo apt install ros-foxy-usb-cam 安装好之后，为了让系统能够找到该功能包，需要进入tros的目录，建立对应的软连接。 # 建立软连接 $ cd /opt/tros $ sudo python3 create_soft_link.py --foxy /opt/ros/foxy/ --tros /opt/tros/ 因为旭日X3Pi可以连接csi摄像头，设备名占用了video0-7，所以外接的USB摄像头会被自动分配到video8，我们需要在ROS2的功能包中修改一下设备号。 # 修改配置文件 $ cd /opt/tros/share/usb_cam/config $ sudo vim params.yaml 然后给这个设备添加权限，最后再设置TogetherROS的环境变量就可以使用啦。 # 添加可执行权限 $ sudo chmod 777 /dev/video8 # 添加环境变量 $ source /opt/tros/local_setup.bash 运行相机驱动 我们来试一试。 $ ros2 launch usb_cam demo_launch.py #启动相机，X3Pi $ ros2 run rqt_image_view rqt_image_view #查看图像，PC 这里直接在X3Pi中启动usb_cam的launch文件，然后再启动一个能和他通信的Ubuntu桌面系统，打开rqt_image_view，选择对应的话题，就可以看到图像了。也就是说明我们成功的用TROS驱动了这个USB摄像头。 TogetherROS相机驱动 除此之外，TogetherROS中也提供了USB摄像头的驱动节点，连接摄像头之后，直接设置设备的权限和TogetherROS的环境变量就可以使用了。 $ source /opt/tros/local_setup.bash $ sudo chmod 777 /dev/video8 $ ros2 launch hobot_usb_cam hobot_usb_cam.launch.py 之后可以再打开一个新的终端，输入对应的指令，然后启动websocket这个节点，就可以把image这个话题的数据发送到网页了。 $ source /opt/tros/local_setup.bash $ cd /opt/tros/lib/websocket/webservice $ sudo chmod +x ./sbin/nginx $ sudo ./sbin/nginx -p . $ ros2 run websocket websocket --ros-args -p image_topic: = /image -p image_type: = mjpeg -p only_show_image: = true 这时我们直接打开在通一个局域网下的浏览器，输入X3Pi的地址，就可以进去到一个网页，点击左上方web端展示即可看到USB摄像头的实时画面。 激光雷达驱动 移动机器人中常用的激光雷达大多也是USB借口的，比如这款rplidar。 安装与配置 如果我们想把它跑起来，同样需要一个驱动包，大家可以在工作空间中下载雷达的驱动包，然后进行编译。编译完成后，添加环境变量就可以使用这个功能包了。 # 下载源码 $ mkdir -p catkin_ws/src $ cd ~/catkin_ws/src $ git clone -b ros2 https://github.com/slamtec/rplidar_ros.git # 编译 $ cd ~/catkin_ws $ colcon build --symlink-install # 添加环境变量 $ source ~/catkin_ws/install/setup.bash # 添加权限 $ sudo chmod 777 /dev/ttyUSB0 还要记得给激光雷达的USB口设置对应的权限。 运行激光雷达驱动 驱动安装好之后，就可以启动雷达了。 在旭日X3派的终端中，运行启动激光雷达的launch文件。 $ ros2 launch rplidar_ros2 rplidar_launch.py #启动雷达，X3PI $ ros2 run rviz2 rviz2 #查看点云，PC 启动成功后，我们在电脑端的Ubuntu系统中，在ros2环境下打开rviz2，然后将世界坐标系改为laser，然后添加LaserScan的可视化选项，并且把Reliability Policy的选项改为System Default，此时就可以看到激光雷达的点云数据了。","text_tokens":["soft","桌面","就","web","，","usb","试一试","明","名","通过","create","安装","build","局域网","找到","不仅","进去","laser","一个","雷达","：","来","csi","topic","应该","同样","后","这款","端的","使用","colcon","外接","点击","中","兼容","websocket","rviz2","包","设置","系统","串行","也","传输数据","之一","把","可以","rqt","image","也就是说","能","src","摄像","左上方","进入","~","成熟","--","旭日","规范","所以","$","cam","+","实时","video8","像头","params","自动","移动机器人","很多","送到","话题","接线","列出","https","端","如果","广泛","x3pi","发送","电脑","线","此时","cd","方式","文件","这时","source","记得","地址","执行","能够","=","包中","ubuntu","快","可视","首先","而且","听说","b","打印","选择","动机","软","再启动","驱动","分配","了","相比","完成",".","给","那","比如","之外","true","手机","对应","编译","会","激光雷达","都","与","派","展示","777","配置","system","。","再","install","还有","号","py","添加","opt","起来","方法","share","用来","就是说","config","例如","video0","摄像头","节点","除此","启动","可","环境变","将","出来","catkin","因为","hobot","更加","/","_","下","打开","用","啦","到","和","slamtec","x3","借口","ws","dev","成功","com","坐标","foxy","可视化","uart","环境变量","p","列出来","常用",":","它","权限","local","看到","进行","跑","为了","建立","最后","网页","rplidar","生活","打印机","目录","run","policy","上用","nginx","环境","7","标准","讲到","点云","试试","上方","git","yaml","想","机器人","通讯","就是","浏览","default","原理","让","印机","采用","之前","chmod","togetherros","包了","接口","reliability","画面","#","总线","apt","空间","还要","速度","发送到","是","上","setup","于","vim","除此之外","设备","专门","硬件","即可","demo","大家","激光","数据","移动","ros","通信","symlink","下载","输入","更","口","laserscan","pc","only","改为","运行","bash","好","c","show","一种","选项","查看","图像","sbin","局域","复杂","机器","x","工作","sudo","浏览器","并且","坐标系"," ","type","这个","源码","-","被","大多","两根","tros","提供","github","先","之后","配置文件","mjpeg","外设","通","功能","link","类似","view","a","串行总线","launch","终端","clone","变量","最","、","世界","传输","我们","的","常","ros2","左上","一下","这里","在","指令","python3","然后","ttyusb0","该","相机","mkdir","webservice","连接","直接","新","他","占用","lib","args","有","修改","所有","需要"],"title":"USB外设驱动","title_tokens":["外设","驱动","usb"]},{"location":"hhp/4.6_USB%E5%A4%96%E8%AE%BE%E9%A9%B1%E5%8A%A8/#usb","text":"在电脑上，我们最常用的接口之一，应该就是USB了，相比之前讲到的外设通信方法，USB更加复杂，速度也更快。","text_tokens":["最","更加","接口","讲到","方法","快","在","也","外设","之一","复杂","，","就是","通信","我们","的","usb","。","更","应该","速度","了","相比","电脑","上","之前","常用"],"title":"USB外设驱动","title_tokens":["外设","驱动","usb"]},{"location":"hhp/4.6_USB%E5%A4%96%E8%AE%BE%E9%A9%B1%E5%8A%A8/#usb_1","text":"USB不仅是我们生活中最常用的一种接口，也是一种串行总线的通讯方式。他类似于UART，有两根线用来传输数据。 而且USB还有专门的接口规范，比如我们常听说的USB Type A、Type C。例如这里列出来的USB口，打印机常用的B口，手机上用的C口，都是标准的USB接口。 USB的接口规范，使用广泛，很多成熟的外设都是采用的USB接口。","text_tokens":["最","比如","规范","手机","标准","接口","列出来","用来","不仅","一种","串行","数据","这里","也","总线","外设","很多","传输数据","而且","、","都","例如","听说","，","通讯","传输","我们","的","类似","b","usb","打印","。","a","串行总线","口","常","印机","列出","生活","他"," ","type","打印机","是","使用","还有","c","uart","广泛","采用","有","于","线","上用","出来","方式","两根","成熟","专门","中","常用"],"title":"USB通信原理","title_tokens":["通信","原理","usb"]},{"location":"hhp/4.6_USB%E5%A4%96%E8%AE%BE%E9%A9%B1%E5%8A%A8/#_1","text":"比如USB摄像头。","text_tokens":["比如","。","摄像","摄像头","像头","usb"],"title":"摄像头驱动","title_tokens":["驱动","像头","摄像","摄像头"]},{"location":"hhp/4.6_USB%E5%A4%96%E8%AE%BE%E9%A9%B1%E5%8A%A8/#_2","text":"这里我们使用一个USB摄像头，通过一个相机驱动把它跑起来，并且可以看到图像数据。 方法有很多中，TogetherROS兼容ROS2的所有功能，那我们就先试试ROS2中的标准方法，在旭日X3PI上直接安装一个usb_cam功能包。","text_tokens":["那","旭日","togetherros","兼容","安装","标准","先","包","cam","起来","方法","它","数据","这里","像头","在","试试","_","很多","看到","图像","就","一个","跑","摄像头","功能","，","把","可以","我们","相机","的","usb","。","直接","并且","摄像"," ","驱动","使用","x3pi","上","有","ros2","所有","通过","中"],"title":"硬件接线","title_tokens":["接线","硬件"]},{"location":"hhp/4.6_USB%E5%A4%96%E8%AE%BE%E9%A9%B1%E5%8A%A8/#ros2","text":"","text_tokens":[],"title":"ROS2相机驱动","title_tokens":["相机","驱动","ros2"]},{"location":"hhp/4.6_USB%E5%A4%96%E8%AE%BE%E9%A9%B1%E5%8A%A8/#_3","text":"首先安装ROS2的相机驱动包： # 安装功能包 $ sudo apt install ros-foxy-usb-cam 安装好之后，为了让系统能够找到该功能包，需要进入tros的目录，建立对应的软连接。 # 建立软连接 $ cd /opt/tros $ sudo python3 create_soft_link.py --foxy /opt/ros/foxy/ --tros /opt/tros/ 因为旭日X3Pi可以连接csi摄像头，设备名占用了video0-7，所以外接的USB摄像头会被自动分配到video8，我们需要在ROS2的功能包中修改一下设备号。 # 修改配置文件 $ cd /opt/tros/share/usb_cam/config $ sudo vim params.yaml 然后给这个设备添加权限，最后再设置TogetherROS的环境变量就可以使用啦。 # 添加可执行权限 $ sudo chmod 777 /dev/video8 # 添加环境变量 $ source /opt/tros/local_setup.bash","text_tokens":["soft","执行","能够","包中","权限","local","首先","就","为了","，","建立","最后","sudo","usb","软"," ","驱动","这个","分配","了","目录","-","被","环境","名","tros","create",".","给","安装","7","对应","找到","之后","配置文件","会","yaml","功能","：","link","777","配置","。","csi","让","再","install","使用","号","py","chmod","外接","变量","添加","opt","togetherros","包","设置","系统","share","#","config","video0","apt","摄像头","可以","我们","的","摄像","可","环境变","setup","进入","ros2","vim","因为","设备","--","旭日","一下","所以","$","cam","/","video8","像头","params","在","_","自动","python3","ros","啦","到","然后","该","相机","dev","连接","foxy","占用","x3pi","cd","修改","环境变量","文件","bash","需要","source","好"],"title":"安装与配置","title_tokens":["与","安装","配置"]},{"location":"hhp/4.6_USB%E5%A4%96%E8%AE%BE%E9%A9%B1%E5%8A%A8/#_4","text":"我们来试一试。 $ ros2 launch usb_cam demo_launch.py #启动相机，X3Pi $ ros2 run rqt_image_view rqt_image_view #查看图像，PC 这里直接在X3Pi中启动usb_cam的launch文件，然后再启动一个能和他通信的Ubuntu桌面系统，打开rqt_image_view，选择对应的话题，就可以看到图像了。也就是说明我们成功的用TROS驱动了这个USB摄像头。","text_tokens":["demo","对应","$","cam","系统","桌面","就是说","这里","ubuntu","像头","查看","#","在","_","图像","打开","就","一个","话题","看到","用","摄像头","和","，","rqt","然后","image","我们","相机","来","的","通信","可以","就是","也就是说","usb","view","能","。","选择","成功","直接","摄像","启动","pc","再启动","launch","他"," ","试一试","驱动","这个","了","x3pi","run","明","ros2","py","文件","tros","中","."],"title":"运行相机驱动","title_tokens":["相机","驱动","运行"]},{"location":"hhp/4.6_USB%E5%A4%96%E8%AE%BE%E9%A9%B1%E5%8A%A8/#togetherros","text":"除此之外，TogetherROS中也提供了USB摄像头的驱动节点，连接摄像头之后，直接设置设备的权限和TogetherROS的环境变量就可以使用了。 $ source /opt/tros/local_setup.bash $ sudo chmod 777 /dev/video8 $ ros2 launch hobot_usb_cam hobot_usb_cam.launch.py 之后可以再打开一个新的终端，输入对应的指令，然后启动websocket这个节点，就可以把image这个话题的数据发送到网页了。 $ source /opt/tros/local_setup.bash $ cd /opt/tros/lib/websocket/webservice $ sudo chmod +x ./sbin/nginx $ sudo ./sbin/nginx -p . $ ros2 run websocket websocket --ros-args -p image_topic: = /image -p image_type: = mjpeg -p only_show_image: = true 这时我们直接打开在通一个局域网下的浏览器，输入X3Pi的地址，就可以进去到一个网页，点击左上方web端展示即可看到USB摄像头的实时画面。","text_tokens":["show","地址",":","=","权限","local","就","sbin","局域","web","看到","，","x","sudo","网页","usb","浏览器"," ","type","驱动","这个","了","run","-","nginx","环境","tros","提供",".","true","之外","局域网","对应","之后","进去","mjpeg","上方","通","一个","展示","777","浏览","。","topic","再","launch","终端","使用","py","chmod","变量","点击","中","opt","togetherros","websocket","设置","画面","也","摄像头","节点","可以","把","image","我们","的","除此","摄像","启动","左上方","发送到","环境变","setup","ros2","除此之外","左上","设备","hobot","--","即可","$","cam","+","实时","数据","/","video8","像头","在","_","下","打开","指令","送到","话题","ros","到","和","然后","输入","webservice","dev","连接","直接","新","端","lib","args","x3pi","发送","cd","环境变量","only","bash","这时","source","p"],"title":"TogetherROS相机驱动","title_tokens":["相机","驱动","togetherros"]},{"location":"hhp/4.6_USB%E5%A4%96%E8%AE%BE%E9%A9%B1%E5%8A%A8/#_5","text":"移动机器人中常用的激光雷达大多也是USB借口的，比如这款rplidar。","text_tokens":["比如","激光","也","移动机器人","激光雷达","移动","雷达","机器人","借口","机器","，","的","usb","动机","。","rplidar","这款","是","大多","中","常用"],"title":"激光雷达驱动","title_tokens":["激光","雷达","激光雷达","驱动"]},{"location":"hhp/4.6_USB%E5%A4%96%E8%AE%BE%E9%A9%B1%E5%8A%A8/#_6","text":"如果我们想把它跑起来，同样需要一个驱动包，大家可以在工作空间中下载雷达的驱动包，然后进行编译。编译完成后，添加环境变量就可以使用这个功能包了。 # 下载源码 $ mkdir -p catkin_ws/src $ cd ~/catkin_ws/src $ git clone -b ros2 https://github.com/slamtec/rplidar_ros.git # 编译 $ cd ~/catkin_ws $ colcon build --symlink-install # 添加环境变量 $ source ~/catkin_ws/install/setup.bash # 添加权限 $ sudo chmod 777 /dev/ttyUSB0 还要记得给激光雷达的USB口设置对应的权限。","text_tokens":[":","它","权限","就","进行","跑","，","工作","sudo","b","usb","rplidar"," ","驱动","这个","源码","-","环境","完成",".","给","github","build","对应","编译","激光雷达","git","一个","想","雷达","功能","777","。","同样","install","后","clone","使用","colcon","chmod","变量","添加","中","包了","包","设置","起来","#","空间","把","可以","我们","还要","的","src","环境变","setup","ros2","catkin","~","--","大家","$","激光","/","在","_","ros","slamtec","symlink","然后","ttyusb0","下载","mkdir","ws","dev","口","com","https","如果","cd","环境变量","bash","需要","source","p","记得"],"title":"安装与配置","title_tokens":["与","安装","配置"]},{"location":"hhp/4.6_USB%E5%A4%96%E8%AE%BE%E9%A9%B1%E5%8A%A8/#_7","text":"驱动安装好之后，就可以启动雷达了。 在旭日X3派的终端中，运行启动激光雷达的launch文件。 $ ros2 launch rplidar_ros2 rplidar_launch.py #启动雷达，X3PI $ ros2 run rviz2 rviz2 #查看点云，PC 启动成功后，我们在电脑端的Ubuntu系统中，在ros2环境下打开rviz2，然后将世界坐标系改为laser，然后添加LaserScan的可视化选项，并且把Reliability Policy的选项改为System Default，此时就可以看到激光雷达的点云数据了。","text_tokens":["旭日","安装","rviz2","$","reliability","之后","系统","激光","点云","数据","ubuntu","选项","查看","在","#","laser","_","激光雷达","可视","就","下","打开","看到","雷达","派","世界","x3","，","可以","然后","把","我们","的","default","system","。","成功","rplidar","并且","启动","坐标","pc","laserscan","launch","后"," ","终端","驱动","坐标系","了","端的","可视化","x3pi","电脑","run","policy","将","此时","ros2","文件","py","运行","环境","改为","好","添加","中","."],"title":"运行激光雷达驱动","title_tokens":["激光雷达","雷达","激光","运行","驱动"]},{"location":"hhp/5.1_%E6%9C%BA%E5%99%A8%E8%A7%86%E8%A7%89%E4%BB%8B%E7%BB%8D/","text":"机器视觉介绍 机器视觉概念 机器视觉， 就是用计算机来模拟人的视觉功能，但这并不仅仅是人眼的简单延伸，更重要的是像人脑一样，可以从客观事物的图像中提取信息，进行处理并加以理解，最终用于实际检测、控制等场景。 获取图像信息相对简单，但想让机器人理解图像中千变万化的物品，就难上加难了。 为了解决这一系列复杂的问题，机器视觉也是一个涉猎广泛的交叉学科，横跨人工智能、神经生物学、物理学、计算机科学、图像处理、模式识别等诸多领域。时至今日，在各个领域中，都有大量开发者或组织参与其中，也积累了众多技术，不过依然还有很多问题亟待解决，就像我们对自己大脑的研究也只是冰山一角一样，机器视觉的研究也将会是一个长久的工作。 机器视觉相关的关键技术也有不少，比如视觉图像的采集和信号处理，这个过程主要是通过传感器硬件采集外部光信号的过程，光信号最终会转变成数字电路的信号，便于下一步的处理；类似左边图片中看到的效果，获取图像之后，更重要的是要识别图像中的物体、确定物体的位置、或者检测物品的变化，这就要用到模式识别或者机器学习等技术，这个部分也是当今机器视觉研究的重点。 和人类的两只眼睛不同，机器用于获取图像的传感器种类较为丰富，可以是一个摄像头，也可以是两个摄像头，还可以是三个、四个、很多个摄像头，不仅可以获取颜色信息，还可以通过红外相机获取深度或者能量信息，这可比人眼获取的信息丰富多了，当然，这也会对后期的处理带来不同的计算压力。 在工业领域，机器视觉系统已经被广泛用于自动检验、工件加工、装配自动化以及生产过程控制等工作。随着机器人的快速发展和应用，机器视觉也逐渐应用于农业机器人、AMR物流机器人、服务机器人、无人驾驶汽车等各种机器人，活跃在农场、物流、仓储、交通、医院等多种环境中。 机器视觉流程 人类视觉擅长于对复杂、非结构化的场景进行定性解释，但机器视觉凭借速度、精度和可重复性等优势，非常适合对结构化场景进行定量测量。 一般来讲，典型的机器视觉系统可以分为如图所示的三个部分：图像采集、图像分析和控制输出。 图像采集注重对原始光学信号的采样，是整个视觉系统的传感部分，核心是相机和相关的配件。 其中光源用于照明待检测的物体，并突显其特征，便于让相机能够更好的捕捉图像。光源是影响机器视觉系统成像质量的重要因素，好的光源和照明效果对机器视觉判断影响很大。当前，机器视觉的光源已经突破人眼的可见光范围，其光谱范围跨越红外光（IR）、可见光、紫外光（UV）乃至X射线波段，可实现更精细和更广泛的检测范围，以及特殊成像需求。 相机被喻为机器视觉系统的“眼睛”，承担着图像信息采集的重要任务。图像传感器又是相机的核心元器件，主要有CCD和CMOS两种类型，其工作原理是将相机镜头接收到的光学信号转化成数字信号。选择合适的相机是机器视觉系统设计的重要环节，不仅直接决定了采集图像的质量和速度，同时也与整个系统的运行模式相关。 图像处理系统接收到相机传来的数字图像之后，通过各种软件算法进行图像特征提取、特征分析和数据标定，最后进行判断。这是各种视觉算法研究最为集中的部分，从传统的模式识别算法，到当前热门的各种机器学习方法，都是为了更好的让机器理解环境。 对于人来讲，识别某一个物体是苹果似乎理所当然，但是对于机器人来讲，就需要提取各种各样不同种类、颜色、形状的苹果特征，然后训练得到一个苹果的“模型”，再通过这个模型对实时图像做匹配，从而分析面前这个东西到底是不是苹果。 在机器人系统中，视觉识别的结果最终要和机器人的某些行为绑定，也就是第三个部分——控制输出，包含I/O接口、运动控制、可视化显示等。当图像处理系统完成图像分析后，将判断的结果发给机器人控制系统，接下来机器人完成运动控制。比如视觉识别到了抓取目标的位置，通过IO口控制夹爪完成抓取和放置，过程中识别的结果和运动的状态，都可以在上位机中显示，方便我们监控。 就机器视觉而言，在这三个部分中，图像分析占据了绝对的核心，涉及的方法、使用的各种开源软件或者框架非常多，这也是我们后续开发的重点，TogetherROS中提供了大量的算法、工具和功能支持。 旭日X3派配置 了解了机器视觉的基本原理和流程，相信大家对视觉应用已经充满了期待，我们这就准备开始。 后续课程中，我们将继续在旭日X3派的开发板上，使用TogetherROS实现各种各样的视觉例程，不过我们得先找到一个相机，比如usb相机或者MIPI接口配套的相机模块，然后连接到开发板对应的接口上。 电脑和开发板之前通过网线连接，便于我们查看视觉处理的结果，速度更快。 如果有HDMI屏幕的话，也可以准备好，稍后需要使用的时候插上查看结果，如果没有的话，也没有影响，后续我们会使用一套网络传输工具，通过板卡的IP地址，就可以看到图像处理的实时状态啦。 USB相机图像采集 关于相机的驱动，请大家也再确认一下，这是后续视觉处理的基础。 如果是USB相机的话，可以参考这个过程验证下是否可以顺利看到图像。 # 旭日X3派 $ sudo apt install ros-foxy-usb-cam $ cd /opt/tros $ python3 create_soft_link.py --foxy /opt/ros/foxy/ --tros /opt/tros $ source /opt/tros/local_setup.bash $ ros2 launch usb_cam demo_launch.py # 修改params.yaml配置文件中的设备号 # PC $ source /opt/ros/foxy/local_setup.bash $ ros2 run rqt_image_view rqt_image_view MIPI相机图像采集 如果使用的是MIPI相机的话，可以参考这个流程驱动相机并显示图像。 # 旭日X3派 $ source /opt/tros/local_setup.bash $ ros2 run mipi_cam mipi_cam --ros-args -p video_device: = F37 -p image_width: = 960 -p image_height: = 540 # PC $ source /opt/ros/foxy/local_setup.bash $ ros2 run rqt_image_view rqt_image_view 为了提高图像的编码和传输效率，我们建议大家使用MIPI接口的相机，后续应用功能我们也会以该相机为主。","text_tokens":["soft","基础","红外","擅长","原始","涉猎","环节","获取","突显","很大","后续","就","是不是","无人驾驶","，","驾驶","usb","识别","众多","重要","概念","状态","可见光","交叉","通过","特殊","create","各种","找到","神经","不仅","问题","随着","今日","输出","判断","目标","这是","一个","擅长于","：","来","cmos","一系列","研究","延伸","课程","决定","非常适合","基本","i","后","冰山","使用","人脑","跨越","学科","放置","农业","集中","没有","中","模式","可重复性","射线","合适","amr","分为","系统","诸多","质量","也","深度","传来","自动化","可以","rqt","image","o","摄像","需求","960","介绍","横跨","不是","最终","形状","电路","计算","亟待","两个","自己","应用","--","同时","理解","图像处理","旭日","效率","$","cam","实时","请","像头","params","自动","整个","很多","模型","数字","height","信号","领域","两只","ccd","接收","变化","方便","就要","紫外光","行为","种类","物体","转变","光学","注重","模拟","广泛","特征","如果","接下","电脑","继续","cd","文件","不仅仅","物理","三个","得到","做","source","第三个","如图所示","只是","地址","左边","能够","得","光源","=","典型","快","可视","因素","重复性","工具","稍后","两种","工业","加以","配件","选择","匹配","客观","农场","uv","时至今日","位置","驱动","仓储","了","照明","定量","抓取","或","生物学","复性","最为","流程","完成",".","比如","对应","软件","关键","计算机科学","会","都","与","派","亟待解决","绑定","技术","width","光","待","提高","配置","。","device","训练","检验","图片","再","框架","数字图像","install","冰山一角","；","还有","传统","号","py","任务","学习","变成","opt","物流","不同","带来","方法","数字电路","又","类型","一套","配套","其中","解释","人","摄像头","提取","不少","爪","但是","开发者","控制系统","结果","颜色","发给","丰富","可","影响","智能","检测","数字电","将","接下来","用到","突破","当然","组织","算法","模式识别","过程","实现","感器","人工","器件","充满","/","下来","汽车","_","一角","是否","物品","下","传感","外部","用","眼睛","啦","到","和","x3","已经","难上加难","模块","屏幕","积累","要","核心","活跃","并","千变万化","逐渐","网络","元器","foxy","ir","个","io","可视化","还","但","信号处理","标定","p","理所当然","服务",":","苹果","基本原理","不过","local","客观事物","看到","进行","场景","为了","从","以及","可比","镜头","最后","压力","生产","编码","一般来讲","效果","run","了解","video","环境","红外光","开始","当今","开源","关键技术","视觉","解决","各个领域","热门","yaml","想","机器人","控制","就是","网线","板卡","紫外","对","原理","人类","承担","让","一样","后期","精细","开发","转化","确定","第三","重复","之前","科学","（","togetherros","简单","接口","以","非","#","四个","apt","参考","处理","夹","相对","速度","绝对","乃至","是","准备","x射线","上","setup","于","占据","适合","设备","系列","依然","硬件","多种","demo","大家","来讲","大量","工件","似乎","更好","数据","元器件","—","特征提取","而言","验证","ros","发展","理学","用于","一步","相信","结构化","参与","医院","捕捉","无人","更","口","pc","f37","转化成","精度","生物","从而","能量","范围","支持","运行","当前","bash","好","加工","包含","对于","查看","上位","图像","建议","复杂","机器","工作","sudo","插上","一系","计算机","转变成","重点"," ","这个","主要","东西","设计","-","被","数字信号","长于","提供","tros","先","之后","关于","配置文件","各种各样","这","成像","人工智能","特征分析","物理学","事物","多","采集","功能","大脑","各样","到底","link","采样","某些","类似","view","“","光谱","运动","launch","相关","所示","测量","一般","着","当","便于","监控","喻为","分析","像","时候","顺利","较为","例程","、","mipi","）","传输","我们","的","定性","hdmi","ip地址","波段","化成","机中","其","凭借","ros2","确认","重要环节","信息","某","装配","一下","540","涉及","优势","等","人眼","在","结构","部分","快速","”","的话","显示","python3","仅仅","至今","非常","面前","本原","然后","该","相机","各个","连接","直接","交通","为主","交叉学科","长久","或者","期待","args","有","传感器","修改","开发板","需要","实际","可见","算机"],"title":"机器视觉介绍","title_tokens":["介绍","视觉","机器"]},{"location":"hhp/5.1_%E6%9C%BA%E5%99%A8%E8%A7%86%E8%A7%89%E4%BB%8B%E7%BB%8D/#_1","text":"","text_tokens":[],"title":"机器视觉介绍","title_tokens":["介绍","视觉","机器"]},{"location":"hhp/5.1_%E6%9C%BA%E5%99%A8%E8%A7%86%E8%A7%89%E4%BB%8B%E7%BB%8D/#_2","text":"机器视觉， 就是用计算机来模拟人的视觉功能，但这并不仅仅是人眼的简单延伸，更重要的是像人脑一样，可以从客观事物的图像中提取信息，进行处理并加以理解，最终用于实际检测、控制等场景。 获取图像信息相对简单，但想让机器人理解图像中千变万化的物品，就难上加难了。 为了解决这一系列复杂的问题，机器视觉也是一个涉猎广泛的交叉学科，横跨人工智能、神经生物学、物理学、计算机科学、图像处理、模式识别等诸多领域。时至今日，在各个领域中，都有大量开发者或组织参与其中，也积累了众多技术，不过依然还有很多问题亟待解决，就像我们对自己大脑的研究也只是冰山一角一样，机器视觉的研究也将会是一个长久的工作。 机器视觉相关的关键技术也有不少，比如视觉图像的采集和信号处理，这个过程主要是通过传感器硬件采集外部光信号的过程，光信号最终会转变成数字电路的信号，便于下一步的处理；类似左边图片中看到的效果，获取图像之后，更重要的是要识别图像中的物体、确定物体的位置、或者检测物品的变化，这就要用到模式识别或者机器学习等技术，这个部分也是当今机器视觉研究的重点。 和人类的两只眼睛不同，机器用于获取图像的传感器种类较为丰富，可以是一个摄像头，也可以是两个摄像头，还可以是三个、四个、很多个摄像头，不仅可以获取颜色信息，还可以通过红外相机获取深度或者能量信息，这可比人眼获取的信息丰富多了，当然，这也会对后期的处理带来不同的计算压力。 在工业领域，机器视觉系统已经被广泛用于自动检验、工件加工、装配自动化以及生产过程控制等工作。随着机器人的快速发展和应用，机器视觉也逐渐应用于农业机器人、AMR物流机器人、服务机器人、无人驾驶汽车等各种机器人，活跃在农场、物流、仓储、交通、医院等多种环境中。","text_tokens":["只是","红外","服务","左边","加工","涉猎","发展","获取","不过","客观事物","图像","就","看到","进行","无人驾驶","场景","为了","从","以及","复杂","，","机器","可比","驾驶","工业","工作","加以","压力","生产","一系","计算机","客观","识别","众多","转变成","农场","时至今日","重点","重要"," ","位置","这个","主要","了","仓储","效果","被","环境","或","交叉","生物学","通过","比如","各种","之后","神经","不仅","问题","当今","今日","关键","计算机科学","关键技术","随着","会","这","人工智能","视觉","解决","各个领域","物理学","一个","想","事物","都","多","采集","功能","亟待解决","大脑","机器人","控制","就是","技术","来","光","一系列","对","延伸","研究","类似","人类","。","检验","让","图片","一样","后期","相关","开发","冰山","冰山一角","；","人脑","还有","学科","确定","科学","农业","中","学习","变成","模式","便于","简单","物流","amr","不同","带来","系统","数字电路","像","诸多","也","较为","其中","深度","自动化","、","四个","人","摄像头","提取","不少","可以","我们","的","处理","相对","开发者","摄像","颜色","横跨","丰富","是","最终","智能","电路","检测","计算","数字电","亟待","两个","将","于","用到","当然","组织","自己","信息","应用","系列","模式识别","理解","图像处理","依然","过程","硬件","感器","装配","多种","人工","等","大量","工件","人眼","像头","在","部分","自动","一角","很多","快速","物品","下","汽车","传感","外部","数字","用","眼睛","信号","理学","仅仅","领域","至今","用于","和","一步","难上加难","两只","相机","已经","变化","各个","参与","就要","积累","要","医院","无人","种类","物体","更","转变","交通","活跃","并","千变万化","逐渐","交叉学科","长久","或者","个","模拟","广泛","生物","有","传感器","能量","还","但","不仅仅","物理","信号处理","三个","实际","算机"],"title":"机器视觉概念","title_tokens":["概念","视觉","机器"]},{"location":"hhp/5.1_%E6%9C%BA%E5%99%A8%E8%A7%86%E8%A7%89%E4%BB%8B%E7%BB%8D/#_3","text":"人类视觉擅长于对复杂、非结构化的场景进行定性解释，但机器视觉凭借速度、精度和可重复性等优势，非常适合对结构化场景进行定量测量。 一般来讲，典型的机器视觉系统可以分为如图所示的三个部分：图像采集、图像分析和控制输出。 图像采集注重对原始光学信号的采样，是整个视觉系统的传感部分，核心是相机和相关的配件。 其中光源用于照明待检测的物体，并突显其特征，便于让相机能够更好的捕捉图像。光源是影响机器视觉系统成像质量的重要因素，好的光源和照明效果对机器视觉判断影响很大。当前，机器视觉的光源已经突破人眼的可见光范围，其光谱范围跨越红外光（IR）、可见光、紫外光（UV）乃至X射线波段，可实现更精细和更广泛的检测范围，以及特殊成像需求。 相机被喻为机器视觉系统的“眼睛”，承担着图像信息采集的重要任务。图像传感器又是相机的核心元器件，主要有CCD和CMOS两种类型，其工作原理是将相机镜头接收到的光学信号转化成数字信号。选择合适的相机是机器视觉系统设计的重要环节，不仅直接决定了采集图像的质量和速度，同时也与整个系统的运行模式相关。 图像处理系统接收到相机传来的数字图像之后，通过各种软件算法进行图像特征提取、特征分析和数据标定，最后进行判断。这是各种视觉算法研究最为集中的部分，从传统的模式识别算法，到当前热门的各种机器学习方法，都是为了更好的让机器理解环境。 对于人来讲，识别某一个物体是苹果似乎理所当然，但是对于机器人来讲，就需要提取各种各样不同种类、颜色、形状的苹果特征，然后训练得到一个苹果的“模型”，再通过这个模型对实时图像做匹配，从而分析面前这个东西到底是不是苹果。 在机器人系统中，视觉识别的结果最终要和机器人的某些行为绑定，也就是第三个部分——控制输出，包含I/O接口、运动控制、可视化显示等。当图像处理系统完成图像分析后，将判断的结果发给机器人控制系统，接下来机器人完成运动控制。比如视觉识别到了抓取目标的位置，通过IO口控制夹爪完成抓取和放置，过程中识别的结果和运动的状态，都可以在上位机中显示，方便我们监控。 就机器视觉而言，在这三个部分中，图像分析占据了绝对的核心，涉及的方法、使用的各种开源软件或者框架非常多，这也是我们后续开发的重点，TogetherROS中提供了大量的算法、工具和功能支持。","text_tokens":["理所当然","擅长","红外","能够","光源","典型","包含","原始","环节","苹果","对于","突显","很大","上位","可视","后续","图像","就","因素","重复性","进行","是不是","场景","为了","工具","两种","以及","复杂","从","，","机器","镜头","最后","工作","配件","选择","匹配","识别","uv","一般来讲","重点","重要"," ","位置","这个","主要","了","照明","效果","东西","设计","状态","可见光","定量","被","抓取","数字信号","环境","复性","长于","红外光","通过","提供","特殊","最为","完成","比如","各种","软件","之后","不仅","目标","输出","判断","开源","这是","各种各样","这","成像","视觉","特征分析","热门","一个","都","多","擅长于","与","采集","功能","：","各样","机器人","控制","到底","绑定","就是","cmos","紫外","对","采样","研究","待","原理","人类","非常适合","决定","。","某些","训练","承担","让","“","光谱","再","框架","数字图像","精细","i","运动","相关","后","开发","转化","跨越","传统","使用","放置","第三","重复","所示","任务","测量","一般","集中","着","学习","中","（","当","可重复性","便于","射线","合适","模式","togetherros","分为","不同","接口","监控","系统","喻为","非","分析","方法","质量","又","类型","也","其中","传来","解释","、","人","提取","可以","）","我们","的","定性","爪","但是","处理","夹","o","控制系统","需求","结果","速度","颜色","绝对","发给","可","影响","是","乃至","波段","化成","检测","形状","x射线","不是","最终","将","机中","接下来","其","凭借","突破","占据","当然","重要环节","适合","信息","算法","某","第三个","同时","模式识别","实现","图像处理","理解","过程","感器","涉及","优势","等","来讲","似乎","器件","大量","实时","人眼","更好","数据","元器件","—","/","下来","特征提取","在","结构","部分","整个","”","模型","显示","传感","数字","而言","眼睛","信号","到","和","非常","面前","用于","已经","ccd","然后","相机","结构化","接收","方便","紫外光","行为","要","捕捉","种类","物体","核心","更","直接","口","光学","并","转化成","元器","精度","ir","或者","注重","io","广泛","特征","从而","可视化","接下","传感器","有","范围","但","支持","运行","三个","当前","标定","需要","得到","做","可见","好","如图所示"],"title":"机器视觉流程","title_tokens":["视觉","机器","流程"]},{"location":"hhp/5.1_%E6%9C%BA%E5%99%A8%E8%A7%86%E8%A7%89%E4%BB%8B%E7%BB%8D/#x3","text":"了解了机器视觉的基本原理和流程，相信大家对视觉应用已经充满了期待，我们这就准备开始。 后续课程中，我们将继续在旭日X3派的开发板上，使用TogetherROS实现各种各样的视觉例程，不过我们得先找到一个相机，比如usb相机或者MIPI接口配套的相机模块，然后连接到开发板对应的接口上。 电脑和开发板之前通过网线连接，便于我们查看视觉处理的结果，速度更快。 如果有HDMI屏幕的话，也可以准备好，稍后需要使用的时候插上查看结果，如果没有的话，也没有影响，后续我们会使用一套网络传输工具，通过板卡的IP地址，就可以看到图像处理的实时状态啦。","text_tokens":["地址","得","查看","快","基本原理","不过","后续","就","看到","图像","工具","稍后","，","机器","usb","插上"," ","了","了解","状态","通过","开始","流程","比如","各种","对应","先","找到","各种各样","会","这","视觉","一个","派","各样","网线","板卡","对","课程","原理","。","基本","开发","使用","之前","没有","中","togetherros","便于","接口","时候","一套","配套","也","例程","mipi","可以","传输","我们","的","处理","结果","hdmi","速度","ip地址","影响","准备","上","将","应用","旭日","实现","图像处理","大家","实时","充满","在","的话","啦","到","和","本原","x3","已经","相信","然后","相机","模块","屏幕","连接","更","网络","或者","期待","如果","电脑","继续","有","开发板","需要","好"],"title":"旭日X3派配置","title_tokens":["x3","派","旭日","配置"]},{"location":"hhp/5.1_%E6%9C%BA%E5%99%A8%E8%A7%86%E8%A7%89%E4%BB%8B%E7%BB%8D/#usb","text":"关于相机的驱动，请大家也再确认一下，这是后续视觉处理的基础。 如果是USB相机的话，可以参考这个过程验证下是否可以顺利看到图像。 # 旭日X3派 $ sudo apt install ros-foxy-usb-cam $ cd /opt/tros $ python3 create_soft_link.py --foxy /opt/ros/foxy/ --tros /opt/tros $ source /opt/tros/local_setup.bash $ ros2 launch usb_cam demo_launch.py # 修改params.yaml配置文件中的设备号 # PC $ source /opt/ros/foxy/local_setup.bash $ ros2 run rqt_image_view rqt_image_view","text_tokens":["soft","基础","local","后续","看到","图像","，","sudo","usb"," ","驱动","这个","run","-","tros","create",".","关于","配置文件","这是","视觉","yaml","派","link","配置","view","。","再","install","launch","号","py","中","opt","顺利","#","也","apt","可以","rqt","image","的","参考","处理","是","setup","ros2","确认","设备","--","旭日","一下","过程","demo","大家","$","cam","请","/","params","_","是否","的话","下","验证","python3","ros","x3","相机","pc","foxy","如果","cd","修改","文件","bash","source"],"title":"USB相机图像采集","title_tokens":["相机","图像","采集","usb"]},{"location":"hhp/5.1_%E6%9C%BA%E5%99%A8%E8%A7%86%E8%A7%89%E4%BB%8B%E7%BB%8D/#mipi","text":"如果使用的是MIPI相机的话，可以参考这个流程驱动相机并显示图像。 # 旭日X3派 $ source /opt/tros/local_setup.bash $ ros2 run mipi_cam mipi_cam --ros-args -p video_device: = F37 -p image_width: = 960 -p image_height: = 540 # PC $ source /opt/ros/foxy/local_setup.bash $ ros2 run rqt_image_view rqt_image_view 为了提高图像的编码和传输效率，我们建议大家使用MIPI接口的相机，后续应用功能我们也会以该相机为主。","text_tokens":["opt","效率","大家","接口","$","cam",":","以","=","/","#","也","会","local","_","的话","后续","图像","显示","建议","mipi","ros","height","派","为了","和","功能","x3","width","，","可以","rqt","image","传输","相机","我们","的","该","参考","p","提高","view","。","device","编码","并","f37","960","pc","foxy","为主"," ","驱动","这个","如果","使用","是","args","run","setup","-","video","应用","ros2","540","bash","source","tros","--","流程","旭日","."],"title":"MIPI相机图像采集","title_tokens":["mipi","图像","采集","相机"]},{"location":"hhp/5.2_CV%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%8A%A0%E9%80%9F/","text":"CV图像加速处理 OpenCV是一个著名的机器视觉处理库，相信大家都有听过，这个库中有很多图像处理的基础算法，比如灰度变化、图像滤波等，不过这个库为了保证较好的通用性，主要通过软件实现各种算法，TogetherROS对此作了大量优化，我们一起来看看。 TogetherROS视觉加速 TogetherROS系统中集成了地平线Hobot CV视觉加速库，通过底层芯片中的硬件引擎，软硬件协同，可以提升常用CV算子的性能，降低系统资源的消耗，例如高斯滤波、图像缩放、畸变校正等常用的视觉处理方法。 而且在接口风格上兼容OpenCV，可以做到与OpenCV混合编程，便于视觉应用的开发。 具体测试CV加速库的效率，与OpenCV中软件实现的效率进行对比，我们分别对比图像缩放的帧率，图像旋转的帧率，高斯滤波的帧率，通过Hobot CV视觉加速库运行的帧率可以做到OpenCV的2到3倍，甚至更多倍。 效果这么好，具体该如何使用呢？ 高斯滤波 我们先来看下图像处理中常用的高斯滤波算法，OpenCV和hobotcv，正面PK一下，我们也看看在程序中如何使用hobotcv的图像处理加速算法。 运行示例程序 $ source /opt/tros/setup.bash $ cp -r /opt/tros/lib/hobot_cv/config/ . $ ros2 launch hobot_cv hobot_cv_gaussian_blur.launch.py 代码解析 代码地址：https://c-gitlab.horizon.ai/HHP/box/hobot_cv/-/blob/develop/test/test_gaussian_blur.cpp // Copyright (c) 2021 Horizon Robotics.All Rights Reserved. // // The material in this file is confidential and contains trade secrets // of Horizon Robotics Inc. This is proprietary information owned by // Horizon Robotics Inc. No part of this work may be disclosed, // reproduced, copied, transmitted, or used in any way for any purpose, // without the express written permission of Horizon Robotics Inc. #include <algorithm> #include <chrono> #include <fstream> #include <iomanip> #include <iostream> #include <iterator> #include <map> #include <queue> #include <utility> #include \"hobotcv_gaussian_blur.h\" #include \"opencv2/core/mat.hpp\" #include \"opencv2/imgcodecs.hpp\" #include \"opencv2/imgproc.hpp\" void analyse_result ( cv :: Mat & out_filter , cv :: Mat & cls_filter , std :: string flag_name ) { auto start_time = std :: chrono :: steady_clock :: now (); std :: cout << \"\" << std :: endl ; std :: cout << \"analyse_result start \" << std :: endl ; std :: cout << \"---------\" << flag_name << std :: endl ; std :: cout << \"out_filter type:\" << out_filter . type () << \",cols:\" << out_filter . cols << \",rows:\" << out_filter . rows << \",channel:\" << out_filter . channels () << std :: endl ; std :: cout << \"cls_filter type:\" << cls_filter . type () << \",cols:\" << cls_filter . cols << \",rows:\" << cls_filter . rows << \",channel:\" << cls_filter . channels () << std :: endl ; double minvalue , maxvalue ; cv :: Point mixIdx , maxIdx ; cv :: minMaxLoc ( out_filter , & minvalue , & maxvalue , & mixIdx , & maxIdx ); std :: cout << \"out_filter minvalue:\" << minvalue << \",max:\" << maxvalue << std :: endl ; std :: cout << \"out_filter min,x:\" << mixIdx . x << \",y:\" << mixIdx . y << std :: endl ; std :: cout << \"out_filter max,x:\" << maxIdx . x << \",y:\" << maxIdx . y << std :: endl ; cv :: minMaxLoc ( cls_filter , & minvalue , & maxvalue , & mixIdx , & maxIdx ); std :: cout << \"cls_filter minvalue:\" << minvalue << \",max:\" << maxvalue << std :: endl ; std :: cout << \"cls_filter min,x:\" << mixIdx . x << \",y:\" << mixIdx . y << std :: endl ; std :: cout << \"cls_filter max,x:\" << maxIdx . x << \",y:\" << maxIdx . y << std :: endl ; cv :: Mat mat_diff = cv :: abs ( out_filter - cls_filter ); cv :: Scalar sum_error = cv :: sum ( mat_diff >= 1 ); cv :: Scalar mean_error = cv :: sum ( mat_diff ) / ( mat_diff . rows * mat_diff . cols ); cv :: minMaxLoc ( mat_diff , & minvalue , & maxvalue , & mixIdx , & maxIdx ); std :: cout << \"\" << std :: endl ; std :: cout << \"diff diff diff\" << std :: endl ; std :: cout << \"mat_diff minvalue:\" << minvalue << \",max:\" << maxvalue << std :: endl ; std :: cout << \"mat_diff min,x:\" << mixIdx . x << \",y:\" << mixIdx . y << std :: endl ; std :: cout << \"mat_diff max,x:\" << maxIdx . x << \",y:\" << maxIdx . y << std :: endl ; std :: cout << \"\" << std :: endl ; std :: cout << \"error sum:\" << sum_error [ 0 ] << \",max:\" << maxvalue << \",mean_error:\" << mean_error [ 0 ] << std :: endl ; int time_used_ms_end = std :: chrono :: duration_cast < std :: chrono :: milliseconds > ( std :: chrono :: steady_clock :: now () - start_time ) . count (); std :: cout << \"analyse_result,time_used_ms_end:\" << time_used_ms_end << std :: endl ; std :: cout << \"analyse_result end \" << std :: endl ; std :: cout << \"\" << std :: endl ; } int main () { int32_t ret = -1 ; HobotGaussianBlurParam blur_param ; HOBOTCV_INITIALIZE_GAUSSIAN_BLUR_PARAM ( & blur_param ); HobotCVGaussianBlurHandle handle ; ret = HobotCVGaussianBlurCreate ( blur_param , & handle ); if ( ret < 0 ) { printf ( \"HobotCVGaussianBlurCreate failed, error msg:%d \\n \" , ret ); return -1 ; } for ( int i = 0 ; i < 5 ; i ++ ) { std :: string m_tof_file_s = \"images/frame1_\" + std :: to_string ( i ) + \".png\" ; std :: cout << \"===================\" << std :: endl ; std :: cout << \"image name :\" << m_tof_file_s << std :: endl ; cv :: Mat src = cv :: imread ( m_tof_file_s , CV_16UC1 ); cv :: Mat dst ; cv :: medianBlur ( src , src , 3 ); auto start_time_infe = std :: chrono :: steady_clock :: now (); ret = HobotCVGaussianBlurProcess ( handle , & src , & dst ); if ( ret < 0 ) { printf ( \"HobotCVGaussianBlurProcess failed, error msg:%d \\n \" , ret ); return -1 ; } int infe_time = std :: chrono :: duration_cast < std :: chrono :: microseconds > ( std :: chrono :: steady_clock :: now () - start_time_infe ). count (); std :: cout << \"infe cost time:\" << infe_time << std :: endl ; auto start_time_gauss = std :: chrono :: steady_clock :: now (); cv :: Mat gaussian_tof ; cv :: GaussianBlur ( src , gaussian_tof , cv :: Size ( 3 , 3 ), 0 , 0 , cv :: BORDER_REPLICATE ); int guss_time = std :: chrono :: duration_cast < std :: chrono :: microseconds > ( std :: chrono :: steady_clock :: now () - start_time_gauss ). count (); std :: cout << \"guss_time cost time:\" << guss_time << std :: endl ; float save_rate = float (( guss_time * 1.0 - infe_time * 1.0 ) / guss_time ); std :: cout << \"hobotcv save rate:\" << save_rate << std :: endl ; analyse_result ( dst , gaussian_tof , \"GaussianBlur\" ); std :: cout << \"-------------------------\" << std :: endl ; std :: cout << \"\" << std :: endl ; } ret = HobotCVGaussianBlurDestroy ( handle ); if ( ret < 0 ) { printf ( \"HobotCVGaussianBlurDestroy failed, error msg:%d \\n \" , ret ); return -1 ; } return 0 ; } 图像裁剪与缩放 再来看另外一个案例，图像的裁剪与缩放，比如这样一幅图片，我们尝试剪裁左上角的一小块图像出来，或者对裁剪的某一块图像放大来看看。 运行示例程序 # 配置TogetherROS环境 source /opt/tros/setup.bash # 从TogetherROS的安装路径中拷贝出运行示例需要的模型和配置文件。 cp -r /opt/tros/lib/hobot_cv/config/ . # 启动launch文件 ros2 launch hobot_cv hobot_cv_crop_resize.launch.py 代码解析 代码地址：https://c-gitlab.horizon.ai/HHP/box/hobot_cv/-/blob/develop/src/test.cpp // Copyright (c) 2021 Horizon Robotics.All Rights Reserved. // // The material in this file is confidential and contains trade secrets // of Horizon Robotics Inc. This is proprietary information owned by // Horizon Robotics Inc. No part of this work may be disclosed, // reproduced, copied, transmitted, or used in any way for any purpose, // without the express written permission of Horizon Robotics Inc. #include \"include/hobotcv_imgproc.h\" #include \"include/utils.h\" #include \"opencv2/core/mat.hpp\" #include \"opencv2/core/types.hpp\" #include \"opencv2/imgcodecs.hpp\" #include \"opencv2/opencv.hpp\" #include <fstream> #include <string> #include <chrono> #include <iostream> void writeImg ( cv :: Mat & mat , std :: string imgfile ) { cv :: Mat img_bgr ; cv :: cvtColor ( mat , img_bgr , cv :: COLOR_YUV2BGR_NV12 ); cv :: imwrite ( imgfile , img_bgr ); } int main () { std :: string image_file = \"config/test.jpg\" ; cv :: Mat bgr_mat = cv :: imread ( image_file , cv :: IMREAD_COLOR ); auto src_height = bgr_mat . rows ; auto src_width = bgr_mat . cols ; cv :: Mat srcmat_nv12 ; BGRToNv12 ( bgr_mat , srcmat_nv12 ); auto dst_height = src_height / 2 ; auto dst_width = src_width / 2 ; cv :: Mat dstmat_nv12 ( dst_height * 3 / 2 , dst_width , CV_8UC1 ); auto before_resize = std :: chrono :: system_clock :: now (); auto ret = hobot_cv :: hobotcv_resize ( srcmat_nv12 , src_height , src_width , dstmat_nv12 , dst_height , dst_width ); auto after_resize = std :: chrono :: system_clock :: now (); auto interval = std :: chrono :: duration_cast < std :: chrono :: milliseconds > ( after_resize - before_resize ). count (); if ( 0 == ret ) { std :: cout << \"resize finish, time: \" << interval << \"ms\" << std :: endl ; } writeImg ( dstmat_nv12 , \"./resize.jpg\" ); auto before_crop = std :: chrono :: system_clock :: now (); auto cropmat = hobot_cv :: hobotcv_crop ( srcmat_nv12 , src_height , src_width , 200 , 200 , cv :: Range ( 0 , 200 ), cv :: Range ( 0 , 200 )); auto after_crop = std :: chrono :: system_clock :: now (); interval = std :: chrono :: duration_cast < std :: chrono :: milliseconds > ( after_crop - before_crop ). count (); std :: cout << \"crop finish, time: \" << interval << \"ms\" << std :: endl ; writeImg ( cropmat , \"./crop.jpg\" ); auto before_cropResize = std :: chrono :: system_clock :: now (); auto cropResizemat = hobot_cv :: hobotcv_crop ( srcmat_nv12 , src_height , src_width , src_height , src_width , cv :: Range ( 200 , 400 ), cv :: Range ( 200 , 400 )); auto after_cropResize = std :: chrono :: system_clock :: now (); interval = std :: chrono :: duration_cast < std :: chrono :: milliseconds > ( after_cropResize - before_cropResize ). count (); std :: cout << \"cropResize finish, time: \" << interval << \"ms\" << std :: endl ; writeImg ( cropResizemat , \"./cropResize.jpg\" ); return 0 ; }","text_tokens":["pk","基础","copyright","proprietary","bgrtonv12","cvtcolor","分别","，","iterator","？","disclosed","库","rows","系统资源","contains","风格","拷贝","旋转","hobotcv","hhp","nv12","通过","听","安装","各种","ai","d","frame1","h","较","案例","by","一个","：","提升","milliseconds","来","作","通用性","16uc1","i","[","\\","使用","rate","中","time","fstream","兼容","系统","transmitted","小块","work","也","jpg","软硬件","可以","校正","image","r","n","gaussianblur","混合","src","in","路径","降低","算子","and","应用","图像处理","flag","效率","develop","尝试","$","max","+","cout","资源","out","呢","模型","很多","做到","height","used","优化","5","dst","变化","]","box","引擎","include","iostream","https","ret","color","robotics","types","文件","source","imgcodecs","maxvalue","地址","=","may","滤波","而且","gitlab","to","2021","(","如何","range","is","endl","2","甚至","count","cols","了","border","代码","rights","of","来看","express","blob","\"",".","这样","比如","放大","软件","率","保证","都","without","与","trade","1","width","before","配置","system","mixidx","。","剪裁","reserved","---------","图片","再","guss","加速","horizon","void","way","py","map","utils","多倍","opt","material","y","起来","方法","config","test","例如","printf","interval","int32","microseconds","启动","png","opencv","++","集成","出来","算法","cast","hobot","实现","all","medianblur","/","_","下","到","和","正面","%","s","8uc1","imread","灰度","3","channels","string","著名","一小块","confidential","be","dstmat","常用","or","point","queue",":","core","}","不过","{","进行","为了","从","file","性能","if",";","0","name","utility","opencv2","一小","crop","出","编程","cpp","iomanip","cls","效果","倍","具体","minvalue","帧","环境","另外","hobotcvgaussianblurprocess","t","ms","高斯","程序","resize","-------------------------","min",")","视觉","&","algorithm","for","return","对","minmaxloc","int","imgproc","开发","result","一块","一幅","srcmat","*","sum","imgfile","togetherros","cropmat","cropresizemat","接口","#","maxidx","一","this","处理","这么","blur","<","hpp","是",">","缩放","上","setup","tof","畸变","硬件","mat","大家","大量","abs","size","copied","对此","msg","左上角","hobotgaussianblurparam","上角","过","相信","initialize","infe","save","scalar","更","diff","no","duration","any","filter","gaussian","运行","bash","cv","1.0","好","c","steady","对比","cp","information","after","channel","permission","裁剪","img","图像","地平线","clock","机器","x","解析","secrets","yuv2bgr","inc","hobotcvgaussianblurhandle","m"," ","type","这个","主要","mean","-","chrono","double","tros","reproduced","示例","测试","failed","先","owned","end","200","配置文件","writeimg","地平","part","handle","看看","协同","imwrite","launch","images","std","purpose","hobotcvgaussianblurdestroy","芯片","written","便于","cost","400","main","、","float","我们","replicate","的","底层","error","库中","ros2","finish","左上","某","hobotcvgaussianblurcreate","软硬","一下","通用","等","param","在","the","bgr","now","该","消耗",",","analyse","auto","或者","cropresize","lib","start","gauss","有","需要"],"title":"CV图像处理加速","title_tokens":["图像处理","处理","图像","加速","cv"]},{"location":"hhp/5.2_CV%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%8A%A0%E9%80%9F/#cv","text":"OpenCV是一个著名的机器视觉处理库，相信大家都有听过，这个库中有很多图像处理的基础算法，比如灰度变化、图像滤波等，不过这个库为了保证较好的通用性，主要通过软件实现各种算法，TogetherROS对此作了大量优化，我们一起来看看。","text_tokens":["图像处理","实现","基础","比如","通用","togetherros","各种","大家","等","软件","大量","起来","较","对此","不过","滤波","很多","视觉","图像","保证","一个","都","、","一","为了","优化","，","机器","相信","过","我们","的","变化","处理","。","库","作","看看","通用性","灰度","opencv","这个","著名","主要","是","了","有","库中","算法","通过","好","听"],"title":"CV图像加速处理","title_tokens":["cv","处理","图像","加速"]},{"location":"hhp/5.2_CV%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%8A%A0%E9%80%9F/#togetherros","text":"TogetherROS系统中集成了地平线Hobot CV视觉加速库，通过底层芯片中的硬件引擎，软硬件协同，可以提升常用CV算子的性能，降低系统资源的消耗，例如高斯滤波、图像缩放、畸变校正等常用的视觉处理方法。 而且在接口风格上兼容OpenCV，可以做到与OpenCV混合编程，便于视觉应用的开发。 具体测试CV加速库的效率，与OpenCV中软件实现的效率进行对比，我们分别对比图像缩放的帧率，图像旋转的帧率，高斯滤波的帧率，通过Hobot CV视觉加速库运行的帧率可以做到OpenCV的2到3倍，甚至更多倍。 效果这么好，具体该如何使用呢？","text_tokens":["对比","滤波","分别","图像","地平线","而且","进行","，","如何","性能","？","库","系统资源","2","甚至","风格"," ","编程","旋转","了","效果","倍","具体","帧","通过","测试","软件","高斯","率","视觉","地平","与","提升","。","协同","开发","使用","加速","芯片","中","多倍","togetherros","兼容","便于","接口","系统","方法","、","例如","软硬件","可以","校正","我们","的","底层","处理","混合","这么","opencv","集成","缩放","上","降低","算子","应用","畸变","软硬","hobot","实现","硬件","效率","等","资源","在","呢","做到","到","该","消耗","更","引擎","3","运行","cv","好","常用"],"title":"TogetherROS视觉加速","title_tokens":["视觉","togetherros","加速"]},{"location":"hhp/5.2_CV%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%8A%A0%E9%80%9F/#_1","text":"我们先来看下图像处理中常用的高斯滤波算法，OpenCV和hobotcv，正面PK一下，我们也看看在程序中如何使用hobotcv的图像处理加速算法。","text_tokens":["图像处理","pk","先","高斯","程序","在","也","滤波","下","图像","和","正面","，","我们","的","如何","处理","。","看看","opencv","使用","加速","hobotcv","来看","一下","算法","中","常用"],"title":"高斯滤波","title_tokens":["滤波","高斯"]},{"location":"hhp/5.2_CV%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%8A%A0%E9%80%9F/#_2","text":"$ source /opt/tros/setup.bash $ cp -r /opt/tros/lib/hobot_cv/config/ . $ ros2 launch hobot_cv hobot_cv_gaussian_blur.launch.py","text_tokens":["opt","$","cp","/","_","config","r","blur","launch"," ","lib","setup","-","ros2","gaussian","py","bash","source","cv","tros","hobot","."],"title":"运行示例程序","title_tokens":["运行","示例","程序"]},{"location":"hhp/5.2_CV%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%8A%A0%E9%80%9F/#_3","text":"代码地址：https://c-gitlab.horizon.ai/HHP/box/hobot_cv/-/blob/develop/test/test_gaussian_blur.cpp // Copyright (c) 2021 Horizon Robotics.All Rights Reserved. // // The material in this file is confidential and contains trade secrets // of Horizon Robotics Inc. This is proprietary information owned by // Horizon Robotics Inc. No part of this work may be disclosed, // reproduced, copied, transmitted, or used in any way for any purpose, // without the express written permission of Horizon Robotics Inc. #include <algorithm> #include <chrono> #include <fstream> #include <iomanip> #include <iostream> #include <iterator> #include <map> #include <queue> #include <utility> #include \"hobotcv_gaussian_blur.h\" #include \"opencv2/core/mat.hpp\" #include \"opencv2/imgcodecs.hpp\" #include \"opencv2/imgproc.hpp\" void analyse_result ( cv :: Mat & out_filter , cv :: Mat & cls_filter , std :: string flag_name ) { auto start_time = std :: chrono :: steady_clock :: now (); std :: cout << \"\" << std :: endl ; std :: cout << \"analyse_result start \" << std :: endl ; std :: cout << \"---------\" << flag_name << std :: endl ; std :: cout << \"out_filter type:\" << out_filter . type () << \",cols:\" << out_filter . cols << \",rows:\" << out_filter . rows << \",channel:\" << out_filter . channels () << std :: endl ; std :: cout << \"cls_filter type:\" << cls_filter . type () << \",cols:\" << cls_filter . cols << \",rows:\" << cls_filter . rows << \",channel:\" << cls_filter . channels () << std :: endl ; double minvalue , maxvalue ; cv :: Point mixIdx , maxIdx ; cv :: minMaxLoc ( out_filter , & minvalue , & maxvalue , & mixIdx , & maxIdx ); std :: cout << \"out_filter minvalue:\" << minvalue << \",max:\" << maxvalue << std :: endl ; std :: cout << \"out_filter min,x:\" << mixIdx . x << \",y:\" << mixIdx . y << std :: endl ; std :: cout << \"out_filter max,x:\" << maxIdx . x << \",y:\" << maxIdx . y << std :: endl ; cv :: minMaxLoc ( cls_filter , & minvalue , & maxvalue , & mixIdx , & maxIdx ); std :: cout << \"cls_filter minvalue:\" << minvalue << \",max:\" << maxvalue << std :: endl ; std :: cout << \"cls_filter min,x:\" << mixIdx . x << \",y:\" << mixIdx . y << std :: endl ; std :: cout << \"cls_filter max,x:\" << maxIdx . x << \",y:\" << maxIdx . y << std :: endl ; cv :: Mat mat_diff = cv :: abs ( out_filter - cls_filter ); cv :: Scalar sum_error = cv :: sum ( mat_diff >= 1 ); cv :: Scalar mean_error = cv :: sum ( mat_diff ) / ( mat_diff . rows * mat_diff . cols ); cv :: minMaxLoc ( mat_diff , & minvalue , & maxvalue , & mixIdx , & maxIdx ); std :: cout << \"\" << std :: endl ; std :: cout << \"diff diff diff\" << std :: endl ; std :: cout << \"mat_diff minvalue:\" << minvalue << \",max:\" << maxvalue << std :: endl ; std :: cout << \"mat_diff min,x:\" << mixIdx . x << \",y:\" << mixIdx . y << std :: endl ; std :: cout << \"mat_diff max,x:\" << maxIdx . x << \",y:\" << maxIdx . y << std :: endl ; std :: cout << \"\" << std :: endl ; std :: cout << \"error sum:\" << sum_error [ 0 ] << \",max:\" << maxvalue << \",mean_error:\" << mean_error [ 0 ] << std :: endl ; int time_used_ms_end = std :: chrono :: duration_cast < std :: chrono :: milliseconds > ( std :: chrono :: steady_clock :: now () - start_time ) . count (); std :: cout << \"analyse_result,time_used_ms_end:\" << time_used_ms_end << std :: endl ; std :: cout << \"analyse_result end \" << std :: endl ; std :: cout << \"\" << std :: endl ; } int main () { int32_t ret = -1 ; HobotGaussianBlurParam blur_param ; HOBOTCV_INITIALIZE_GAUSSIAN_BLUR_PARAM ( & blur_param ); HobotCVGaussianBlurHandle handle ; ret = HobotCVGaussianBlurCreate ( blur_param , & handle ); if ( ret < 0 ) { printf ( \"HobotCVGaussianBlurCreate failed, error msg:%d \\n \" , ret ); return -1 ; } for ( int i = 0 ; i < 5 ; i ++ ) { std :: string m_tof_file_s = \"images/frame1_\" + std :: to_string ( i ) + \".png\" ; std :: cout << \"===================\" << std :: endl ; std :: cout << \"image name :\" << m_tof_file_s << std :: endl ; cv :: Mat src = cv :: imread ( m_tof_file_s , CV_16UC1 ); cv :: Mat dst ; cv :: medianBlur ( src , src , 3 ); auto start_time_infe = std :: chrono :: steady_clock :: now (); ret = HobotCVGaussianBlurProcess ( handle , & src , & dst ); if ( ret < 0 ) { printf ( \"HobotCVGaussianBlurProcess failed, error msg:%d \\n \" , ret ); return -1 ; } int infe_time = std :: chrono :: duration_cast < std :: chrono :: microseconds > ( std :: chrono :: steady_clock :: now () - start_time_infe ). count (); std :: cout << \"infe cost time:\" << infe_time << std :: endl ; auto start_time_gauss = std :: chrono :: steady_clock :: now (); cv :: Mat gaussian_tof ; cv :: GaussianBlur ( src , gaussian_tof , cv :: Size ( 3 , 3 ), 0 , 0 , cv :: BORDER_REPLICATE ); int guss_time = std :: chrono :: duration_cast < std :: chrono :: microseconds > ( std :: chrono :: steady_clock :: now () - start_time_gauss ). count (); std :: cout << \"guss_time cost time:\" << guss_time << std :: endl ; float save_rate = float (( guss_time * 1.0 - infe_time * 1.0 ) / guss_time ); std :: cout << \"hobotcv save rate:\" << save_rate << std :: endl ; analyse_result ( dst , gaussian_tof , \"GaussianBlur\" ); std :: cout << \"-------------------------\" << std :: endl ; std :: cout << \"\" << std :: endl ; } ret = HobotCVGaussianBlurDestroy ( handle ); if ( ret < 0 ) { printf ( \"HobotCVGaussianBlurDestroy failed, error msg:%d \\n \" , ret ); return -1 ; } return 0 ; }","text_tokens":["imgcodecs","maxvalue","copyright","or","proprietary","point","地址","steady","queue",":","=","information","core","}","may","permission","channel","{","gitlab","to","clock","2021","(","x","file","iterator","if","is","secrets","disclosed",";","0","inc","name","utility","opencv2","rows","endl","count","hobotcvgaussianblurhandle","m","contains"," ","iomanip","cpp","type","cls","cols","mean","border","代码","rights","-","of","hobotcv","hhp","chrono","double","minvalue","express","hobotcvgaussianblurprocess","reproduced","t","blob","\"",".","failed","d","ai","ms","frame1","h","owned","end","-------------------------","min",")","by","&","algorithm","without","part","trade","：","for","1","milliseconds","return","handle","mixidx","reserved","---------","minmaxloc","int","16uc1","i","imgproc","images","[","\\","guss","std","purpose","result","hobotcvgaussianblurdestroy","horizon","void","way","written","*","rate","map","sum","time","fstream","material","y","cost","transmitted","work","#","test","maxidx","main","printf","float","image","replicate","this","n","gaussianblur","int32","microseconds","error","src","in","blur","png","<","hpp","++",">","tof","and","cast","hobotcvgaussianblurcreate","hobot","all","mat","flag","develop","medianblur","abs","max","param","+","size","copied","msg","/","cout","out","_","hobotgaussianblurparam","the","now","used","5","initialize","dst","infe","save","scalar","%","s","]",",","analyse","imread","diff","box","include","iostream","auto","3","https","string","channels","ret","no","robotics","start","gauss","confidential","duration","any","filter","gaussian","be","cv","1.0","c"],"title":"代码解析","title_tokens":["解析","代码"]},{"location":"hhp/5.2_CV%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%8A%A0%E9%80%9F/#_4","text":"再来看另外一个案例，图像的裁剪与缩放，比如这样一幅图片，我们尝试剪裁左上角的一小块图像出来，或者对裁剪的某一块图像放大来看看。","text_tokens":["比如","尝试","放大","小块","案例","左上角","裁剪","图像","一个","与","上角","，","我们","来","的","对","剪裁","。","看看","图片","一小","再","或者","一小块","缩放","一块","一幅","来看","出来","左上","另外","某","这样"],"title":"图像裁剪与缩放","title_tokens":["裁剪","图像","与","缩放"]},{"location":"hhp/5.2_CV%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%8A%A0%E9%80%9F/#_5","text":"# 配置TogetherROS环境 source /opt/tros/setup.bash # 从TogetherROS的安装路径中拷贝出运行示例需要的模型和配置文件。 cp -r /opt/tros/lib/hobot_cv/config/ . # 启动launch文件 ros2 launch hobot_cv hobot_cv_crop_resize.launch.py","text_tokens":["opt","togetherros","安装","示例","resize","cp","/","配置文件","#","_","模型","config","从","和","的","r","配置","。","启动","路径","launch","crop","出"," ","拷贝","lib","setup","-","ros2","环境","文件","运行","bash","需要","source","py","cv","tros","hobot","中","."],"title":"运行示例程序","title_tokens":["运行","示例","程序"]},{"location":"hhp/5.2_CV%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%8A%A0%E9%80%9F/#_6","text":"代码地址：https://c-gitlab.horizon.ai/HHP/box/hobot_cv/-/blob/develop/src/test.cpp // Copyright (c) 2021 Horizon Robotics.All Rights Reserved. // // The material in this file is confidential and contains trade secrets // of Horizon Robotics Inc. This is proprietary information owned by // Horizon Robotics Inc. No part of this work may be disclosed, // reproduced, copied, transmitted, or used in any way for any purpose, // without the express written permission of Horizon Robotics Inc. #include \"include/hobotcv_imgproc.h\" #include \"include/utils.h\" #include \"opencv2/core/mat.hpp\" #include \"opencv2/core/types.hpp\" #include \"opencv2/imgcodecs.hpp\" #include \"opencv2/opencv.hpp\" #include <fstream> #include <string> #include <chrono> #include <iostream> void writeImg ( cv :: Mat & mat , std :: string imgfile ) { cv :: Mat img_bgr ; cv :: cvtColor ( mat , img_bgr , cv :: COLOR_YUV2BGR_NV12 ); cv :: imwrite ( imgfile , img_bgr ); } int main () { std :: string image_file = \"config/test.jpg\" ; cv :: Mat bgr_mat = cv :: imread ( image_file , cv :: IMREAD_COLOR ); auto src_height = bgr_mat . rows ; auto src_width = bgr_mat . cols ; cv :: Mat srcmat_nv12 ; BGRToNv12 ( bgr_mat , srcmat_nv12 ); auto dst_height = src_height / 2 ; auto dst_width = src_width / 2 ; cv :: Mat dstmat_nv12 ( dst_height * 3 / 2 , dst_width , CV_8UC1 ); auto before_resize = std :: chrono :: system_clock :: now (); auto ret = hobot_cv :: hobotcv_resize ( srcmat_nv12 , src_height , src_width , dstmat_nv12 , dst_height , dst_width ); auto after_resize = std :: chrono :: system_clock :: now (); auto interval = std :: chrono :: duration_cast < std :: chrono :: milliseconds > ( after_resize - before_resize ). count (); if ( 0 == ret ) { std :: cout << \"resize finish, time: \" << interval << \"ms\" << std :: endl ; } writeImg ( dstmat_nv12 , \"./resize.jpg\" ); auto before_crop = std :: chrono :: system_clock :: now (); auto cropmat = hobot_cv :: hobotcv_crop ( srcmat_nv12 , src_height , src_width , 200 , 200 , cv :: Range ( 0 , 200 ), cv :: Range ( 0 , 200 )); auto after_crop = std :: chrono :: system_clock :: now (); interval = std :: chrono :: duration_cast < std :: chrono :: milliseconds > ( after_crop - before_crop ). count (); std :: cout << \"crop finish, time: \" << interval << \"ms\" << std :: endl ; writeImg ( cropmat , \"./crop.jpg\" ); auto before_cropResize = std :: chrono :: system_clock :: now (); auto cropResizemat = hobot_cv :: hobotcv_crop ( srcmat_nv12 , src_height , src_width , src_height , src_width , cv :: Range ( 200 , 400 ), cv :: Range ( 200 , 400 )); auto after_cropResize = std :: chrono :: system_clock :: now (); interval = std :: chrono :: duration_cast < std :: chrono :: milliseconds > ( after_cropResize - before_cropResize ). count (); std :: cout << \"cropResize finish, time: \" << interval << \"ms\" << std :: endl ; writeImg ( cropResizemat , \"./cropResize.jpg\" ); return 0 ; }","text_tokens":["imgcodecs","copyright","or","proprietary","地址",":","=","bgrtonv12","information","core","}","after","cvtcolor","may","permission","{","img","gitlab","clock","2021","(","file","if","is","secrets","disclosed",";","yuv2bgr","inc","0","range","rows","opencv2","endl","2","count","contains","crop"," ","cpp","cols","代码","rights","-","of","hobotcv","hhp","chrono","nv12","express","reproduced","blob","\"",".","ai","ms","h","owned","resize","200",")","by","&","writeimg","without","part","trade","：","for","width","milliseconds","return","before","system","reserved","imwrite","int","imgproc","std","purpose","horizon","void","way","srcmat","written","*","utils","time","fstream","imgfile","cropmat","material","cropresizemat","400","transmitted","work","#","jpg","config","test","main","interval","image","this","src","in","hpp","opencv","<",">","finish","and","cast","hobot","all","mat","develop","dstmat","copied","/","cout","_","the","bgr","height","now","used","dst","8uc1",",","imread","box","include","iostream","auto","3","https","string","color","ret","cropresize","no","robotics","confidential","types","duration","any","be","cv","c"],"title":"代码解析","title_tokens":["解析","代码"]},{"location":"hhp/5.3_%E6%A8%A1%E5%9E%8B%E6%8E%A8%E7%90%86%E6%A1%86%E6%9E%B6/","text":"模型推理框架 智能机器人与机器学习是紧密相连的，机器学习又可以分成数据采集、标注、训练、推理等环节，其中数据的训练需要消耗大量算力，适合在服务器或者云端进行，不过训练好的模型可是要部署到机器人端进行推理运算的，所以模型推理的效率如何，直接决定了机器人视觉处理的效率，这刚好是TogetherROS所擅长的地方。 Hobot DNN模型推理库 TogetherROS系统集成了Hobot DNN模型推理库，集成了众多开源模型，借助底层芯片中的AI引擎BPU，提供充足的算力保障，开发者实际使用中，就不用花费很多时间在模型的调教和数据的训练上，基于这套系统，很快就可以部署人工智能应用啦。 hobot_dnn是在地平线X3开发板上利用BPU处理器实现AI推理功能，基于地平线EasyDNN和ROS2 Node进行二次开发，为应用开发提供更简单易用的模型集成开发接口，包括模型管理、基于模型描述的输入处理及结果解析，以及模型输出内存分配管理等功能。 关于hobot_dnn的使用逻辑流程如这张图所示，供大家参考，我们后续也会通过具体的案例解释代码的实现过程。 算法与应用库 在Hobot DNN模型推理库的基础上，地平线还提供了一套基于TogetherROS系统的AI算法包，称为BOXs，这样我们就不需要从零构建算法，基于这些标准而高效的算法，可以更关注应用层面的APP开发。 从这张图中我们可以看到，这套AI算法包中包含两大块，一个是基础算法，一个是应用算法。 基础算法中主要是图像分类、语义分割和目标检测这些常用的算法，应用层面就会基于这些算法和某些场景，动态实现更为复杂的人体识别、骨骼点识别、手势识别等具体的功能，这些模块就可以和机器人运功功能直接结合，节省了我们开发AI视觉部分的时间。 模型推理测试 这套模型推理和算法库的效果如何呢？ 我们先来体验一个TogetherROS系统自带的案例，识别这张图片中的人，以及每个人的骨骼关键点。 # 配置TogetherROS环境 $ source /opt/tros/setup.bash # 从tros的安装路径中拷贝出运行示例需要的配置文件。config中为example使用的模型，回灌使用的本地图片 $ cp -r /opt/tros/lib/dnn_node_example/config/ . # 使用本地jpg格式图片通过同步模式进行回环预测，并存储渲染后的图片 $ ros2 launch dnn_node_example hobot_dnn_node_example_feedback.launch.py","text_tokens":["手势","基础","所","app","擅长","服务","逻辑","易用","包含","环节","关注","包中","cp","回灌","这套","feedback","常用","算力","不过","构建","后续","就","看到","地平线","图像","进行","场景","从","以及","复杂","，","机器","花费","解析","如何","？","结合","库","easydnn","标注","动态","识别","众多","语义","出"," ","拷贝","及","分配","了","主要","效果","代码","不用","具体","-","渲染","环境","同步","提供","通过","tros","流程","这样",".","示例","测试","安装","ai","标准","先","云端","利用","开源","输出","关于","案例","刚好","目标","更为","关键","会","配置文件","这","人工智能","视觉","包括","bpu","关键点","部署","一个","与","地平","采集","功能","机器人","来","某些","张图","决定","配置","。","训练","图片","框架","高效","launch","后","描述","开发","点","使用","dnn","处理器","中为","所示","芯片","人体","py","node","中","学习","服务器","opt","togetherros","简单","模式","接口","包","系统","地方","时间","又","一套","#","也","推理","很快","jpg","回环","其中","config","可是","解释","、","二次开发","这张","人","借助","可以","运功","我们","的","如","参考","r","底层","处理","理器","体验","开发者","结果","路径","运算","集成","是","智能","零","而","检测","节省","自带","上","setup","ros2","二次","适合","算法","应用","example","hobot","系统集成","实现","过程","调教","效率","所以","人工","大家","等","$","大量","每个","boxs","数据","/","务器","在","预测","这些","_","模型","紧密","很多","称为","部分","呢","啦","到","和","存储","x3","本地","骨骼","格式","充足","模块","输入","管理","供","要","分类","消耗","更","直接","基于","不","引擎","并","相连","层面","或者","端","为","两大块","分割","lib","开发板","还","文件","运行","大块","分成","需要","source","实际","bash","好","内存","保障"],"title":"模型推理框架","title_tokens":["模型","推理","框架"]},{"location":"hhp/5.3_%E6%A8%A1%E5%9E%8B%E6%8E%A8%E7%90%86%E6%A1%86%E6%9E%B6/#_1","text":"智能机器人与机器学习是紧密相连的，机器学习又可以分成数据采集、标注、训练、推理等环节，其中数据的训练需要消耗大量算力，适合在服务器或者云端进行，不过训练好的模型可是要部署到机器人端进行推理运算的，所以模型推理的效率如何，直接决定了机器人视觉处理的效率，这刚好是TogetherROS所擅长的地方。","text_tokens":["效率","togetherros","所以","所","服务","擅长","等","云端","大量","地方","环节","数据","又","务器","刚好","在","算力","推理","不过","模型","紧密","其中","视觉","这","可是","部署","、","进行","与","采集","到","机器人","，","机器","可以","的","如何","决定","要","处理","。","消耗","训练","标注","直接","相连","运算","或者","端","是","智能","了","分成","需要","适合","好","学习","服务器"],"title":"模型推理框架","title_tokens":["模型","推理","框架"]},{"location":"hhp/5.3_%E6%A8%A1%E5%9E%8B%E6%8E%A8%E7%90%86%E6%A1%86%E6%9E%B6/#hobot-dnn","text":"TogetherROS系统集成了Hobot DNN模型推理库，集成了众多开源模型，借助底层芯片中的AI引擎BPU，提供充足的算力保障，开发者实际使用中，就不用花费很多时间在模型的调教和数据的训练上，基于这套系统，很快就可以部署人工智能应用啦。 hobot_dnn是在地平线X3开发板上利用BPU处理器实现AI推理功能，基于地平线EasyDNN和ROS2 Node进行二次开发，为应用开发提供更简单易用的模型集成开发接口，包括模型管理、基于模型描述的输入处理及结果解析，以及模型输出内存分配管理等功能。 关于hobot_dnn的使用逻辑流程如这张图所示，供大家参考，我们后续也会通过具体的案例解释代码的实现过程。","text_tokens":["逻辑","易用","这套","算力","后续","就","地平线","进行","以及","，","花费","解析","库","easydnn","众多"," ","及","分配","了","代码","不用","具体","提供","通过","流程","ai","利用","开源","输出","关于","案例","会","包括","人工智能","这","bpu","部署","地平","功能","张图","。","训练","描述","开发","使用","dnn","处理器","所示","芯片","node","中","togetherros","简单","接口","系统","时间","也","推理","很快","解释","、","二次开发","借助","可以","我们","的","如","参考","底层","处理","理器","开发者","结果","集成","智能","是","上","ros2","二次","应用","hobot","系统集成","实现","过程","调教","人工","大家","等","数据","在","_","模型","很多","啦","和","x3","充足","输入","管理","供","更","基于","引擎","为","开发板","实际","内存","保障"],"title":"Hobot DNN模型推理库","title_tokens":["模型","dnn","库"," ","hobot","推理"]},{"location":"hhp/5.3_%E6%A8%A1%E5%9E%8B%E6%8E%A8%E7%90%86%E6%A1%86%E6%9E%B6/#_2","text":"在Hobot DNN模型推理库的基础上，地平线还提供了一套基于TogetherROS系统的AI算法包，称为BOXs，这样我们就不需要从零构建算法，基于这些标准而高效的算法，可以更关注应用层面的APP开发。 从这张图中我们可以看到，这套AI算法包中包含两大块，一个是基础算法，一个是应用算法。 基础算法中主要是图像分类、语义分割和目标检测这些常用的算法，应用层面就会基于这些算法和某些场景，动态实现更为复杂的人体识别、骨骼点识别、手势识别等具体的功能，这些模块就可以和机器人运功功能直接结合，节省了我们开发AI视觉部分的时间。","text_tokens":["手势","基础","app","包含","关注","包中","这套","构建","就","看到","地平线","图像","场景","从","复杂","，","机器","结合","库","动态","识别","语义"," ","主要","了","具体","提供","这样","ai","标准","目标","更为","会","这","视觉","一个","地平","功能","机器人","某些","张图","。","高效","开发","点","dnn","人体","中","togetherros","包","系统","时间","一套","推理","、","可以","运功","我们","的","是","零","而","检测","节省","上","算法","应用","hobot","实现","等","boxs","在","这些","称为","模型","部分","和","骨骼","模块","分类","更","基于","直接","不","层面","两大块","分割","还","大块","需要","常用"],"title":"算法与应用库","title_tokens":["应用","与","库","算法"]},{"location":"hhp/5.3_%E6%A8%A1%E5%9E%8B%E6%8E%A8%E7%90%86%E6%A1%86%E6%9E%B6/#_3","text":"这套模型推理和算法库的效果如何呢？ 我们先来体验一个TogetherROS系统自带的案例，识别这张图片中的人，以及每个人的骨骼关键点。 # 配置TogetherROS环境 $ source /opt/tros/setup.bash # 从tros的安装路径中拷贝出运行示例需要的配置文件。config中为example使用的模型，回灌使用的本地图片 $ cp -r /opt/tros/lib/dnn_node_example/config/ . # 使用本地jpg格式图片通过同步模式进行回环预测，并存储渲染后的图片 $ ros2 launch dnn_node_example hobot_dnn_node_example_feedback.launch.py","text_tokens":["cp","回灌","这套","feedback","进行","从","以及","，","如何","？","库","识别","出"," ","拷贝","效果","-","渲染","环境","同步","tros","通过",".","示例","安装","先","案例","关键","配置文件","关键点","一个","来","配置","。","图片","launch","后","使用","dnn","中为","py","node","中","opt","togetherros","模式","系统","#","推理","jpg","回环","config","这张","人","我们","的","r","体验","路径","自带","setup","ros2","算法","example","hobot","$","每个","/","预测","呢","_","模型","存储","和","本地","骨骼","格式","并","lib","文件","运行","bash","需要","source"],"title":"模型推理测试","title_tokens":["模型","测试","推理"]},{"location":"hhp/5.4_%E5%9B%BE%E5%83%8F%E7%89%A9%E4%BD%93%E5%88%86%E7%B1%BB/","text":"图像物体分类 接下来我们继续学习基于Hobot CNN模型推理库之上的视觉应用。 机器人要感知周边环境，那就得确定看到的图像中都有什么，比如地上有一只猫，旁边有一个桌子之类的，这个猫和桌子就是具体的物体分类啦。 图像分类原理 如果是人来识别一只猫的话，似乎再简单不过了，无论黑猫、白猫还是花猫，我们一眼就可以看出来。 不过这件事对于机器人来讲可没有那么简单，为了能够让机器准确识别一只猫，无数学者可是研究了几十年啊，虽然还赶不上人类的智慧，但是这件事已经没有那么遥不可及了。 比如说我们要让机器识别图像中有一只猫，我们就得先教会机器什么是猫，对此我们就得把各种各样猫的照片给计算机看，目的就是让机器学习，看的越多，识别的也就越准。 我们那里找这么多猫的图片呢？ 大家可能听说过一个著名的视觉对象数据库——ImageNet，里边有超过1400万张标注过的图像，2万多个类别，我们就可以利用这个庞大的数据库，找到很多猫的照片。 然后就搭建神经网络，把这些数据放进去训练了，调教出一套比较好的识别模型。 接下来把这套模型部署到机器人上，之后每当有一幅图像收到之后，就传到这个模型中，也就是模型推理，推理的结果就是类似这样的数据，概率最大的，也就是机器识别到的物体啦。 关于机器学习，理论众多，大家可以学习专门的课程，我们课上还是重点讲解在TogetherROS中的实现方法。 编程开发方法 我们来看这样一张图片，大家很快就可以发现这是一只斑马。 运行示例程序 我们如何用机器来识别它呢，大家先来运行这个案例，这是基于ImageNet数据集训练的模型，可以识别1000种常见的物体，我们看一下效果如何？ $ cd /app/ai_inference/01_basic_sample/ $ sudo python3 ./test_mobilenetv1.py 代码解析 test_mobilenetv1.py： #!/usr/bin/env python3 from hobot_dnn import pyeasy_dnn as dnn import numpy as np import cv2 def bgr2nv12_opencv ( image ): height , width = image . shape [ 0 ], image . shape [ 1 ] area = height * width yuv420p = cv2 . cvtColor ( image , cv2 . COLOR_BGR2YUV_I420 ) . reshape (( area * 3 // 2 ,)) y = yuv420p [: area ] uv_planar = yuv420p [ area :] . reshape (( 2 , area // 4 )) uv_packed = uv_planar . transpose (( 1 , 0 )) . reshape (( area // 2 ,)) nv12 = np . zeros_like ( yuv420p ) nv12 [: height * width ] = y nv12 [ height * width :] = uv_packed return nv12 def print_properties ( pro ): print ( \"tensor type:\" , pro . tensor_type ) print ( \"data type:\" , pro . dtype ) print ( \"layout:\" , pro . layout ) print ( \"shape:\" , pro . shape ) def get_hw ( pro ): if pro . layout == \"NCHW\" : return pro . shape [ 2 ], pro . shape [ 3 ] else : return pro . shape [ 1 ], pro . shape [ 2 ] if __name__ == '__main__' : # test classification result models = dnn . load ( '../models/mobilenetv1_224x224_nv12.bin' ) # test input and output properties print ( \"=\" * 10 , \"inputs[0] properties\" , \"=\" * 10 ) print_properties ( models [ 0 ] . inputs [ 0 ] . properties ) print ( \"inputs[0] name is:\" , models [ 0 ] . inputs [ 0 ] . name ) print ( \"=\" * 10 , \"outputs[0] properties\" , \"=\" * 10 ) print_properties ( models [ 0 ] . outputs [ 0 ] . properties ) print ( \"outputs[0] name is:\" , models [ 0 ] . outputs [ 0 ] . name ) # 打开图片 img_file = cv2 . imread ( './zebra_cls.jpg' ) # 把图片缩放到模型的输入尺寸 # 获取算法模型的输入tensor 的尺寸 h , w = get_hw ( models [ 0 ] . inputs [ 0 ] . properties ) des_dim = ( w , h ) resized_data = cv2 . resize ( img_file , des_dim , interpolation = cv2 . INTER_AREA ) nv12_data = bgr2nv12_opencv ( resized_data ) # 模型推理 outputs = models [ 0 ] . forward ( nv12_data ) print ( \"=\" * 10 , \"Get output[0] numpy data\" , \"=\" * 10 ) print ( \"output[0] buffer numpy info: \" ) print ( \"shape: \" , outputs [ 0 ] . buffer . shape ) print ( \"dtype: \" , outputs [ 0 ] . buffer . dtype ) # print(\"First 10 results:\", outputs[0].buffer[0][:10]) # 从输出结果中得到值最大的那个序号，比如 zebra 就是第 340 个值，应该大于 0.99 print ( \"=\" * 10 , \"Classification result\" , \"=\" * 10 ) assert np . argmax ( outputs [ 0 ] . buffer ) == 340 # 输出类别序号和预测概率值 print ( \"cls id: %d Confidence: %f \" % ( np . argmax ( outputs [ 0 ] . buffer ), outputs [ 0 ] . buffer [ 0 ][ np . argmax ( outputs [ 0 ] . buffer )])) Mobilenetv2物体分类 用图片进行识别不太过瘾，毕竟是静态的图像，没问题，TogetherROS中还提供了实时物体分类的案例，我们继续来体验一下。 为了实时显示视觉识别的效果，这里我们需要启动TogetherROS中的一个web服务器，它会把视觉识别的实时效果，通过网络传输出来，我们直接在浏览器中就可以看到结果啦。也是便于我们开发调试的一个重要工具。 # 启动webserver服务 $ cd /opt/tros/lib/websocket/webservice/ $ chmod +x ./sbin/nginx && ./sbin/nginx -p . 运行例程： $ source /opt/tros/setup.bash $ cp -r /opt/tros/lib/dnn_node_example/config/ . $ cp -r /opt/tros/lib/dnn_benchmark_example/config/runtime/ ./config/ $ ros2 launch /opt/tros/share/dnn_node_example/launch/hobot_dnn_node_example.launch.py config_file: = config/mobilenetv2workconfig.json image_width: = 480 image_height: = 272 在浏览器中登录192.168.1.10，就可以看到分类效果啦：","text_tokens":["confidence","周边环境","概率","这套","获取","area","越准","cvtcolor","就","web","like","cnn","，","？","cv2","库","识别","bgr2nv12","众多","放进","重要","01","tensor","nv12","每当","通过","各种","ai","d","benchmark","课上","h","找到","神经","问题","进去","案例","输出","这是","教会","啊","赶不上","一个","部署","usr","第","：","之上","yuv420p","学者","来","研究","课程","应该","[","几十","1.10","一张","没有","中","websocket","几十年","感知","什么","models","放进去","w","也","推理","越","传到","jpg","智慧","可以","把","image","r","黑猫","layout","计算","讲解","地上","and","应用","example","找","那么","$","+","实时","务器","它会","不太","呢","模型","很多","zeros","height","万多个","事","mobilenetv1","]","物体","基于","reshape","'","__","color","import","如果","接下","继续","cd","mobilenetv2","得到","source","得","能够","=","静态","np","工具","听说","(","如何","is","340","uv","2","了","as","万多","代码","1400","来看","dtype","万张","这样",".","给","那","比如","\"","&&","sample","利用","224x224","都","照片","interpolation","width","1","。","训练","图片","再","毕竟","dnn","py","学习","opt","y","方法","share","发现","一套","info","config","test","des","env","但是","体验","results","numpy","启动","结果","opencv","webserver","可","zebra","开发方法","神经网络","接下来","出来","算法","hobot","实现","buffer","/","input","下来","预测","_","打开","用","啦","到","和","已经","要","%","分类","basic","imread","runtime","网络","3","著名","def","还","i420","argmax","10","p","一眼","app","服务","!",":","它","没","不过","看到","进行","为了","从","file","这件","if","192.168","0","bin","name","标注","出","编程","cls","值","效果","具体","..","nginx","对象","环境","多个","程序","resize","庞大",")","272","常见","视觉","return","机器人","就是","浏览","原理","人类","花猫","搭建","虽然","让","inputs","开发","f","确定","result","一幅","pro","*","chmod","超过","node","服务器","togetherros","简单","一只","猫","#","get","可是","不可","过瘾","这么","是","上","setup","无论","专门","调教","data","大家","旁边","似乎","来讲","放到","里边","对此","数据","—","那里","遥不可及","过","准确","理论","输入","properties","bgr2yuv","output","斑马","运行","bash","桌子","种","from","0.99","好","周边","白猫","个值","尺寸","inference","对于","cp","img","图像","sbin","缩","数据库","机器","else","id","x","sudo","解析","就可以看","imagenet","浏览器","计算机","重点"," ","type","这个","十年","mobilenetv2workconfig","-","提供","tros","示例","inter","先","之后","调试","目的","resized","关于","各种各样","人来","多猫","多","各样","planar","中有","forward","类似","classification","看","launch","pyeasy","比如说","print","便于","480","outputs","很快","序号","例程","json","main","、","类别","可能","assert","比较","传输","我们","的","transpose","之类","收到","还是","nchw","ros2","据库","一下","shape","无数","这里","在","load","这些","的话","显示","python3","dim","1000","然后","那个","first","webservice",",","直接","大于","packed","lib","有","最大","集","hw","需要","登录","4","算机","神经网"],"title":"图像物体分类","title_tokens":["分类","图像","物体"]},{"location":"hhp/5.4_%E5%9B%BE%E5%83%8F%E7%89%A9%E4%BD%93%E5%88%86%E7%B1%BB/#_1","text":"接下来我们继续学习基于Hobot CNN模型推理库之上的视觉应用。 机器人要感知周边环境，那就得确定看到的图像中都有什么，比如地上有一只猫，旁边有一个桌子之类的，这个猫和桌子就是具体的物体分类啦。","text_tokens":["那","比如","周边环境","一只","得","旁边","感知","什么","猫","下来","推理","模型","视觉","就","看到","图像","一个","都","啦","和","机器人","cnn","之上","机器","，","我们","就是","的","中","要","。","分类","库","物体","基于"," ","之类","这个","接下","确定","具体","继续","有","接下来","环境","地上","桌子","应用","周边","hobot","学习"],"title":"图像物体分类","title_tokens":["分类","图像","物体"]},{"location":"hhp/5.4_%E5%9B%BE%E5%83%8F%E7%89%A9%E4%BD%93%E5%88%86%E7%B1%BB/#_2","text":"如果是人来识别一只猫的话，似乎再简单不过了，无论黑猫、白猫还是花猫，我们一眼就可以看出来。 不过这件事对于机器人来讲可没有那么简单，为了能够让机器准确识别一只猫，无数学者可是研究了几十年啊，虽然还赶不上人类的智慧，但是这件事已经没有那么遥不可及了。 比如说我们要让机器识别图像中有一只猫，我们就得先教会机器什么是猫，对此我们就得把各种各样猫的照片给计算机看，目的就是让机器学习，看的越多，识别的也就越准。 我们那里找这么多猫的图片呢？ 大家可能听说过一个著名的视觉对象数据库——ImageNet，里边有超过1400万张标注过的图像，2万多个类别，我们就可以利用这个庞大的数据库，找到很多猫的照片。 然后就搭建神经网络，把这些数据放进去训练了，调教出一套比较好的识别模型。 接下来把这套模型部署到机器人上，之后每当有一幅图像收到之后，就传到这个模型中，也就是模型推理，推理的结果就是类似这样的数据，概率最大的，也就是机器识别到的物体啦。 关于机器学习，理论众多，大家可以学习专门的课程，我们课上还是重点讲解在TogetherROS中的实现方法。","text_tokens":["得","能够","概率","对于","这套","越准","不过","图像","就","为了","听说","数据库","，","机器","这件","就可以看","？","imagenet","标注","识别","计算机","众多","2","放进","出","重点"," ","这个","了","十年","万多","1400","对象","每当","万张","这样","给","比如","各种","先","利用","课上","找到","多个","之后","神经","目的","进去","好","关于","庞大","各种各样","人来","多猫","教会","视觉","啊","赶不上","一个","部署","多","照片","各样","机器人","就是","学者","中有","研究","课程","类似","人类","花猫","。","训练","搭建","虽然","让","看","图片","再","一幅","几十","比如说","神经网","超过","没有","学习","中","togetherros","简单","一只","几十年","什么","方法","猫","放进去","一套","也","推理","越","传到","可是","、","智慧","类别","不可","可能","可以","把","比较","我们","的","但是","这么","黑猫","结果","收到","可","是","神经网络","计算","上","还是","接下来","讲解","出来","无论","找","那么","据库","专门","实现","调教","大家","似乎","来讲","无数","里边","对此","数据","—","下来","在","那里","呢","这些","的话","很多","模型","啦","到","遥不可及","已经","过","万多个","准确","然后","理论","事","要","物体","网络","著名","如果","接下","有","最大","还","一眼","算机","白猫"],"title":"图像分类原理","title_tokens":["分类","图像","原理"]},{"location":"hhp/5.4_%E5%9B%BE%E5%83%8F%E7%89%A9%E4%BD%93%E5%88%86%E7%B1%BB/#_3","text":"我们来看这样一张图片，大家很快就可以发现这是一只斑马。","text_tokens":["。","就","大家","一只","图片","来看","很快","，","可以","发现","我们","这是","一张","斑马","这样"],"title":"编程开发方法","title_tokens":["开发方法","编程","开发","方法"]},{"location":"hhp/5.4_%E5%9B%BE%E5%83%8F%E7%89%A9%E4%BD%93%E5%88%86%E7%B1%BB/#_4","text":"我们如何用机器来识别它呢，大家先来运行这个案例，这是基于ImageNet数据集训练的模型，可以识别1000种常见的物体，我们看一下效果如何？ $ cd /app/ai_inference/01_basic_sample/ $ sudo python3 ./test_mobilenetv1.py","text_tokens":["app","大家","ai","先","sample","$","inference","它","案例","数据","/","这是","呢","_","模型","常见","test","python3","用","，","机器","可以","1000","我们","来","的","sudo","如何","？","imagenet","mobilenetv1","物体","训练","basic","基于","识别","看"," ","这个","效果","01","cd","集","py","运行","种","一下","."],"title":"运行示例程序","title_tokens":["运行","示例","程序"]},{"location":"hhp/5.4_%E5%9B%BE%E5%83%8F%E7%89%A9%E4%BD%93%E5%88%86%E7%B1%BB/#_5","text":"test_mobilenetv1.py： #!/usr/bin/env python3 from hobot_dnn import pyeasy_dnn as dnn import numpy as np import cv2 def bgr2nv12_opencv ( image ): height , width = image . shape [ 0 ], image . shape [ 1 ] area = height * width yuv420p = cv2 . cvtColor ( image , cv2 . COLOR_BGR2YUV_I420 ) . reshape (( area * 3 // 2 ,)) y = yuv420p [: area ] uv_planar = yuv420p [ area :] . reshape (( 2 , area // 4 )) uv_packed = uv_planar . transpose (( 1 , 0 )) . reshape (( area // 2 ,)) nv12 = np . zeros_like ( yuv420p ) nv12 [: height * width ] = y nv12 [ height * width :] = uv_packed return nv12 def print_properties ( pro ): print ( \"tensor type:\" , pro . tensor_type ) print ( \"data type:\" , pro . dtype ) print ( \"layout:\" , pro . layout ) print ( \"shape:\" , pro . shape ) def get_hw ( pro ): if pro . layout == \"NCHW\" : return pro . shape [ 2 ], pro . shape [ 3 ] else : return pro . shape [ 1 ], pro . shape [ 2 ] if __name__ == '__main__' : # test classification result models = dnn . load ( '../models/mobilenetv1_224x224_nv12.bin' ) # test input and output properties print ( \"=\" * 10 , \"inputs[0] properties\" , \"=\" * 10 ) print_properties ( models [ 0 ] . inputs [ 0 ] . properties ) print ( \"inputs[0] name is:\" , models [ 0 ] . inputs [ 0 ] . name ) print ( \"=\" * 10 , \"outputs[0] properties\" , \"=\" * 10 ) print_properties ( models [ 0 ] . outputs [ 0 ] . properties ) print ( \"outputs[0] name is:\" , models [ 0 ] . outputs [ 0 ] . name ) # 打开图片 img_file = cv2 . imread ( './zebra_cls.jpg' ) # 把图片缩放到模型的输入尺寸 # 获取算法模型的输入tensor 的尺寸 h , w = get_hw ( models [ 0 ] . inputs [ 0 ] . properties ) des_dim = ( w , h ) resized_data = cv2 . resize ( img_file , des_dim , interpolation = cv2 . INTER_AREA ) nv12_data = bgr2nv12_opencv ( resized_data ) # 模型推理 outputs = models [ 0 ] . forward ( nv12_data ) print ( \"=\" * 10 , \"Get output[0] numpy data\" , \"=\" * 10 ) print ( \"output[0] buffer numpy info: \" ) print ( \"shape: \" , outputs [ 0 ] . buffer . shape ) print ( \"dtype: \" , outputs [ 0 ] . buffer . dtype ) # print(\"First 10 results:\", outputs[0].buffer[0][:10]) # 从输出结果中得到值最大的那个序号，比如 zebra 就是第 340 个值，应该大于 0.99 print ( \"=\" * 10 , \"Classification result\" , \"=\" * 10 ) assert np . argmax ( outputs [ 0 ] . buffer ) == 340 # 输出类别序号和预测概率值 print ( \"cls id: %d Confidence: %f \" % ( np . argmax ( outputs [ 0 ] . buffer ), outputs [ 0 ] . buffer [ 0 ][ np . argmax ( outputs [ 0 ] . buffer )]))","text_tokens":["个值","confidence","尺寸","!",":","=","概率","获取","area","np","cvtcolor","img","缩","like","从","，","else","id","(","file","if","cv2","is","0","bin","340","name","bgr2nv12","uv","2"," ","type","cls","值","as","tensor","..","nv12","dtype","\"",".","比如","inter","d","h","resize","resized","输出",")","224x224","usr","interpolation","第","：","return","width","1","yuv420p","planar","就是","forward","classification","图片","inputs","应该","[","f","dnn","result","pro","pyeasy","py","*","print","中","y","models","w","#","get","outputs","推理","jpg","info","序号","test","main","类别","assert","把","image","des","env","的","transpose","numpy","results","layout","结果","opencv","zebra","nchw","算法","and","hobot","buffer","shape","data","放到","/","input","预测","load","_","模型","zeros","打开","python3","height","dim","和","输入","那个","first","%","mobilenetv1","]","properties",",","bgr2yuv","reshape","output","imread","3","大于","'","__","packed","color","import","def","最大","i420","hw","argmax","10","from","得到","0.99","4"],"title":"代码解析","title_tokens":["解析","代码"]},{"location":"hhp/5.4_%E5%9B%BE%E5%83%8F%E7%89%A9%E4%BD%93%E5%88%86%E7%B1%BB/#mobilenetv2","text":"用图片进行识别不太过瘾，毕竟是静态的图像，没问题，TogetherROS中还提供了实时物体分类的案例，我们继续来体验一下。 为了实时显示视觉识别的效果，这里我们需要启动TogetherROS中的一个web服务器，它会把视觉识别的实时效果，通过网络传输出来，我们直接在浏览器中就可以看到结果啦。也是便于我们开发调试的一个重要工具。 # 启动webserver服务 $ cd /opt/tros/lib/websocket/webservice/ $ chmod +x ./sbin/nginx && ./sbin/nginx -p . 运行例程： $ source /opt/tros/setup.bash $ cp -r /opt/tros/lib/dnn_node_example/config/ . $ cp -r /opt/tros/lib/dnn_benchmark_example/config/runtime/ ./config/ $ ros2 launch /opt/tros/share/dnn_node_example/launch/hobot_dnn_node_example.launch.py config_file: = config/mobilenetv2workconfig.json image_width: = 480 image_height: = 272 在浏览器中登录192.168.1.10，就可以看到分类效果啦：","text_tokens":["服务",":","=","cp","静态","没","图像","web","就","看到","工具","进行","sbin","为了","，","x","file","192.168","浏览器","识别","重要"," ","了","效果","mobilenetv2workconfig","-","nginx","tros","提供","通过",".","&&","benchmark","调试","问题","案例","272","视觉","一个","：","width","来","浏览","。","图片","launch","开发","毕竟","dnn","py","1.10","chmod","node","中","服务器","opt","togetherros","便于","websocket","share","480","#","也","config","例程","json","把","过瘾","传输","我们","可以","image","的","r","体验","启动","结果","webserver","是","setup","出来","ros2","example","hobot","一下","$","+","实时","这里","/","务器","它会","不太","在","_","显示","用","height","啦","webservice","分类","物体","直接","runtime","网络","lib","继续","cd","还","运行","bash","需要","source","登录","p"],"title":"Mobilenetv2物体分类","title_tokens":["mobilenetv2","分类","物体"]},{"location":"hhp/5.5_%E5%8A%A8%E6%80%81%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/","text":"动态目标检测 图像物体分类重在分析图像中存在的物体是什么，便于机器理解看到的环境信息，另外一种场景，机器不仅要识别某一物体，还要知道这个物体所在的位置，当物体在运动时，更要快速连续的跟踪，这就是目标检测，重在分析识别到物体在图像中的位置。 目标检测原理 假设我们要识别图像中这只狗的位置，以最为常用的YOLO算法为例，它会运用单个卷积神经网络(CNN) ，将图像分成网格，并预测每个网格的对象概率和边界框。 比如，对于这个图像，Yolo的CNN网络将输入的图片分割成7x7的网格，然后每个网格负责去检测那些中心点落在该格子内的目标，比如，小狗这个目标的中心点在左下角的网格中，那该网格就负责预测狗这个对象。 每个网格中将有多个边界框，在训练时，我们希望每个对象只有一个边界框，比如最终只有一个边界框把这只狗包起来。因此，我们根据哪个边界框与之前标注的重叠度最高，预测对象的位置和概率。 最终包围对象的边界框，就是识别的结果，使用四个描述符进行说明： 边界框的中心位置 边界框的高度 边界框的宽度 识别到对象所属的类 这样就完成了对目标的实时检测，拿到目标的信息之后，就可以进行后续的机器人行为控制了。 我们对目标检测系统运行速度的要求一般都比较高，可以实时处理视频流，比如车辆行驶的动态监测、自然环境中的目标识别，有着非常广泛的应用价值。 回到TogetherROS和旭日X3派的开发板，我们来看下这套软硬件结合的目标检测系统，效率如何。 MIPI相机目标检测 接下来，我们要利用MIPI相机，动态识别图像中各种各样的物体以及他们所在的位置，推理过程使用的是基于COCO数据集训练的80个类别，也就是可以识别80种常用的物体位置。 运行例程 $ cd /app/ai_inference/03_mipi_camera_sample/ $ python3 ./mipi_camera.py 代码解析 mipi_camera.py： #!/usr/bin/env python3 import numpy as np import cv2 import colorsys # Camera API libs from hobot_vio import libsrcampy as srcampy from hobot_dnn import pyeasy_dnn as dnn # detection model class names def get_classes (): return np . array ([ \"person\" , \"bicycle\" , \"car\" , \"motorcycle\" , \"airplane\" , \"bus\" , \"train\" , \"truck\" , \"boat\" , \"traffic light\" , \"fire hydrant\" , \"stop sign\" , \"parking meter\" , \"bench\" , \"bird\" , \"cat\" , \"dog\" , \"horse\" , \"sheep\" , \"cow\" , \"elephant\" , \"bear\" , \"zebra\" , \"giraffe\" , \"backpack\" , \"umbrella\" , \"handbag\" , \"tie\" , \"suitcase\" , \"frisbee\" , \"skis\" , \"snowboard\" , \"sports ball\" , \"kite\" , \"baseball bat\" , \"baseball glove\" , \"skateboard\" , \"surfboard\" , \"tennis racket\" , \"bottle\" , \"wine glass\" , \"cup\" , \"fork\" , \"knife\" , \"spoon\" , \"bowl\" , \"banana\" , \"apple\" , \"sandwich\" , \"orange\" , \"broccoli\" , \"carrot\" , \"hot dog\" , \"pizza\" , \"donut\" , \"cake\" , \"chair\" , \"couch\" , \"potted plant\" , \"bed\" , \"dining table\" , \"toilet\" , \"tv\" , \"laptop\" , \"mouse\" , \"remote\" , \"keyboard\" , \"cell phone\" , \"microwave\" , \"oven\" , \"toaster\" , \"sink\" , \"refrigerator\" , \"book\" , \"clock\" , \"vase\" , \"scissors\" , \"teddy bear\" , \"hair drier\" , \"toothbrush\" ]) def bgr2nv12_opencv ( image ): height , width = image . shape [ 0 ], image . shape [ 1 ] area = height * width yuv420p = cv2 . cvtColor ( image , cv2 . COLOR_RGB2YUV_I420 ) . reshape (( area * 3 // 2 ,)) y = yuv420p [: area ] uv_planar = yuv420p [ area :] . reshape (( 2 , area // 4 )) uv_packed = uv_planar . transpose (( 1 , 0 )) . reshape (( area // 2 ,)) nv12 = np . zeros_like ( yuv420p ) nv12 [: height * width ] = y nv12 [ height * width :] = uv_packed return nv12 def get_hw ( pro ): if pro . layout == \"NCHW\" : return pro . shape [ 2 ], pro . shape [ 3 ] else : return pro . shape [ 1 ], pro . shape [ 2 ] def postprocess ( model_output , model_hw_shape , origin_image = None , origin_img_shape = None , score_threshold = 0.5 , nms_threshold = 0.6 , dump_image = False ): input_height = model_hw_shape [ 0 ] input_width = model_hw_shape [ 1 ] if origin_image is not None : origin_image_shape = origin_image . shape [ 0 : 2 ] else : origin_image_shape = origin_img_shape prediction_bbox = decode ( outputs = model_output , score_threshold = score_threshold , origin_shape = origin_image_shape , input_size = 512 ) prediction_bbox = nms ( prediction_bbox , iou_threshold = nms_threshold ) prediction_bbox = np . array ( prediction_bbox ) topk = min ( prediction_bbox . shape [ 0 ], 1000 ) if topk != 0 : idx = np . argpartition ( prediction_bbox [ ... , 4 ], - topk )[ - topk :] prediction_bbox = prediction_bbox [ idx ] if dump_image and origin_image is not None : draw_bboxs ( origin_image , prediction_bbox ) return prediction_bbox def draw_bboxs ( image , bboxes , gt_classes_index = None , classes = get_classes ()): \"\"\"draw the bboxes in the original image \"\"\" num_classes = len ( classes ) image_h , image_w , channel = image . shape hsv_tuples = [( 1.0 * x / num_classes , 1. , 1. ) for x in range ( num_classes )] colors = list ( map ( lambda x : colorsys . hsv_to_rgb ( * x ), hsv_tuples )) colors = list ( map ( lambda x : ( int ( x [ 0 ] * 255 ), int ( x [ 1 ] * 255 ), int ( x [ 2 ] * 255 )), colors )) fontScale = 0.5 bbox_thick = int ( 0.6 * ( image_h + image_w ) / 600 ) for i , bbox in enumerate ( bboxes ): coor = np . array ( bbox [: 4 ], dtype = np . int32 ) if gt_classes_index == None : class_index = int ( bbox [ 5 ]) score = bbox [ 4 ] else : class_index = gt_classes_index [ i ] score = 1 bbox_color = colors [ class_index ] c1 , c2 = ( coor [ 0 ], coor [ 1 ]), ( coor [ 2 ], coor [ 3 ]) cv2 . rectangle ( image , c1 , c2 , bbox_color , bbox_thick ) classes_name = classes [ class_index ] bbox_mess = ' %s : %.2f ' % ( classes_name , score ) t_size = cv2 . getTextSize ( bbox_mess , 0 , fontScale , thickness = bbox_thick // 2 )[ 0 ] cv2 . rectangle ( image , c1 , ( c1 [ 0 ] + t_size [ 0 ], c1 [ 1 ] - t_size [ 1 ] - 3 ), bbox_color , - 1 ) cv2 . putText ( image , bbox_mess , ( c1 [ 0 ], c1 [ 1 ] - 2 ), cv2 . FONT_HERSHEY_SIMPLEX , fontScale , ( 0 , 0 , 0 ), bbox_thick // 2 , lineType = cv2 . LINE_AA ) print ( \" {} is in the picture with confidence: {:.4f} , bbox: {} \" . format ( classes_name , score , coor )) # cv2.imwrite(\"demo.jpg\", image) return image def decode ( outputs , score_threshold , origin_shape , input_size = 512 ): def _distance2bbox ( points , distance ): x1 = points [ ... , 0 ] - distance [ ... , 0 ] y1 = points [ ... , 1 ] - distance [ ... , 1 ] x2 = points [ ... , 0 ] + distance [ ... , 2 ] y2 = points [ ... , 1 ] + distance [ ... , 3 ] return np . stack ([ x1 , y1 , x2 , y2 ], - 1 ) def _scores ( cls , ce ): cls = 1 / ( 1 + np . exp ( - cls )) ce = 1 / ( 1 + np . exp ( - ce )) return np . sqrt ( ce * cls ) def _bbox ( bbox , stride , origin_shape , input_size ): h , w = bbox . shape [ 1 : 3 ] yv , xv = np . meshgrid ( np . arange ( h ), np . arange ( w )) xy = ( np . stack (( yv , xv ), 2 ) + 0.5 ) * stride bbox = _distance2bbox ( xy , bbox ) # opencv read, shape[1] is w, shape[0] is h scale_w = origin_shape [ 1 ] / input_size scale_h = origin_shape [ 0 ] / input_size scale = max ( origin_shape [ 0 ], origin_shape [ 1 ]) / input_size # origin img is pad resized #bbox = bbox * scale # origin img is resized bbox = bbox * [ scale_w , scale_h , scale_w , scale_h ] return bbox bboxes = list () strides = [ 8 , 16 , 32 , 64 , 128 ] for i in range ( len ( strides )): cls = outputs [ i ] . buffer bbox = outputs [ i + 5 ] . buffer ce = outputs [ i + 10 ] . buffer scores = _scores ( cls , ce ) classes = np . argmax ( scores , axis =- 1 ) classes = np . reshape ( classes , [ - 1 , 1 ]) max_score = np . max ( scores , axis =- 1 ) max_score = np . reshape ( max_score , [ - 1 , 1 ]) bbox = _bbox ( bbox , strides [ i ], origin_shape , input_size ) bbox = np . reshape ( bbox , [ - 1 , 4 ]) pred_bbox = np . concatenate ([ bbox , max_score , classes ], axis = 1 ) index = pred_bbox [ ... , 4 ] > score_threshold pred_bbox = pred_bbox [ index ] bboxes . append ( pred_bbox ) return np . concatenate ( bboxes ) def nms ( bboxes , iou_threshold , sigma = 0.3 , method = 'nms' ): def bboxes_iou ( boxes1 , boxes2 ): boxes1 = np . array ( boxes1 ) boxes2 = np . array ( boxes2 ) boxes1_area = ( boxes1 [ ... , 2 ] - boxes1 [ ... , 0 ]) * \\ ( boxes1 [ ... , 3 ] - boxes1 [ ... , 1 ]) boxes2_area = ( boxes2 [ ... , 2 ] - boxes2 [ ... , 0 ]) * \\ ( boxes2 [ ... , 3 ] - boxes2 [ ... , 1 ]) left_up = np . maximum ( boxes1 [ ... , : 2 ], boxes2 [ ... , : 2 ]) right_down = np . minimum ( boxes1 [ ... , 2 :], boxes2 [ ... , 2 :]) inter_section = np . maximum ( right_down - left_up , 0.0 ) inter_area = inter_section [ ... , 0 ] * inter_section [ ... , 1 ] union_area = boxes1_area + boxes2_area - inter_area ious = np . maximum ( 1.0 * inter_area / union_area , np . finfo ( np . float32 ) . eps ) return ious classes_in_img = list ( set ( bboxes [:, 5 ])) best_bboxes = [] for cls in classes_in_img : cls_mask = ( bboxes [:, 5 ] == cls ) cls_bboxes = bboxes [ cls_mask ] while len ( cls_bboxes ) > 0 : max_ind = np . argmax ( cls_bboxes [:, 4 ]) best_bbox = cls_bboxes [ max_ind ] best_bboxes . append ( best_bbox ) cls_bboxes = np . concatenate ( [ cls_bboxes [: max_ind ], cls_bboxes [ max_ind + 1 :]]) iou = bboxes_iou ( best_bbox [ np . newaxis , : 4 ], cls_bboxes [:, : 4 ]) weight = np . ones (( len ( iou ),), dtype = np . float32 ) assert method in [ 'nms' , 'soft-nms' ] if method == 'nms' : iou_mask = iou > iou_threshold weight [ iou_mask ] = 0.0 if method == 'soft-nms' : weight = np . exp ( - ( 1.0 * iou ** 2 / sigma )) cls_bboxes [:, 4 ] = cls_bboxes [:, 4 ] * weight score_mask = cls_bboxes [:, 4 ] > 0. cls_bboxes = cls_bboxes [ score_mask ] return best_bboxes def print_properties ( pro ): print ( \"tensor type:\" , pro . tensor_type ) print ( \"data type:\" , pro . dtype ) print ( \"layout:\" , pro . layout ) print ( \"shape:\" , pro . shape ) if __name__ == '__main__' : models = dnn . load ( '../models/fcos_512x512_nv12.bin' ) # 打印输入 tensor 的属性 print_properties ( models [ 0 ] . inputs [ 0 ] . properties ) # 打印输出 tensor 的属性 print ( len ( models [ 0 ] . outputs )) for output in models [ 0 ] . outputs : print_properties ( output . properties ) # 获取 Camera 句柄 cam = srcampy . Camera () # 打开 f37 摄像头，并且把输出突出缩小成算法模型的输入尺寸 h , w = get_hw ( models [ 0 ] . inputs [ 0 ] . properties ) # 打开 F37, 初始化视频 pipeline 0 ，设置帧率30fps，缩放图像为 512 x 512 cam . open_cam ( 0 , 1 , 30 , w , h ) # Get HDMI display object disp = srcampy . Display () # For the meaning of parameters, please refer to the relevant documents of HDMI display disp . display ( 0 , 1920 , 1080 ) input_shape = ( h , w ) while True : # 从相机获取分辨率为 512x512 的nv12格式的图像数据， 参数 2 代表从硬件模块IPU中获取 img = cam . get_img ( 2 , 512 , 512 ) # 把图像数据转成 numpy 数据类型 img = np . frombuffer ( img , dtype = np . uint8 ) # 模型推理 outputs = models [ 0 ] . forward ( img ) # 对算法结果进行过滤，去掉执行度低的检测框，计算检测框的交并比去除冗余框，把检测框的坐标还原到原图位置上 prediction_bbox = postprocess ( outputs , input_shape , origin_img_shape = ( 1080 , 1920 )) # 从新获取一张图像，大小缩放成与显示器的分辨率一样的 1920 x 1080, 并且转换成 bgr格式，方便进行绘图操作 origin_image = cam . get_img ( 2 , 1920 , 1080 ) origin_nv12 = np . frombuffer ( origin_image , dtype = np . uint8 ) . reshape ( 1620 , 1920 ) origin_bgr = cv2 . cvtColor ( origin_nv12 , cv2 . COLOR_YUV420SP2BGR ) # 把算法运行后得到的物体检测框绘制到图像上 box_bgr = draw_bboxs ( origin_bgr , prediction_bbox ) # X3 的HDMI输出模块的输入图像格式需要是NV12的，所以需要先把bgr格式转成NV12 box_nv12 = bgr2nv12_opencv ( box_bgr ) # 把 NV12 格式的图像输出给显示器 disp . set_img ( box_nv12 . tobytes ()) cam . close_cam () USB相机目标检测 如果大家手上没有MIPI接口的相机，使用USB相机也可以实现同样的功能。 运行例程 $ cd /app/ai_inference/02_usb_camera_sample/ $ python3 ./usb_camera_fcos.py 动态目标检测 大家如果没有HDMI显示器的话，也没有问题，刚才的例程，也可以这样来运行，我们通过统一网络环境中的浏览器就可以动态看到结果啦。 # 启动webserver服务 $ cd /opt/tros/lib/websocket/webservice/ $ chmod +x ./sbin/nginx && ./sbin/nginx -p . # 运行例程 $ source /opt/tros/setup.bash $ cp -r /opt/tros/lib/dnn_node_example/config/ . $ cp -r /opt/tros/lib/dnn_benchmark_example/config/runtime/ ./config/ $ ros2 launch /opt/tros/share/dnn_node_example/launch/hobot_dnn_node_example.launch.py config_file: = config/fcosworkconfig.json image_width: = 480 image_height: = 272","text_tokens":["soft","laptop","某一","confidence","suitcase","边界","概率","希望","bbox","这套","获取","area","cvtcolor","视频","后续","就","train","ious","like","cow","，","cnn","重叠","cv2","usb","y2","sports","stride","识别","bgr2nv12","open","bicycle","tensor","libsrcampy","class","nv12","下角","up","回到","去除","spoon","通过","bear","newaxis","各种","ai","benchmark","h","神经","不仅","问题","目标","输出","orange","weight","一个","usr","：","yuv420p","来","names","microwave","argpartition","同样","i","[","后","bed","boxes1","\\","使用","最高","dump","donut","person","detection","一张","没有","中","实时处理","重在","宽度","websocket","包","设置","什么","系统","models","0.3","motorcycle","w","也","推理","jpg","float32","30fps","更要","属性","rectangle","book","软硬件","把","可以","image","4f","显示器","cell","r","elephant","banana","not","in","layout","摄像","网格","初始化","左下","boat","toaster","只有","最终","surfboard","计算","fork","落","and","应用","example","旭日","理解","效率","所以","$","cam","要求","max","+","boxes2","实时","documents","hsv","sandwich","像头","它会","pizza","array","模型","zeros","知道","vase","relevant","height","5","...","方便","行为","frombuffer","]","draw","物体","基于","coco","reshape","box","根据","说明","meshgrid","价值","'","__","成","color","topk","import","如果","广泛","接下","car","cd","缩小","colorsys","maximum","concatenate","得到","source","狗","linetype","执行","过滤","=","np","cup","to","refrigerator","代表","(","0.6","如何","range","is","打印","高度","那些","right","while","uv","2","font","位置","了","as","代码","fire","parking","airplane","ipu","中心","of","来看","snowboard","dtype","最为","完成","这样",".","\"","true","比如","给","&&","sample","利用","率","bus","srcampy","02","bboxs","sink","bottle","都","与","派","width","1","handbag","1920","parameters","。","2f","训练","图片","fcosworkconfig","threshold","dnn","giraffe","py","section","map","minimum","gt","有着","ones","frisbee","drier","opt","ball","y","起来","axis","share","fcos","因此","wine","类型","config","512x512","摄像头","x2","env","oven","tie","int32","numpy","启动","结果","0.5","opencv","webserver","zebra","检测","神经网络","dining","辨率","将","baseball","连续","接下来","所在","postprocess","8","please","手上","存在","小狗","算法","y1","hobot","picture","过程","buffer","close","实现","句柄","统一","append","none","/","input","下来","缩小成","预测","_","下","打开","finfo","list","时","object","tennis","跟踪","到","假设","和","x3","啦","glove","模块","backpack","eps","要","%","分类","s","index","runtime","坐标","网络","并","3","个","false","绘制","操作","def","i420","argmax","10","分成","ind","p","常用","app","read","服务","!","dog",":","cake","decode","}","hydrant","{","看到","进行","场景","sign","从","以及","nms","scissors","1080","sheep","file","bench","if","bboxes","0","bin","结合","name","标注","动态","puttext","512","cls","stop","80","..","nginx","对象","帧","%.","环境","车辆","camera","另外","转","t","比","display","多个","哪个","自然","min",")","拿到","64","那该","thickness","272","绘图","数据类型","tuples","单个","for","return","机器人","控制","就是","初始","高","浏览","对","原理","kite","best","exp","inputs","一样","int","开发","yv","pro","之前","换成","*","len","chmod","node","iou","togetherros","truck","method","light","disp","以","glass","接口","冗余","phone","pred","yolo","#","get","原图","32","line","四个","union","描述符","libs","还要","处理","enumerate","还原","速度","format","输出模块","cat","128","meter","xv","api","xy","是",">","缩放","上","setup","16","打印输出","运用","内","硬件","demo","data","大家","size","stack","数据","度","plant","model","thick","aa","格子","uint8","apple","包围","输入","x1","properties","图像格式","output","gettextsize","30","f37","mouse","分割","255","distance","pipeline","vio","框","运行","bash","种","负责","from","1.0","行驶","0.0","参数","carrot","中将","idx","尺寸","7x7","inference","一种","对于","cp","couch","channel","img","图像","sbin","tv","chair","他们","clock","机器","else","knife","x","解析","浏览器","classes","并且","卷积","rgb2yuv","刚才"," ","sqrt","type","这个","去","rgb","-","转换","ce","低","tros","hair","1620","traffic","inter","先","之后","分辨","resized","toilet","各种各样","scores","所属","这","mess","num","distance2bbox","功能","mask","各样","c2","planar","forward","racket","toothbrush","fontscale","lambda","hershey","keyboard","imwrite","arange","运动","launch","描述","skateboard","bowl","pyeasy","print","一般","监测","coor","当","便于","pad","交","分析","down","simplex","大小","480","outputs","table","colors","origin","score","prediction","转成","例程","json","main","teddy","分辨率","、","mipi","自然环境","类别","assert","比较","我们","的","meaning","tobytes","transpose","hdmi","refer","600","只","points","nchw","ros2","信息","软硬","shape","突出","potted","original","为例","视频流","每个","bat","转换成","skis","在","load","快速","set","的话","broccoli","显示","python3","03","中心点","scale","the","bgr","yuv420sp2bgr","非常","1000","类","然后","格式","该","相机","去掉","webservice","小成",",","umbrella","remote","left","新","c1","packed","为","lib","strides","有","开发板","horse","集","hw","sigma","需要","bird","with","4","hot","神经网","左下角"],"title":"动态目标检测","title_tokens":["检测","动态","目标"]},{"location":"hhp/5.5_%E5%8A%A8%E6%80%81%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/#_1","text":"图像物体分类重在分析图像中存在的物体是什么，便于机器理解看到的环境信息，另外一种场景，机器不仅要识别某一物体，还要知道这个物体所在的位置，当物体在运动时，更要快速连续的跟踪，这就是目标检测，重在分析识别到物体在图像中的位置。","text_tokens":["当","重在","便于","某一","什么","分析","不仅","一种","目标","在","快速","这","图像","看到","知道","时","更要","场景","跟踪","到","，","机器","就是","还要","的","要","分类","。","物体","识别","运动","位置","这个","是","检测","连续","所在","环境","存在","另外","信息","中","理解"],"title":"动态目标检测","title_tokens":["检测","动态","目标"]},{"location":"hhp/5.5_%E5%8A%A8%E6%80%81%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/#_2","text":"假设我们要识别图像中这只狗的位置，以最为常用的YOLO算法为例，它会运用单个卷积神经网络(CNN) ，将图像分成网格，并预测每个网格的对象概率和边界框。 比如，对于这个图像，Yolo的CNN网络将输入的图片分割成7x7的网格，然后每个网格负责去检测那些中心点落在该格子内的目标，比如，小狗这个目标的中心点在左下角的网格中，那该网格就负责预测狗这个对象。 每个网格中将有多个边界框，在训练时，我们希望每个对象只有一个边界框，比如最终只有一个边界框把这只狗包起来。因此，我们根据哪个边界框与之前标注的重叠度最高，预测对象的位置和概率。 最终包围对象的边界框，就是识别的结果，使用四个描述符进行说明： 边界框的中心位置 边界框的高度 边界框的宽度 识别到对象所属的类 这样就完成了对目标的实时检测，拿到目标的信息之后，就可以进行后续的机器人行为控制了。 我们对目标检测系统运行速度的要求一般都比较高，可以实时处理视频流，比如车辆行驶的动态监测、自然环境中的目标识别，有着非常广泛的应用价值。 回到TogetherROS和旭日X3派的开发板，我们来看下这套软硬件结合的目标检测系统，效率如何。","text_tokens":["中将","7x7","边界","概率","希望","对于","这套","常用","视频","后续","图像","就","进行","，","cnn","机器","(","重叠","如何","高度","结合","那些","标注","识别","动态","卷积"," ","位置","这个","了","去","中心","对象","下角","来看","环境","车辆","回到","最为","完成","这样","比如","多个","之后","哪个","神经","目标","自然",")","拿到","那该","所属","这","一个","都","与","单个","派","：","机器人","控制","就是","高","对","。","训练","图片","描述","开发","使用","最高","之前","一般","监测","有着","中","实时处理","togetherros","宽度","包","以","起来","系统","因此","yolo","四个","、","自然环境","描述符","软硬件","把","可以","比较","我们","的","处理","结果","网格","速度","左下","只有","最终","只","神经网络","检测","将","落","小狗","算法","信息","应用","旭日","运用","内","软硬","硬件","效率","要求","为例","实时","每个","视频流","度","它会","预测","在","下","格子","时","中心点","假设","到","和","非常","x3","包围","然后","类","该","输入","行为","要","网络","并","根据","说明","价值","成","分割","广泛","有","开发板","框","运行","分成","负责","狗","行驶","神经网","左下角"],"title":"目标检测原理","title_tokens":["检测","原理","目标"]},{"location":"hhp/5.5_%E5%8A%A8%E6%80%81%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/#mipi","text":"接下来，我们要利用MIPI相机，动态识别图像中各种各样的物体以及他们所在的位置，推理过程使用的是基于COCO数据集训练的80个类别，也就是可以识别80种常用的物体位置。","text_tokens":["各种","利用","数据","下来","各种各样","常用","也","推理","图像","mipi","类别","以及","各样","他们","，","就是","可以","我们","相机","的","要","。","物体","训练","基于","coco","动态","识别","个","位置","是","使用","80","接下","接下来","所在","集","种","中","过程"],"title":"MIPI相机目标检测","title_tokens":["mipi","检测","目标","相机"]},{"location":"hhp/5.5_%E5%8A%A8%E6%80%81%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/#_3","text":"$ cd /app/ai_inference/03_mipi_camera_sample/ $ python3 ./mipi_camera.py","text_tokens":["app","ai","03","cd","mipi","$","sample","python3","inference",".","py","camera","/"," ","_"],"title":"运行例程","title_tokens":["例程","运行"]},{"location":"hhp/5.5_%E5%8A%A8%E6%80%81%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/#_4","text":"mipi_camera.py： #!/usr/bin/env python3 import numpy as np import cv2 import colorsys # Camera API libs from hobot_vio import libsrcampy as srcampy from hobot_dnn import pyeasy_dnn as dnn # detection model class names def get_classes (): return np . array ([ \"person\" , \"bicycle\" , \"car\" , \"motorcycle\" , \"airplane\" , \"bus\" , \"train\" , \"truck\" , \"boat\" , \"traffic light\" , \"fire hydrant\" , \"stop sign\" , \"parking meter\" , \"bench\" , \"bird\" , \"cat\" , \"dog\" , \"horse\" , \"sheep\" , \"cow\" , \"elephant\" , \"bear\" , \"zebra\" , \"giraffe\" , \"backpack\" , \"umbrella\" , \"handbag\" , \"tie\" , \"suitcase\" , \"frisbee\" , \"skis\" , \"snowboard\" , \"sports ball\" , \"kite\" , \"baseball bat\" , \"baseball glove\" , \"skateboard\" , \"surfboard\" , \"tennis racket\" , \"bottle\" , \"wine glass\" , \"cup\" , \"fork\" , \"knife\" , \"spoon\" , \"bowl\" , \"banana\" , \"apple\" , \"sandwich\" , \"orange\" , \"broccoli\" , \"carrot\" , \"hot dog\" , \"pizza\" , \"donut\" , \"cake\" , \"chair\" , \"couch\" , \"potted plant\" , \"bed\" , \"dining table\" , \"toilet\" , \"tv\" , \"laptop\" , \"mouse\" , \"remote\" , \"keyboard\" , \"cell phone\" , \"microwave\" , \"oven\" , \"toaster\" , \"sink\" , \"refrigerator\" , \"book\" , \"clock\" , \"vase\" , \"scissors\" , \"teddy bear\" , \"hair drier\" , \"toothbrush\" ]) def bgr2nv12_opencv ( image ): height , width = image . shape [ 0 ], image . shape [ 1 ] area = height * width yuv420p = cv2 . cvtColor ( image , cv2 . COLOR_RGB2YUV_I420 ) . reshape (( area * 3 // 2 ,)) y = yuv420p [: area ] uv_planar = yuv420p [ area :] . reshape (( 2 , area // 4 )) uv_packed = uv_planar . transpose (( 1 , 0 )) . reshape (( area // 2 ,)) nv12 = np . zeros_like ( yuv420p ) nv12 [: height * width ] = y nv12 [ height * width :] = uv_packed return nv12 def get_hw ( pro ): if pro . layout == \"NCHW\" : return pro . shape [ 2 ], pro . shape [ 3 ] else : return pro . shape [ 1 ], pro . shape [ 2 ] def postprocess ( model_output , model_hw_shape , origin_image = None , origin_img_shape = None , score_threshold = 0.5 , nms_threshold = 0.6 , dump_image = False ): input_height = model_hw_shape [ 0 ] input_width = model_hw_shape [ 1 ] if origin_image is not None : origin_image_shape = origin_image . shape [ 0 : 2 ] else : origin_image_shape = origin_img_shape prediction_bbox = decode ( outputs = model_output , score_threshold = score_threshold , origin_shape = origin_image_shape , input_size = 512 ) prediction_bbox = nms ( prediction_bbox , iou_threshold = nms_threshold ) prediction_bbox = np . array ( prediction_bbox ) topk = min ( prediction_bbox . shape [ 0 ], 1000 ) if topk != 0 : idx = np . argpartition ( prediction_bbox [ ... , 4 ], - topk )[ - topk :] prediction_bbox = prediction_bbox [ idx ] if dump_image and origin_image is not None : draw_bboxs ( origin_image , prediction_bbox ) return prediction_bbox def draw_bboxs ( image , bboxes , gt_classes_index = None , classes = get_classes ()): \"\"\"draw the bboxes in the original image \"\"\" num_classes = len ( classes ) image_h , image_w , channel = image . shape hsv_tuples = [( 1.0 * x / num_classes , 1. , 1. ) for x in range ( num_classes )] colors = list ( map ( lambda x : colorsys . hsv_to_rgb ( * x ), hsv_tuples )) colors = list ( map ( lambda x : ( int ( x [ 0 ] * 255 ), int ( x [ 1 ] * 255 ), int ( x [ 2 ] * 255 )), colors )) fontScale = 0.5 bbox_thick = int ( 0.6 * ( image_h + image_w ) / 600 ) for i , bbox in enumerate ( bboxes ): coor = np . array ( bbox [: 4 ], dtype = np . int32 ) if gt_classes_index == None : class_index = int ( bbox [ 5 ]) score = bbox [ 4 ] else : class_index = gt_classes_index [ i ] score = 1 bbox_color = colors [ class_index ] c1 , c2 = ( coor [ 0 ], coor [ 1 ]), ( coor [ 2 ], coor [ 3 ]) cv2 . rectangle ( image , c1 , c2 , bbox_color , bbox_thick ) classes_name = classes [ class_index ] bbox_mess = ' %s : %.2f ' % ( classes_name , score ) t_size = cv2 . getTextSize ( bbox_mess , 0 , fontScale , thickness = bbox_thick // 2 )[ 0 ] cv2 . rectangle ( image , c1 , ( c1 [ 0 ] + t_size [ 0 ], c1 [ 1 ] - t_size [ 1 ] - 3 ), bbox_color , - 1 ) cv2 . putText ( image , bbox_mess , ( c1 [ 0 ], c1 [ 1 ] - 2 ), cv2 . FONT_HERSHEY_SIMPLEX , fontScale , ( 0 , 0 , 0 ), bbox_thick // 2 , lineType = cv2 . LINE_AA ) print ( \" {} is in the picture with confidence: {:.4f} , bbox: {} \" . format ( classes_name , score , coor )) # cv2.imwrite(\"demo.jpg\", image) return image def decode ( outputs , score_threshold , origin_shape , input_size = 512 ): def _distance2bbox ( points , distance ): x1 = points [ ... , 0 ] - distance [ ... , 0 ] y1 = points [ ... , 1 ] - distance [ ... , 1 ] x2 = points [ ... , 0 ] + distance [ ... , 2 ] y2 = points [ ... , 1 ] + distance [ ... , 3 ] return np . stack ([ x1 , y1 , x2 , y2 ], - 1 ) def _scores ( cls , ce ): cls = 1 / ( 1 + np . exp ( - cls )) ce = 1 / ( 1 + np . exp ( - ce )) return np . sqrt ( ce * cls ) def _bbox ( bbox , stride , origin_shape , input_size ): h , w = bbox . shape [ 1 : 3 ] yv , xv = np . meshgrid ( np . arange ( h ), np . arange ( w )) xy = ( np . stack (( yv , xv ), 2 ) + 0.5 ) * stride bbox = _distance2bbox ( xy , bbox ) # opencv read, shape[1] is w, shape[0] is h scale_w = origin_shape [ 1 ] / input_size scale_h = origin_shape [ 0 ] / input_size scale = max ( origin_shape [ 0 ], origin_shape [ 1 ]) / input_size # origin img is pad resized #bbox = bbox * scale # origin img is resized bbox = bbox * [ scale_w , scale_h , scale_w , scale_h ] return bbox bboxes = list () strides = [ 8 , 16 , 32 , 64 , 128 ] for i in range ( len ( strides )): cls = outputs [ i ] . buffer bbox = outputs [ i + 5 ] . buffer ce = outputs [ i + 10 ] . buffer scores = _scores ( cls , ce ) classes = np . argmax ( scores , axis =- 1 ) classes = np . reshape ( classes , [ - 1 , 1 ]) max_score = np . max ( scores , axis =- 1 ) max_score = np . reshape ( max_score , [ - 1 , 1 ]) bbox = _bbox ( bbox , strides [ i ], origin_shape , input_size ) bbox = np . reshape ( bbox , [ - 1 , 4 ]) pred_bbox = np . concatenate ([ bbox , max_score , classes ], axis = 1 ) index = pred_bbox [ ... , 4 ] > score_threshold pred_bbox = pred_bbox [ index ] bboxes . append ( pred_bbox ) return np . concatenate ( bboxes ) def nms ( bboxes , iou_threshold , sigma = 0.3 , method = 'nms' ): def bboxes_iou ( boxes1 , boxes2 ): boxes1 = np . array ( boxes1 ) boxes2 = np . array ( boxes2 ) boxes1_area = ( boxes1 [ ... , 2 ] - boxes1 [ ... , 0 ]) * \\ ( boxes1 [ ... , 3 ] - boxes1 [ ... , 1 ]) boxes2_area = ( boxes2 [ ... , 2 ] - boxes2 [ ... , 0 ]) * \\ ( boxes2 [ ... , 3 ] - boxes2 [ ... , 1 ]) left_up = np . maximum ( boxes1 [ ... , : 2 ], boxes2 [ ... , : 2 ]) right_down = np . minimum ( boxes1 [ ... , 2 :], boxes2 [ ... , 2 :]) inter_section = np . maximum ( right_down - left_up , 0.0 ) inter_area = inter_section [ ... , 0 ] * inter_section [ ... , 1 ] union_area = boxes1_area + boxes2_area - inter_area ious = np . maximum ( 1.0 * inter_area / union_area , np . finfo ( np . float32 ) . eps ) return ious classes_in_img = list ( set ( bboxes [:, 5 ])) best_bboxes = [] for cls in classes_in_img : cls_mask = ( bboxes [:, 5 ] == cls ) cls_bboxes = bboxes [ cls_mask ] while len ( cls_bboxes ) > 0 : max_ind = np . argmax ( cls_bboxes [:, 4 ]) best_bbox = cls_bboxes [ max_ind ] best_bboxes . append ( best_bbox ) cls_bboxes = np . concatenate ( [ cls_bboxes [: max_ind ], cls_bboxes [ max_ind + 1 :]]) iou = bboxes_iou ( best_bbox [ np . newaxis , : 4 ], cls_bboxes [:, : 4 ]) weight = np . ones (( len ( iou ),), dtype = np . float32 ) assert method in [ 'nms' , 'soft-nms' ] if method == 'nms' : iou_mask = iou > iou_threshold weight [ iou_mask ] = 0.0 if method == 'soft-nms' : weight = np . exp ( - ( 1.0 * iou ** 2 / sigma )) cls_bboxes [:, 4 ] = cls_bboxes [:, 4 ] * weight score_mask = cls_bboxes [:, 4 ] > 0. cls_bboxes = cls_bboxes [ score_mask ] return best_bboxes def print_properties ( pro ): print ( \"tensor type:\" , pro . tensor_type ) print ( \"data type:\" , pro . dtype ) print ( \"layout:\" , pro . layout ) print ( \"shape:\" , pro . shape ) if __name__ == '__main__' : models = dnn . load ( '../models/fcos_512x512_nv12.bin' ) # 打印输入 tensor 的属性 print_properties ( models [ 0 ] . inputs [ 0 ] . properties ) # 打印输出 tensor 的属性 print ( len ( models [ 0 ] . outputs )) for output in models [ 0 ] . outputs : print_properties ( output . properties ) # 获取 Camera 句柄 cam = srcampy . Camera () # 打开 f37 摄像头，并且把输出突出缩小成算法模型的输入尺寸 h , w = get_hw ( models [ 0 ] . inputs [ 0 ] . properties ) # 打开 F37, 初始化视频 pipeline 0 ，设置帧率30fps，缩放图像为 512 x 512 cam . open_cam ( 0 , 1 , 30 , w , h ) # Get HDMI display object disp = srcampy . Display () # For the meaning of parameters, please refer to the relevant documents of HDMI display disp . display ( 0 , 1920 , 1080 ) input_shape = ( h , w ) while True : # 从相机获取分辨率为 512x512 的nv12格式的图像数据， 参数 2 代表从硬件模块IPU中获取 img = cam . get_img ( 2 , 512 , 512 ) # 把图像数据转成 numpy 数据类型 img = np . frombuffer ( img , dtype = np . uint8 ) # 模型推理 outputs = models [ 0 ] . forward ( img ) # 对算法结果进行过滤，去掉执行度低的检测框，计算检测框的交并比去除冗余框，把检测框的坐标还原到原图位置上 prediction_bbox = postprocess ( outputs , input_shape , origin_img_shape = ( 1080 , 1920 )) # 从新获取一张图像，大小缩放成与显示器的分辨率一样的 1920 x 1080, 并且转换成 bgr格式，方便进行绘图操作 origin_image = cam . get_img ( 2 , 1920 , 1080 ) origin_nv12 = np . frombuffer ( origin_image , dtype = np . uint8 ) . reshape ( 1620 , 1920 ) origin_bgr = cv2 . cvtColor ( origin_nv12 , cv2 . COLOR_YUV420SP2BGR ) # 把算法运行后得到的物体检测框绘制到图像上 box_bgr = draw_bboxs ( origin_bgr , prediction_bbox ) # X3 的HDMI输出模块的输入图像格式需要是NV12的，所以需要先把bgr格式转成NV12 box_nv12 = bgr2nv12_opencv ( box_bgr ) # 把 NV12 格式的图像输出给显示器 disp . set_img ( box_nv12 . tobytes ()) cam . close_cam ()","text_tokens":["soft","laptop","confidence","suitcase","bbox","获取","area","cvtcolor","视频","train","ious","like","cow","，","cv2","y2","sports","stride","bgr2nv12","open","bicycle","tensor","libsrcampy","class","nv12","up","去除","spoon","bear","newaxis","h","输出","orange","weight","usr","：","yuv420p","names","microwave","argpartition","i","[","后","bed","boxes1","\\","dump","donut","person","detection","一张","中","设置","models","0.3","motorcycle","w","推理","jpg","float32","30fps","属性","rectangle","book","把","image","4f","显示器","cell","elephant","banana","not","in","layout","摄像","初始化","boat","toaster","surfboard","计算","fork","and","所以","cam","max","+","boxes2","documents","hsv","sandwich","像头","pizza","array","模型","zeros","vase","relevant","height","5","...","方便","frombuffer","]","draw","物体","reshape","box","meshgrid","'","__","topk","color","成","import","car","缩小","colorsys","maximum","concatenate","得到","linetype","执行","过滤","=","np","cup","to","refrigerator","代表","(","0.6","range","is","打印","while","right","uv","2","font","位置","as","fire","parking","airplane","ipu","of","snowboard","dtype","\"",".","给","true","率","bus","srcampy","bboxs","sink","bottle","与","width","1","handbag","1920","parameters","2f","threshold","dnn","giraffe","py","section","map","minimum","gt","ones","frisbee","drier","ball","y","axis","fcos","wine","类型","512x512","摄像头","x2","env","oven","tie","int32","numpy","结果","0.5","opencv","zebra","dining","检测","辨率","baseball","postprocess","please","8","算法","y1","hobot","picture","close","buffer","句柄","append","none","/","input","缩小成","_","object","打开","finfo","list","tennis","到","x3","glove","模块","backpack","eps","%","s","index","坐标","3","并","绘制","false","操作","def","i420","argmax","10","ind","read","!","dog",":","cake","decode","}","hydrant","{","进行","sign","从","nms","scissors","1080","sheep","bench","if","bboxes","0","bin","name","puttext","512","cls","stop","..","帧","%.","camera","转","t","比","display","min",")","64","thickness","绘图","数据类型","tuples","for","return","初始","对","kite","best","exp","inputs","一样","int","yv","pro","换成","*","len","iou","truck","method","light","disp","glass","冗余","phone","pred","#","get","原图","32","line","union","libs","enumerate","还原","format","输出模块","128","cat","meter","xv","api","xy",">","是","缩放","上","16","打印输出","硬件","demo","data","size","stack","数据","度","plant","model","thick","aa","uint8","apple","输入","x1","properties","图像格式","output","gettextsize","30","f37","mouse","255","distance","pipeline","vio","框","运行","from","1.0","0.0","参数","carrot","idx","尺寸","couch","channel","img","图像","tv","chair","clock","else","knife","x","classes","并且","rgb2yuv"," ","sqrt","type","rgb","-","转换","ce","低","hair","1620","traffic","inter","先","分辨","resized","toilet","scores","mess","num","distance2bbox","mask","c2","planar","forward","racket","toothbrush","fontscale","lambda","hershey","keyboard","imwrite","arange","skateboard","bowl","pyeasy","print","coor","pad","交","down","大小","simplex","outputs","table","colors","origin","score","prediction","转成","main","teddy","分辨率","mipi","assert","的","meaning","tobytes","transpose","hdmi","refer","600","points","nchw","shape","突出","potted","original","转换成","bat","skis","load","set","broccoli","显示","python3","scale","the","bgr","yuv420sp2bgr","1000","格式","相机","去掉","小成",",","umbrella","remote","left","新","c1","packed","为","strides","horse","hw","sigma","需要","bird","with","4","hot"],"title":"代码解析","title_tokens":["解析","代码"]},{"location":"hhp/5.5_%E5%8A%A8%E6%80%81%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/#usb","text":"如果大家手上没有MIPI接口的相机，使用USB相机也可以实现同样的功能。","text_tokens":["使用","实现","。","大家","mipi","接口","usb","手上","功能","同样","，","可以","相机","也","的","没有","如果"],"title":"USB相机目标检测","title_tokens":["相机","检测","目标","usb"]},{"location":"hhp/5.5_%E5%8A%A8%E6%80%81%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/#_5","text":"$ cd /app/ai_inference/02_usb_camera_sample/ $ python3 ./usb_camera_fcos.py","text_tokens":["app","ai","sample","cd","python3","$","inference",".","py","fcos","camera","/"," ","02","usb","_"],"title":"运行例程","title_tokens":["例程","运行"]},{"location":"hhp/5.5_%E5%8A%A8%E6%80%81%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/#_6","text":"大家如果没有HDMI显示器的话，也没有问题，刚才的例程，也可以这样来运行，我们通过统一网络环境中的浏览器就可以动态看到结果啦。 # 启动webserver服务 $ cd /opt/tros/lib/websocket/webservice/ $ chmod +x ./sbin/nginx && ./sbin/nginx -p . # 运行例程 $ source /opt/tros/setup.bash $ cp -r /opt/tros/lib/dnn_node_example/config/ . $ cp -r /opt/tros/lib/dnn_benchmark_example/config/runtime/ ./config/ $ ros2 launch /opt/tros/share/dnn_node_example/launch/hobot_dnn_node_example.launch.py config_file: = config/fcosworkconfig.json image_width: = 480 image_height: = 272","text_tokens":["服务",":","=","cp","就","看到","sbin","，","x","file","浏览器","动态","刚才"," ","-","nginx","环境","tros","通过","这样",".","&&","benchmark","问题","272","width","来","浏览","。","launch","fcosworkconfig","dnn","py","chmod","node","没有","中","opt","websocket","share","480","#","也","config","例程","json","可以","image","我们","显示器","的","r","启动","结果","hdmi","webserver","setup","ros2","example","hobot","大家","统一","$","+","/","_","的话","显示","height","啦","webservice","runtime","网络","lib","如果","cd","运行","bash","source","p"],"title":"动态目标检测","title_tokens":["检测","动态","目标"]},{"location":"hhp/5.6_%E4%BA%BA%E4%BD%93%E6%A3%80%E6%B5%8B%E4%B8%8E%E8%B7%9F%E8%B8%AA/","text":"人体检测与跟踪 不知道大家有没有玩过类似XBOX的体感游戏机，上边会有一个相机，动态识别我们的动作，比如跳舞、打球，是不是还挺神奇的，这就是人体检测与跟踪的应用。 TogetherROS中也集成了一套类似的算法，可以识别人体、人头、人脸、人手等一系列关键点，我们来体验一下。 编程开发方法 先来看一个人体识别的基础应用，我们驱动相机后，实时采样视觉信息，然后再通过检测算法，识别每一幅图片中人体位置，并把识别的结果保存成一张图片，便于我们查看。 运行例程 # 下载例程代码（与之前课程下载的代码一致） $ cd /userdata/dev_ws/src $ git clone https://gitee.com/guyuehome/togetherros_tutorials.git $ cd /userdata/dev_ws/ $ colcon build # 终端1，运行相机 $ source /opt/tros/setup.bash $ ros2 run mipi_cam mipi_cam --ros-args -p out_format: = nv12 -p image_width: = 960 -p image_height: = 544 -p video_device: = F37 # 终端2，运行例程 $ source /opt/tros/setup.bash $ source ./install/local_setup.bash $ mkdir -p config && cp -r /opt/tros/lib/dnn_node_example/config/multitask_body_kps_960x544.hbm config/ $ ros2 run cpp_dnn_demo cpp_dnn_demo --ros-args -p image: = config/test.jpg 代码解析 #include \"opencv2/core/mat.hpp\" #include \"opencv2/imgcodecs.hpp\" #include \"opencv2/imgproc.hpp\" #include \"dnn_node/dnn_node.h\" #include \"dnn_node/util/image_proc.h\" #include \"sensor_msgs/msg/image.hpp\" using namespace hobot :: dnn_node ; class BodyDetNode : public DnnNode { public : BodyDetNode ( const std :: string & node_name = \"body_det\" , const rclcpp :: NodeOptions & options = rclcpp :: NodeOptions ()) : DnnNode ( node_name , options ) { // 获取模型输入图片的尺寸，包括图片的宽model_input_width_和高model_input_height ，用于模型前处理 if ( Init () != 0 || GetModelInputSize ( 0 , model_input_width_ , model_input_height_ ) < 0 ) { RCLCPP_ERROR ( rclcpp :: get_logger ( \"example\" ), \"Node init fail!\" ); } //创建图片消息的subscriber，订阅的topic为”/image_raw”，消息类型为sensor_msgs::msg::Image。订阅到的图片用于算法模型推理 ros_img_subscription_ = this -> create_subscription < sensor_msgs :: msg :: Image > ( \"/image_raw\" , 10 , std :: bind ( & BodyDetNode :: FeedImg , this , std :: placeholders :: _1 )); } ~ BodyDetNode () override {} void FeedImg ( const sensor_msgs :: msg :: Image :: ConstSharedPtr msg ); protected : int SetNodePara () override { if ( ! dnn_node_para_ptr_ ) return -1 ; //指定模型推理使用的模型文件名和模型名 dnn_node_para_ptr_ -> model_file = \"config/multitask_body_kps_960x544.hbm\" ; dnn_node_para_ptr_ -> model_name = \"multitask_body_kps_960x544\" ; //指定模型输出的人体框的解析方法，其中人体框输出索引为box_output_index_ //使用的解析方法为hobot_dnn预定义的检测框解析方法FaceHandDetectionOutputParser。 std :: shared_ptr < OutputParser > box_out_parser = std :: make_shared < FaceHandDetectionOutputParser > (); dnn_node_para_ptr_ -> output_parsers_ . emplace_back ( std :: make_pair ( box_output_index_ , box_out_parser ) ); return 0 ; } int PostProcess ( const std :: shared_ptr < DnnNodeOutput > & node_output ) override ; private : int model_input_width_ = -1 ; int model_input_height_ = -1 ; const int32_t box_output_index_ = 1 ; sensor_msgs :: msg :: Image :: ConstSharedPtr img_msg_ ; rclcpp :: Subscription < sensor_msgs :: msg :: Image >:: ConstSharedPtr ros_img_subscription_ = nullptr ; }; //输出模型结果，并将结果渲染到图片后保存在本地 int BodyDetNode::PostProcess ( const std :: shared_ptr < DnnNodeOutput > & node_output ) { if ( node_output -> outputs . empty () || static_cast < int32_t > ( node_output -> outputs . size ()) < box_output_index_ ) { RCLCPP_ERROR ( rclcpp :: get_logger ( \"example\" ), \"Invalid outputs\" ); return -1 ; } auto * filter2d_result = dynamic_cast < Filter2DResult *> ( node_output -> outputs [ box_output_index_ ]. get ()); if ( ! filter2d_result ) return -1 ; std :: stringstream ss ; ss << \"img encoding: \" << img_msg_ -> encoding << \", stamp: \" << img_msg_ -> header . stamp . sec << \",\" << img_msg_ -> header . stamp . nanosec << \" \\n out box size: \" << filter2d_result -> boxes . size () << \" \\n \" ; cv :: Mat nv12 ( img_msg_ -> height * 3 / 2 , img_msg_ -> width , CV_8UC1 , const_cast < char *> ( reinterpret_cast < const char *> ( img_msg_ -> data . data ()))); cv :: Mat bgr ; cv :: cvtColor ( nv12 , bgr , CV_YUV2BGR_NV12 ); for ( auto & rect : filter2d_result -> boxes ) { ss << \"rect: \" << rect . left << \" \" << rect . top << \" \" << rect . right << \" \" << rect . bottom << \" \\n \" ; // 图片渲染 cv :: rectangle ( bgr , cv :: Point ( rect . left , rect . top ), cv :: Point ( rect . right , rect . bottom ), cv :: Scalar ( 255 , 0 , 0 ), 3 ); } std :: string result_image = \"render_\" + std :: to_string ( img_msg_ -> header . stamp . sec ) + \".\" + std :: to_string ( img_msg_ -> header . stamp . nanosec ) + \".jpg\" ; ss << \"Render img to file: \" << result_image ; RCLCPP_INFO ( rclcpp :: get_logger ( \"example\" ), \"%s\" , ss . str (). c_str ()); cv :: imwrite ( result_image , bgr ); return 0 ; } //将nv12格式的图片转成模型输入的数据类型DNNInput后，输入给推理任务 void BodyDetNode::FeedImg ( const sensor_msgs :: msg :: Image :: ConstSharedPtr img_msg ) { if ( ! img_msg ) return ; if ( \"nv12\" != img_msg -> encoding ) { RCLCPP_ERROR ( rclcpp :: get_logger ( \"example\" ), \"Only support nv12 img encoding!\" ); return ; } img_msg_ = img_msg ; // 创建模型输入数据 auto inputs = std :: vector < std :: shared_ptr < DNNInput >> { ImageProc :: GetNV12PyramidFromNV12Img ( reinterpret_cast < const char *> ( img_msg -> data . data ()), img_msg -> height , img_msg -> width , model_input_height_ , model_input_width_ )}; // 运行推理，DnnNode基类中定义并实现的启动推理接口。 Run ( inputs ); } int main ( int argc , char ** argv ) { rclcpp :: init ( argc , argv ); rclcpp :: spin ( std :: make_shared < BodyDetNode > ()); rclcpp :: shutdown (); return 0 ; } 人体检测与跟踪 结果保存成图片，虽然便于保留数据，但是不利于动态看到效果，我们不如再来实时动态效果显示。 在这个案例中，我们在之前人体识别的基础上，进一步实现了人体部位的识别和骨骼、眼神等关键点的识别，比如头、脸、身体、手掌、眼睛。 识别的结果同样是通过浏览器来进行查看。 # 启动webserver服务 $ cd /opt/tros/lib/websocket/webservice/ $ chmod +x ./sbin/nginx && ./sbin/nginx -p . # 运行例程 $ source /opt/tros/setup.bash $ cp -r /opt/tros/lib/mono2d_body_detection/config/ . $ ros2 launch /opt/tros/share/mono2d_body_detection/launch/hobot_mono2d_body_detection.launch.py","text_tokens":["基础","xbox","获取","cvtcolor","bind","是不是","constsharedptr","，","static","msgs","识别","|","宽","身体","nv12","class","nullptr","名","通过","create","boxes","build","h","案例","输出","一个","960x544","神奇","来","一系列","课程","游戏","topic","同样","后","[","dnninput","\\","使用","colcon","detection","一张","没有","中","websocket","stringstream","也","推理","jpg","filter2d","rectangle","可以","把","image","r","n","spin","sec","src","subscription","960","不是","应用","example","~","--","$","cam","+","imageproc","实时","override","out","模型","知道","argc","height","subscriber","getmodelinputsize","本地","body","]","include","box","https","成","const","人头","encoding","cd","init","索引","文件","emplace","source","imgcodecs","stamp","raw","有没有","=","invalid","不利","不如","to","userdata","(","利于","right","2","proc","驱动","位置","了","private","代码","义","渲染","来看","feedimg","\"",".","给","比如","&&","using","基类","关键","会","包括","关键点","与","1","width","nanosec","pair","。","人手","device","图片","再","install","options","挺","dnn","dnnnodeoutput","void","py","任务","sensor","parsers","opt","544","方法","share","ptr","一套","类型","info","config","其中","test","namespace","int32","但是","体验","argv","启动","结果","webserver","集成","开发方法","检测","将","postprocess","保留","算法","cast","hobot","实现","shutdown","/","input","_","跳舞","部位","眼睛","跟踪","到","和","ws","str","%","8uc1","s","dev","index","不","com","bottom","并","3","string","进一步","public","tutorials","还","10","p","手掌","point","服务","!",":","动作","reinterpret","core","dynamic","}","local","{","看到","进行","前","dnnnode","file","if",";","0","name","opencv2","动态","编程","cpp","效果","fail","run","video","nginx","转","上边","t","体感","订阅","kps",")","placeholders","视觉","git","&","数据类型","for","return","就是","高","浏览","虽然","inputs","int","top","imgproc","开发","result","一幅","之前","*","chmod","node","rect","（","togetherros","nodeoptions","接口","一致","back","#","get","getnv12pyramidfromnv12img","this","multitask","处理","rclcpp","char","人脸","format","hpp","<",">","是","上","setup","系列","mat","demo","data","大家","头","size","msg","数据","model","玩过","ros","用于","一步","下载","输入","scalar","bodydetnode","output","gitee","f37","255","脸","logger","框","empty","only","运行","bash","cv","c","尺寸","mono2d","cp","不利于","查看","游戏机","img","定义","sbin","文件名","x","解析","yuv2bgr","浏览器","一系","protected"," ","这个","-","tros","parser","shared","先","render","这","采样","类似","imwrite","launch","clone","终端","每","filter2dresult","std","人体","保存","setnodepara","便于","打球","det","outputs","例程","main","、","mipi","眼神","header","）","指定","我们","的","vector","error","ss","消息","hbm","util","ros2","信息","一下","outputparser","等","预定","facehanddetectionoutputparser","para","在","”","显示","bgr","然后","格式","动态效果","相机","骨骼","mkdir","webservice",",","left","auto","make","support","为","lib","args","创建","有","guyuehome"],"title":"人体检测与跟踪","title_tokens":["人体","检测","与","跟踪"]},{"location":"hhp/5.6_%E4%BA%BA%E4%BD%93%E6%A3%80%E6%B5%8B%E4%B8%8E%E8%B7%9F%E8%B8%AA/#_1","text":"不知道大家有没有玩过类似XBOX的体感游戏机，上边会有一个相机，动态识别我们的动作，比如跳舞、打球，是不是还挺神奇的，这就是人体检测与跟踪的应用。 TogetherROS中也集成了一套类似的算法，可以识别人体、人头、人脸、人手等一系列关键点，我们来体验一下。","text_tokens":["体感","比如","togetherros","大家","打球","等","有没有","xbox","动作","关键","一套","也","会","这","游戏机","跳舞","关键点","知道","一个","玩过","、","是不是","与","跟踪","神奇","，","就是","可以","我们","相机","来","的","一系列","类似","游戏","。","人手","体验","一系","不","动态","识别","人脸"," ","挺","集成","系列","不是","了","检测","人头","有","应用","还","人体","一下","算法","上边","没有","中"],"title":"人体检测与跟踪","title_tokens":["人体","检测","与","跟踪"]},{"location":"hhp/5.6_%E4%BA%BA%E4%BD%93%E6%A3%80%E6%B5%8B%E4%B8%8E%E8%B7%9F%E8%B8%AA/#_2","text":"先来看一个人体识别的基础应用，我们驱动相机后，实时采样视觉信息，然后再通过检测算法，识别每一幅图片中人体位置，并把识别的结果保存成一张图片，便于我们查看。","text_tokens":["基础","便于","先","实时","查看","视觉","一个","算法","，","把","然后","我们","相机","的","采样","。","识别","图片","再","并","结果","后","驱动","位置","每","成","检测","一幅","来看","人体","信息","保存","应用","通过","一张","中"],"title":"编程开发方法","title_tokens":["开发方法","编程","开发","方法"]},{"location":"hhp/5.6_%E4%BA%BA%E4%BD%93%E6%A3%80%E6%B5%8B%E4%B8%8E%E8%B7%9F%E8%B8%AA/#_3","text":"# 下载例程代码（与之前课程下载的代码一致） $ cd /userdata/dev_ws/src $ git clone https://gitee.com/guyuehome/togetherros_tutorials.git $ cd /userdata/dev_ws/ $ colcon build # 终端1，运行相机 $ source /opt/tros/setup.bash $ ros2 run mipi_cam mipi_cam --ros-args -p out_format: = nv12 -p image_width: = 960 -p image_height: = 544 -p video_device: = F37 # 终端2，运行例程 $ source /opt/tros/setup.bash $ source ./install/local_setup.bash $ mkdir -p config && cp -r /opt/tros/lib/dnn_node_example/config/multitask_body_kps_960x544.hbm config/ $ ros2 run cpp_dnn_demo cpp_dnn_demo --ros-args -p image: = config/test.jpg","text_tokens":[":","=","cp","local","，","userdata","2"," ","cpp","代码","run","-","video","nv12","tros",".","build","&&","kps","git","960x544","与","1","width","课程","device","install","clone","终端","dnn","colcon","之前","node","（","opt","togetherros","544","一致","#","jpg","config","例程","test","mipi","）","image","的","r","multitask","src","960","format","hbm","setup","ros2","example","--","demo","$","cam","/","out","_","ros","height","相机","下载","mkdir","ws","body","dev","gitee","com","f37","https","lib","args","tutorials","guyuehome","cd","运行","bash","source","p"],"title":"运行例程","title_tokens":["例程","运行"]},{"location":"hhp/5.6_%E4%BA%BA%E4%BD%93%E6%A3%80%E6%B5%8B%E4%B8%8E%E8%B7%9F%E8%B8%AA/#_4","text":"#include \"opencv2/core/mat.hpp\" #include \"opencv2/imgcodecs.hpp\" #include \"opencv2/imgproc.hpp\" #include \"dnn_node/dnn_node.h\" #include \"dnn_node/util/image_proc.h\" #include \"sensor_msgs/msg/image.hpp\" using namespace hobot :: dnn_node ; class BodyDetNode : public DnnNode { public : BodyDetNode ( const std :: string & node_name = \"body_det\" , const rclcpp :: NodeOptions & options = rclcpp :: NodeOptions ()) : DnnNode ( node_name , options ) { // 获取模型输入图片的尺寸，包括图片的宽model_input_width_和高model_input_height ，用于模型前处理 if ( Init () != 0 || GetModelInputSize ( 0 , model_input_width_ , model_input_height_ ) < 0 ) { RCLCPP_ERROR ( rclcpp :: get_logger ( \"example\" ), \"Node init fail!\" ); } //创建图片消息的subscriber，订阅的topic为”/image_raw”，消息类型为sensor_msgs::msg::Image。订阅到的图片用于算法模型推理 ros_img_subscription_ = this -> create_subscription < sensor_msgs :: msg :: Image > ( \"/image_raw\" , 10 , std :: bind ( & BodyDetNode :: FeedImg , this , std :: placeholders :: _1 )); } ~ BodyDetNode () override {} void FeedImg ( const sensor_msgs :: msg :: Image :: ConstSharedPtr msg ); protected : int SetNodePara () override { if ( ! dnn_node_para_ptr_ ) return -1 ; //指定模型推理使用的模型文件名和模型名 dnn_node_para_ptr_ -> model_file = \"config/multitask_body_kps_960x544.hbm\" ; dnn_node_para_ptr_ -> model_name = \"multitask_body_kps_960x544\" ; //指定模型输出的人体框的解析方法，其中人体框输出索引为box_output_index_ //使用的解析方法为hobot_dnn预定义的检测框解析方法FaceHandDetectionOutputParser。 std :: shared_ptr < OutputParser > box_out_parser = std :: make_shared < FaceHandDetectionOutputParser > (); dnn_node_para_ptr_ -> output_parsers_ . emplace_back ( std :: make_pair ( box_output_index_ , box_out_parser ) ); return 0 ; } int PostProcess ( const std :: shared_ptr < DnnNodeOutput > & node_output ) override ; private : int model_input_width_ = -1 ; int model_input_height_ = -1 ; const int32_t box_output_index_ = 1 ; sensor_msgs :: msg :: Image :: ConstSharedPtr img_msg_ ; rclcpp :: Subscription < sensor_msgs :: msg :: Image >:: ConstSharedPtr ros_img_subscription_ = nullptr ; }; //输出模型结果，并将结果渲染到图片后保存在本地 int BodyDetNode::PostProcess ( const std :: shared_ptr < DnnNodeOutput > & node_output ) { if ( node_output -> outputs . empty () || static_cast < int32_t > ( node_output -> outputs . size ()) < box_output_index_ ) { RCLCPP_ERROR ( rclcpp :: get_logger ( \"example\" ), \"Invalid outputs\" ); return -1 ; } auto * filter2d_result = dynamic_cast < Filter2DResult *> ( node_output -> outputs [ box_output_index_ ]. get ()); if ( ! filter2d_result ) return -1 ; std :: stringstream ss ; ss << \"img encoding: \" << img_msg_ -> encoding << \", stamp: \" << img_msg_ -> header . stamp . sec << \",\" << img_msg_ -> header . stamp . nanosec << \" \\n out box size: \" << filter2d_result -> boxes . size () << \" \\n \" ; cv :: Mat nv12 ( img_msg_ -> height * 3 / 2 , img_msg_ -> width , CV_8UC1 , const_cast < char *> ( reinterpret_cast < const char *> ( img_msg_ -> data . data ()))); cv :: Mat bgr ; cv :: cvtColor ( nv12 , bgr , CV_YUV2BGR_NV12 ); for ( auto & rect : filter2d_result -> boxes ) { ss << \"rect: \" << rect . left << \" \" << rect . top << \" \" << rect . right << \" \" << rect . bottom << \" \\n \" ; // 图片渲染 cv :: rectangle ( bgr , cv :: Point ( rect . left , rect . top ), cv :: Point ( rect . right , rect . bottom ), cv :: Scalar ( 255 , 0 , 0 ), 3 ); } std :: string result_image = \"render_\" + std :: to_string ( img_msg_ -> header . stamp . sec ) + \".\" + std :: to_string ( img_msg_ -> header . stamp . nanosec ) + \".jpg\" ; ss << \"Render img to file: \" << result_image ; RCLCPP_INFO ( rclcpp :: get_logger ( \"example\" ), \"%s\" , ss . str (). c_str ()); cv :: imwrite ( result_image , bgr ); return 0 ; } //将nv12格式的图片转成模型输入的数据类型DNNInput后，输入给推理任务 void BodyDetNode::FeedImg ( const sensor_msgs :: msg :: Image :: ConstSharedPtr img_msg ) { if ( ! img_msg ) return ; if ( \"nv12\" != img_msg -> encoding ) { RCLCPP_ERROR ( rclcpp :: get_logger ( \"example\" ), \"Only support nv12 img encoding!\" ); return ; } img_msg_ = img_msg ; // 创建模型输入数据 auto inputs = std :: vector < std :: shared_ptr < DNNInput >> { ImageProc :: GetNV12PyramidFromNV12Img ( reinterpret_cast < const char *> ( img_msg -> data . data ()), img_msg -> height , img_msg -> width , model_input_height_ , model_input_width_ )}; // 运行推理，DnnNode基类中定义并实现的启动推理接口。 Run ( inputs ); } int main ( int argc , char ** argv ) { rclcpp :: init ( argc , argv ); rclcpp :: spin ( std :: make_shared < BodyDetNode > ()); rclcpp :: shutdown (); return 0 ; }","text_tokens":["imgcodecs","stamp","尺寸","point","!",":","raw","=","invalid","reinterpret","core","获取","}","dynamic","cvtcolor","{","img","bind","定义","constsharedptr","文件名","to","前","，","dnnnode","static","(","file","解析","if","yuv2bgr",";","0","msgs","name","right","opencv2","protected","2","proc"," ","private","fail","|","run","宽","-","义","渲染","class","nv12","nullptr","feedimg","名","转","t","\"",".","create","parser","boxes","给","shared","using","订阅","h","kps","基类","输出",")","render","placeholders","包括","&","数据类型","960x544","for","return","width","1","高","nanosec","pair","。","图片","topic","inputs","int","top","imwrite","options","imgproc","后","[","dnninput","filter2dresult","\\","使用","std","dnn","result","dnnnodeoutput","void","人体","*","任务","sensor","parsers","保存","node","rect","中","setnodepara","nodeoptions","接口","方法","ptr","back","det","类型","#","get","推理","outputs","stringstream","jpg","config","其中","filter2d","info","main","rectangle","header","指定","image","getnv12pyramidfromnv12img","namespace","的","this","multitask","n","spin","int32","处理","vector","rclcpp","error","sec","char","argv","启动","结果","subscription","ss","hpp","<","消息",">","检测","hbm","将","util","postprocess","算法","cast","~","example","hobot","outputparser","mat","实现","data","shutdown","预定","+","imageproc","facehanddetectionoutputparser","size","override","msg","数据","input","/","para","out","model","在","_","模型","”","argc","ros","height","bgr","subscriber","到","和","getmodelinputsize","用于","本地","格式","输入","str","body","scalar","bodydetnode","%","8uc1","]","s",",","index","left","output","bottom","include","box","并","auto","3","make","string","support","为","const","255","成","public","创建","encoding","init","索引","logger","框","empty","文件","emplace","only","10","运行","cv","c"],"title":"代码解析","title_tokens":["解析","代码"]},{"location":"hhp/5.6_%E4%BA%BA%E4%BD%93%E6%A3%80%E6%B5%8B%E4%B8%8E%E8%B7%9F%E8%B8%AA/#_5","text":"结果保存成图片，虽然便于保留数据，但是不利于动态看到效果，我们不如再来实时动态效果显示。 在这个案例中，我们在之前人体识别的基础上，进一步实现了人体部位的识别和骨骼、眼神等关键点的识别，比如头、脸、身体、手掌、眼睛。 识别的结果同样是通过浏览器来进行查看。 # 启动webserver服务 $ cd /opt/tros/lib/websocket/webservice/ $ chmod +x ./sbin/nginx && ./sbin/nginx -p . # 运行例程 $ source /opt/tros/setup.bash $ cp -r /opt/tros/lib/mono2d_body_detection/config/ . $ ros2 launch /opt/tros/share/mono2d_body_detection/launch/hobot_mono2d_body_detection.launch.py","text_tokens":["基础","服务","mono2d","cp","不利于","不利","查看","不如","看到","sbin","进行","，","x","利于","浏览器","动态","识别"," ","这个","了","效果","-","身体","nginx","tros","通过",".","比如","&&","案例","关键","关键点","来","浏览","。","虽然","图片","再","同样","launch","之前","人体","detection","py","chmod","保存","中","opt","便于","websocket","share","#","config","例程","、","眼神","我们","的","r","但是","启动","结果","webserver","是","上","setup","ros2","保留","hobot","实现","等","$","头","+","实时","数据","/","在","_","部位","显示","眼睛","和","一步","骨骼","动态效果","body","webservice","成","进一步","lib","脸","cd","运行","bash","source","p","手掌"],"title":"人体检测与跟踪","title_tokens":["人体","检测","与","跟踪"]},{"location":"hhp/5.7_%E5%8D%95%E7%9B%AE3D%E5%AE%A4%E5%86%85%E6%A3%80%E6%B5%8B/","text":"单目3D室内检测 接下来，我们继续学习物体 3D 检测算法。 机器人有时候不仅仅要识别出人，还要识别出房间里有什么东西，这就是室内物体 3D 检测啦。 在TogetherROS上，就集成了这样一套算法，接下来让我们一起来体验以下吧。 先来看一张图片，很明显大家可以看到图中有两个垃圾桶。 运行示例程序 # 配置ROS2环境 $ source /opt/tros/setup.bash # 从tros的安装路径中拷贝出运行示例需要的配置文件。 $ cp -r /opt/tros/lib/mono3d_indoor_detection/config/ . # 启动launch文件 $ ros2 launch /opt/tros/share/mono3d_indoor_detection/launch/mono3d_indoor_detection.launch.py [ INFO ] [ 1654858490 .168592166 ] [ mono3d_detection ] : target type: trash_can [ INFO ] [ 1654858490 .168644750 ] [ mono3d_detection ] : target type: width, value: 236 .816406 [ INFO ] [ 1654858490 .168704333 ] [ mono3d_detection ] : target type: height, value: 305 .664062 [ INFO ] [ 1654858490 .168759584 ] [ mono3d_detection ] : target type: length, value: 224 .182129 [ INFO ] [ 1654858490 .168812334 ] [ mono3d_detection ] : target type: rotation, value: -1571.989179 [ INFO ] [ 1654858490 .168862543 ] [ mono3d_detection ] : target type: x, value: -191.977829 [ INFO ] [ 1654858490 .168916168 ] [ mono3d_detection ] : target type: y, value: -143.963307 [ INFO ] [ 1654858490 .168966502 ] [ mono3d_detection ] : target type: z, value: 714 .024127 [ INFO ] [ 1654858490 .169016794 ] [ mono3d_detection ] : target type: depth, value: 714 .024127 [ INFO ] [ 1654858490 .169067461 ] [ mono3d_detection ] : target type: score, value: 0 .973215 [ INFO ] [ 1654858490 .169168795 ] [ mono3d_detection ] : target type: trash_can [ INFO ] [ 1654858490 .169212837 ] [ mono3d_detection ] : target type: width, value: 253 .051758 [ INFO ] [ 1654858490 .169265004 ] [ mono3d_detection ] : target type: height, value: 282 .348633 [ INFO ] [ 1654858490 .169317046 ] [ mono3d_detection ] : target type: length, value: 257 .934570 [ INFO ] [ 1654858490 .169368921 ] [ mono3d_detection ] : target type: rotation, value: -1542.727947 [ INFO ] [ 1654858490 .169418671 ] [ mono3d_detection ] : target type: x, value: 552 .459776 [ INFO ] [ 1654858490 .169470588 ] [ mono3d_detection ] : target type: y, value: -164.073169 [ INFO ] [ 1654858490 .169517505 ] [ mono3d_detection ] : target type: z, value: 1088 .358164 [ INFO ] [ 1654858490 .169566839 ] [ mono3d_detection ] : target type: depth, value: 1088 .358164 [ INFO ] [ 1654858490 .169616464 ] [ mono3d_detection ] : target type: score, value: 0 .875521 很明显，已经识别到了两个垃圾桶。 代码解析 // Copyright (c) 2022，Horizon Robotics. // // Licensed under the Apache License, Version 2.0 (the \"License\"); // you may not use this file except in compliance with the License. // You may obtain a copy of the License at // // http://www.apache.org/licenses/LICENSE-2.0 // // Unless required by applicable law or agreed to in writing, software // distributed under the License is distributed on an \"AS IS\" BASIS, // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. // See the License for the specific language governing permissions and // limitations under the License. #include \"include/centernet_3d_detection_node.h\" #include <unistd.h> #include <fstream> #include <memory> #include <string> #include <vector> #include \"dnn_node/dnn_node.h\" #include \"include/image_utils.h\" #include \"rclcpp/rclcpp.hpp\" #include <sys/stat.h> #ifdef CV_BRIDGE_PKG_ENABLED #include <cv_bridge/cv_bridge.h> #endif using hobot :: easy_dnn :: OutputDescription ; using hobot :: easy_dnn :: OutputParser ; CenterNet3DDetectionNode :: CenterNet3DDetectionNode ( const std :: string & node_name , const NodeOptions & options ) : DnnNode ( node_name , options ), output_frameCount_ ( 0 ) { this -> declare_parameter < int > ( \"is_sync_mode\" , is_sync_mode_ ); this -> declare_parameter < std :: string > ( \"config_file_path\" , config_file_path_ ); this -> declare_parameter < int > ( \"shared_mem\" , shared_mem_ ); this -> declare_parameter < std :: string > ( \"ai_msg_pub_topic_name\" , msg_pub_topic_name_ ); this -> declare_parameter < std :: string > ( \"image_sub_topic_name\" , ros_img_topic_name_ ); this -> declare_parameter < std :: string > ( \"feed_image\" , feed_image_ ); this -> get_parameter < int > ( \"is_sync_mode\" , is_sync_mode_ ); this -> get_parameter < std :: string > ( \"config_file_path\" , config_file_path_ ); this -> get_parameter < int > ( \"shared_mem\" , shared_mem_ ); this -> get_parameter < std :: string > ( \"ai_msg_pub_topic_name\" , msg_pub_topic_name_ ); this -> get_parameter < std :: string > ( \"image_sub_topic_name\" , ros_img_topic_name_ ); this -> get_parameter < std :: string > ( \"feed_image\" , feed_image_ ); model_file_name_ = config_file_path_ + \"/centernet.hbm\" ; mkdir ( \"./result/\" , 666 ); std :: stringstream ss ; ss << \"Parameter:\" << \" \\n config_file_path_:\" << config_file_path_ << \" \\n shared_men:\" << shared_mem_ << \" \\n is_sync_mode_: \" << is_sync_mode_ << \" \\n model_file_name_: \" << model_file_name_ << \" \\n feed_image:\" << feed_image_ ; RCLCPP_WARN ( rclcpp :: get_logger ( \"mono3d_indoor_detection\" ), \"%s\" , ss . str (). c_str ()); if ( Start () == 0 ) { RCLCPP_WARN ( rclcpp :: get_logger ( \"mono3d_indoor_detection\" ), \"start success!!!\" ); } else { RCLCPP_ERROR ( rclcpp :: get_logger ( \"mono3d_indoor_detection\" ), \"start fail!!!\" ); } } CenterNet3DDetectionNode ::~ CenterNet3DDetectionNode () {} int CenterNet3DDetectionNode :: Start () { int ret = Init (); if ( ret != 0 ) { RCLCPP_ERROR ( rclcpp :: get_logger ( \"mono3d_indoor_detection\" ), \"Init failed!\" ); return ret ; } ret = GetModelInputSize ( 0 , model_input_width_ , model_input_height_ ); if ( ret < 0 ) { RCLCPP_ERROR ( rclcpp :: get_logger ( \"mono3d_indoor_detection\" ), \"Get model input size fail!\" ); return ret ; } RCLCPP_INFO ( rclcpp :: get_logger ( \"mono3d_indoor_detection\" ), \"The model input width is %d and height is %d\" , model_input_width_ , model_input_height_ ); msg_publisher_ = this -> create_publisher < ai_msgs :: msg :: PerceptionTargets > ( msg_pub_topic_name_ , 10 ); RCLCPP_INFO ( rclcpp :: get_logger ( \"mono3d_indoor_detection\" ), \"msg_pub_topic_name: %s\" , msg_pub_topic_name_ . data ()); if ( ! feed_image_ . empty ()) { std :: cout << \"mono3d read image:\" << feed_image_ << \" to detect\" << std :: endl ; PredictByImage ( feed_image_ ); return 0 ; } // RCLCPP_INFO ( rclcpp :: get_logger ( \"mono3d_indoor_detection\" ), \"Detect images that use subscriptions\" ); if ( shared_mem_ ) { #ifdef SHARED_MEM_ENABLED RCLCPP_WARN ( rclcpp :: get_logger ( \"mono3d_indoor_detection\" ), \"Create hbmem_subscription with topic_name: %s\" , sharedmem_img_topic_name_ . c_str ()); sharedmem_img_subscription_ = this -> create_subscription_hbmem < hbm_img_msgs :: msg :: HbmMsg1080P > ( sharedmem_img_topic_name_ , 10 , std :: bind ( & CenterNet3DDetectionNode :: SharedMemImgProcess , this , std :: placeholders :: _1 )); #else RCLCPP_ERROR ( rclcpp :: get_logger ( \"mono3d_indoor_detection\" ), \"Unsupport shared mem\" ); #endif } else { RCLCPP_WARN ( rclcpp :: get_logger ( \"mono3d_indoor_detection\" ), \"Create subscription with topic_name: %s\" , ros_img_topic_name_ . c_str ()); ros_img_subscription_ = this -> create_subscription < sensor_msgs :: msg :: Image > ( ros_img_topic_name_ , 10 , std :: bind ( & CenterNet3DDetectionNode :: RosImgProcess , this , std :: placeholders :: _1 )); } return 0 ; } int CenterNet3DDetectionNode :: SetNodePara () { RCLCPP_INFO ( rclcpp :: get_logger ( \"mono3d_indoor_detection\" ), \"Set node para.\" ); if ( ! dnn_node_para_ptr_ ) { return -1 ; } dnn_node_para_ptr_ -> model_file = model_file_name_ ; dnn_node_para_ptr_ -> model_name = model_name_ ; dnn_node_para_ptr_ -> model_task_type = model_task_type_ ; dnn_node_para_ptr_ -> task_num = 1 ; return 0 ; } int CenterNet3DDetectionNode :: SetOutputParser () { // set output parser auto model_manage = GetModel (); if ( ! model_manage || ! dnn_node_para_ptr_ ) { RCLCPP_ERROR ( rclcpp :: get_logger ( \"mono3d_indoor_detection\" ), \"Invalid model\" ); return -1 ; } if ( model_manage -> GetOutputCount () < model_output_count_ ) { RCLCPP_ERROR ( rclcpp :: get_logger ( \"mono3d_indoor_detection\" ), \"Error! Model %s output count is %d, unmatch with count %d\" , dnn_node_para_ptr_ -> model_name . c_str (), model_manage -> GetOutputCount (), model_output_count_ ); return -1 ; } for ( int i = 0 ; i < output_index_ ; ++ i ) { std :: shared_ptr < OutputParser > assist_parser = std :: make_shared < CenterNet3DAssistParser > (); model_manage -> SetOutputParser ( i , assist_parser ); } // set 3D paser auto output_desc = std :: make_shared < OutputDescription > ( model_manage , output_index_ , \"3D_branch\" ); for ( int i = 0 ; i < output_index_ ; ++ i ) { output_desc -> GetDependencies (). push_back ( i ); } output_desc -> SetType ( \"3D\" ); model_manage -> SetOutputDescription ( output_desc ); std :: shared_ptr < OutputParser > out_parser = std :: make_shared < CenterNet3DOutputParser > ( config_file_path_ ); model_manage -> SetOutputParser ( output_index_ , out_parser ); return 0 ; } #define CV_DRAW_LINE(p0, p1) \\ cv::line(image, cv::Point(points[p0][0], points[p0][1]), \\ cv::Point(points[p1][0], points[p1][1]), \\ CV_RGB(0, 255, 0), 2); #define CV_PUT_TEXT(text, px, py, offset) \\ { double fontScale = 3.0l; int thickness = 3u, baseline; \\ cv::Size text_size = cv::getTextSize(text, \\ cv::HersheyFonts::FONT_HERSHEY_PLAIN, fontScale, thickness, &baseline); \\ cv::Point point(px , py); \\ point.y += offset;\\ cv::Rect rect(point.x, point.y, \\ text_size.width, text_size.height); \\ point.y += text_size.height;\\ offset += text_size.height;\\ cv::putText(image, text, point, \\ cv::HersheyFonts::FONT_HERSHEY_PLAIN, \\ fontScale, CV_RGB(0, 255, 128), thickness); } void Render3DBox ( const BBox3D & box , cv :: Mat & image ) { auto & points = box . corners2d_upscale ; CV_DRAW_LINE ( 0 , 1 ) CV_DRAW_LINE ( 0 , 3 ) CV_DRAW_LINE ( 0 , 4 ) CV_DRAW_LINE ( 1 , 2 ) CV_DRAW_LINE ( 1 , 5 ) CV_DRAW_LINE ( 2 , 3 ) CV_DRAW_LINE ( 2 , 6 ) CV_DRAW_LINE ( 3 , 7 ) CV_DRAW_LINE ( 4 , 5 ) CV_DRAW_LINE ( 4 , 7 ) CV_DRAW_LINE ( 5 , 6 ) CV_DRAW_LINE ( 6 , 7 ) std :: string box_type = std :: to_string ( box . class_label ); std :: string score = std :: to_string ( box . score ); int offset = 0 ; if ( - M_PI_2 <= box . r || box . r <= M_PI_2 ) { CV_PUT_TEXT ( box_type , points [ 7 ][ 0 ], points [ 7 ][ 1 ], offset ); CV_PUT_TEXT ( score , points [ 7 ][ 0 ], points [ 7 ][ 1 ], offset ); } else { CV_PUT_TEXT ( box_type , points [ 6 ][ 0 ], points [ 6 ][ 1 ], offset ); CV_PUT_TEXT ( score , points [ 6 ][ 0 ], points [ 6 ][ 1 ], offset ); } } int CenterNet3DDetectionNode :: PostProcess ( const std :: shared_ptr < DnnNodeOutput > & node_output ) { if ( ! msg_publisher_ ) { RCLCPP_ERROR ( rclcpp :: get_logger ( \"example\" ), \"Invalid msg_publisher_\" ); return -1 ; } struct timespec time_start = { 0 , 0 }; clock_gettime ( CLOCK_REALTIME , & time_start ); ai_msgs :: msg :: Perf perf ; perf . set__type ( \"PostProcess\" ); perf . stamp_start . sec = time_start . tv_sec ; perf . stamp_start . nanosec = time_start . tv_nsec ; auto centernet_3d_output = std :: dynamic_pointer_cast < CenterNet3DOutput > ( node_output ); if ( centernet_3d_output ) { std :: stringstream ss ; ss << \"3D output dection info\" ; if ( centernet_3d_output -> image_msg_header_ ) { ss << \", frame_id: \" << centernet_3d_output -> image_msg_header_ -> frame_id << \", stamp: \" << centernet_3d_output -> image_msg_header_ -> stamp . sec << \".\" << centernet_3d_output -> image_msg_header_ -> stamp . nanosec ; } RCLCPP_DEBUG ( rclcpp :: get_logger ( \"mono3d_indoor_detection\" ), \"%s\" , ss . str (). c_str ()); } const auto & outputs = node_output -> outputs ; RCLCPP_DEBUG ( rclcpp :: get_logger ( \"mono3d_indoor_detection\" ), \"outputs size: %d\" , outputs . size ()); if ( outputs . empty () || static_cast < int32_t > ( outputs . size ()) < model_output_count_ ) { RCLCPP_ERROR ( rclcpp :: get_logger ( \"mono3d_indoor_detection\" ), \"Invalid outputs\" ); return -1 ; } int smart_fps = 0 ; { auto tp_now = std :: chrono :: system_clock :: now (); output_frameCount_ ++ ; auto interval = std :: chrono :: duration_cast < std :: chrono :: milliseconds > ( tp_now - output_tp_ ) . count (); if ( interval >= 1000 ) { smart_fps = output_frameCount_ ; RCLCPP_INFO ( rclcpp :: get_logger ( \"mono3d_indoor_detection\" ), \"Smart fps = %d\" , smart_fps ); output_frameCount_ = 0 ; output_tp_ = std :: chrono :: system_clock :: now (); } } ai_msgs :: msg :: PerceptionTargets :: UniquePtr pub_data ( new ai_msgs :: msg :: PerceptionTargets ()); if ( centernet_3d_output -> image_msg_header_ ) { pub_data -> header . set__stamp ( centernet_3d_output -> image_msg_header_ -> stamp ); pub_data -> header . set__frame_id ( centernet_3d_output -> image_msg_header_ -> frame_id ); } pub_data -> set__fps ( smart_fps ); auto * det_result = dynamic_cast < CenterNet3DDetResult *> ( outputs [ output_index_ ]. get ()); if ( ! det_result ) { RCLCPP_INFO ( rclcpp :: get_logger ( \"mono3d_indoor_detection\" ), \"invalid cast\" ); } else { RCLCPP_DEBUG ( rclcpp :: get_logger ( \"mono3d_indoor_detection\" ), \"out box size: %d\" , det_result -> boxes . size ()); std :: map < std :: string , ai_msgs :: msg :: Target > target_list ; std :: vector < ai_msgs :: msg :: Target > targets ; targets . reserve ( det_result -> boxes . size ()); for ( auto & box : det_result -> boxes ) { ai_msgs :: msg :: Target target ; switch ( box . class_label ) { case BBox3D :: CHARGING_BASE : target . type = \"charging_base\" ; break ; case BBox3D :: SLIPPER : target . type = \"slipper\" ; break ; case BBox3D :: TRASH_CAN : target . type = \"trash_can\" ; break ; } RCLCPP_INFO ( rclcpp :: get_logger ( \"mono3d_detection\" ), \"target type: %s\" , target . type . c_str ()); ai_msgs :: msg :: Attribute attribute ; ai_msgs :: msg :: Point point ; attribute . type = \"width\" ; attribute . value = box . w * 1000. ; RCLCPP_INFO ( rclcpp :: get_logger ( \"mono3d_detection\" ), \"target type: %s, value: %f\" , attribute . type . c_str (), attribute . value ); target . attributes . push_back ( attribute ); attribute . type = \"height\" ; attribute . value = box . h * 1000. ; RCLCPP_INFO ( rclcpp :: get_logger ( \"mono3d_detection\" ), \"target type: %s, value: %f\" , attribute . type . c_str (), attribute . value ); target . attributes . push_back ( attribute ); attribute . type = \"length\" ; attribute . value = box . l * 1000. ; RCLCPP_INFO ( rclcpp :: get_logger ( \"mono3d_detection\" ), \"target type: %s, value: %f\" , attribute . type . c_str (), attribute . value ); target . attributes . push_back ( attribute ); attribute . type = \"rotation\" ; attribute . value = box . r * 1000. ; RCLCPP_INFO ( rclcpp :: get_logger ( \"mono3d_detection\" ), \"target type: %s, value: %f\" , attribute . type . c_str (), attribute . value ); target . attributes . push_back ( attribute ); attribute . type = \"x\" ; attribute . value = box . x * 1000. ; RCLCPP_INFO ( rclcpp :: get_logger ( \"mono3d_detection\" ), \"target type: %s, value: %f\" , attribute . type . c_str (), attribute . value ); target . attributes . push_back ( attribute ); attribute . type = \"y\" ; attribute . value = box . y * 1000. ; RCLCPP_INFO ( rclcpp :: get_logger ( \"mono3d_detection\" ), \"target type: %s, value: %f\" , attribute . type . c_str (), attribute . value ); target . attributes . push_back ( attribute ); attribute . type = \"z\" ; attribute . value = box . z * 1000. ; RCLCPP_INFO ( rclcpp :: get_logger ( \"mono3d_detection\" ), \"target type: %s, value: %f\" , attribute . type . c_str (), attribute . value ); target . attributes . push_back ( attribute ); attribute . type = \"depth\" ; attribute . value = box . d * 1000. ; RCLCPP_INFO ( rclcpp :: get_logger ( \"mono3d_detection\" ), \"target type: %s, value: %f\" , attribute . type . c_str (), attribute . value ); target . attributes . push_back ( attribute ); attribute . type = \"score\" ; attribute . value = box . score * 1000. ; RCLCPP_INFO ( rclcpp :: get_logger ( \"mono3d_detection\" ), \"target type: %s, value: %f\" , attribute . type . c_str (), box . score ); target . attributes . push_back ( attribute ); // 8 corners /* 4----------5 6----------7 /| /| /| /| / | / | / | / | / | / | / | / | 7---|------6 |5---|------4 | | | | || | | | | | | || | | | | 0------|---1| 2------|---3 | / | / | / | / | / ^ | / | / v | / |/ |/ |/ |/ 3----------2 1----------0 */ for ( const auto & corners : box . corners2d_upscale ) { geometry_msgs :: msg :: Point32 g_point ; g_point . x = corners [ 0 ]; g_point . y = corners [ 1 ]; point . point . push_back ( g_point ); } point . type = \"corners\" ; target . points . push_back ( point ); targets . push_back ( target ); } pub_data -> targets = std :: move ( targets ); if ( ! centernet_3d_output -> image_name_ . empty ()) { auto img_bgr = cv :: imread ( centernet_3d_output -> image_name_ ); for ( auto & box : det_result -> boxes ) { Render3DBox ( box , img_bgr ); } std :: string :: size_type iPos = centernet_3d_output -> image_name_ . find_last_of ( '/' ) + 1 ; std :: string filename = centernet_3d_output -> image_name_ . substr ( iPos , centernet_3d_output -> image_name_ . length () - iPos ); cv :: imwrite ( \"./result/\" + filename , img_bgr ); } } clock_gettime ( CLOCK_REALTIME , & time_start ); perf . stamp_end . sec = time_start . tv_sec ; perf . stamp_end . nanosec = time_start . tv_nsec ; pub_data -> perfs . emplace_back ( perf ); msg_publisher_ -> publish ( std :: move ( pub_data )); return 0 ; } int CenterNet3DDetectionNode :: Predict ( std :: vector < std :: shared_ptr < DNNInput >> & inputs , const std :: shared_ptr < std :: vector < hbDNNRoi >> rois , std :: shared_ptr < DnnNodeOutput > dnn_output ) { return Run ( inputs , dnn_output , rois , is_sync_mode_ == 1 ); } void CenterNet3DDetectionNode :: RosImgProcess ( const sensor_msgs :: msg :: Image :: ConstSharedPtr img_msg ) { if ( ! img_msg || ! rclcpp :: ok ()) { return ; } std :: stringstream ss ; ss << \"Recved img encoding: \" << img_msg -> encoding << \", h: \" << img_msg -> height << \", w: \" << img_msg -> width << \", step: \" << img_msg -> step << \", frame_id: \" << img_msg -> header . frame_id << \", stamp: \" << img_msg -> header . stamp . sec << \".\" << img_msg -> header . stamp . nanosec << \", data size: \" << img_msg -> data . size (); RCLCPP_INFO ( rclcpp :: get_logger ( \"mono3d_indoor_detection\" ), \"%s\" , ss . str (). c_str ()); auto tp_start = std :: chrono :: system_clock :: now (); // 1. 将图片处理成模型输入数据类型DNNInput // 使用图片生成pym，NV12PyramidInput为DNNInput的子类 std :: shared_ptr < hobot :: easy_dnn :: NV12PyramidInput > pyramid = nullptr ; if ( \"rgb8\" == img_msg -> encoding ) { #ifdef CV_BRIDGE_PKG_ENABLED auto cv_img = cv_bridge :: cvtColorForDisplay ( cv_bridge :: toCvShare ( img_msg ), \"bgr8\" ); { auto tp_now = std :: chrono :: system_clock :: now (); auto interval = std :: chrono :: duration_cast < std :: chrono :: milliseconds > ( tp_now - tp_start ) . count (); RCLCPP_DEBUG ( rclcpp :: get_logger ( \"mono3d_indoor_detection\" ), \"after cvtColorForDisplay cost ms: %d\" , interval ); } pyramid = ImageUtils :: GetNV12Pyramid ( cv_img -> image , model_input_height_ , model_input_width_ ); #else RCLCPP_ERROR ( rclcpp :: get_logger ( \"mono3d_indoor_detection\" ), \"Unsupport cv bridge\" ); #endif } else if ( \"nv12\" == img_msg -> encoding ) { pyramid = ImageUtils :: GetNV12PyramidFromNV12Img ( reinterpret_cast < const char *> ( img_msg -> data . data ()), img_msg -> height , img_msg -> width , model_input_height_ , model_input_width_ ); } if ( ! pyramid ) { RCLCPP_ERROR ( rclcpp :: get_logger ( \"mono3d_indoor_detection\" ), \"Get Nv12 pym fail\" ); return ; } { auto tp_now = std :: chrono :: system_clock :: now (); auto interval = std :: chrono :: duration_cast < std :: chrono :: milliseconds > ( tp_now - tp_start ) . count (); RCLCPP_DEBUG ( rclcpp :: get_logger ( \"mono3d_indoor_detection\" ), \"after GetNV12Pyramid cost ms: %d\" , interval ); } RCLCPP_INFO ( rclcpp :: get_logger ( \"mono3d_indoor_detection\" ), \"Dnn node begin to predict\" ); // 2. 使用pyramid创建DNNInput对象inputs // inputs将会作为模型的输入通过RunInferTask接口传入 auto inputs = std :: vector < std :: shared_ptr < DNNInput >> { pyramid }; auto dnn_output = std :: make_shared < CenterNet3DOutput > (); dnn_output -> src_img_width_ = img_msg -> width ; dnn_output -> src_img_height_ = img_msg -> height ; dnn_output -> image_msg_header_ = std :: make_shared < std_msgs :: msg :: Header > (); dnn_output -> image_msg_header_ -> set__frame_id ( img_msg -> header . frame_id ); dnn_output -> image_msg_header_ -> set__stamp ( img_msg -> header . stamp ); dnn_output -> image_name_ = \"\" ; // 3. 开始预测 uint32_t ret = Predict ( inputs , nullptr , dnn_output ); { auto tp_now = std :: chrono :: system_clock :: now (); auto interval = std :: chrono :: duration_cast < std :: chrono :: milliseconds > ( tp_now - tp_start ) . count (); RCLCPP_DEBUG ( rclcpp :: get_logger ( \"mono3d_indoor_detection\" ), \"after Predict cost ms: %d\" , interval ); } if ( ret != 0 ) { RCLCPP_ERROR ( rclcpp :: get_logger ( \"mono3d_indoor_detection\" ), \"predict img failed!\" ); } return ; } int CenterNet3DDetectionNode :: PredictByImage ( const std :: string & image ) { // 1. 将图片处理成模型输入数据类型DNNInput // 使用图片生成pym，NV12PyramidInput为DNNInput的子类 std :: shared_ptr < hobot :: easy_dnn :: NV12PyramidInput > pyramid = nullptr ; // bgr img，支持将图片resize到模型输入size pyramid = ImageUtils :: GetNV12Pyramid ( image , ImageType :: BGR , model_input_height_ , model_input_width_ ); if ( ! pyramid ) { RCLCPP_ERROR ( rclcpp :: get_logger ( \"mono3d_indoor_detection\" ), \"Get Nv12 pym fail with image: %s\" , image . c_str ()); return -1 ; } // 2. 使用pyramid创建DNNInput对象inputs // inputs将会作为模型的输入通过RunInferTask接口传入 auto inputs = std :: vector < std :: shared_ptr < DNNInput >> { pyramid }; auto dnn_output = std :: make_shared < CenterNet3DOutput > (); dnn_output -> src_img_width_ = 1920 ; dnn_output -> src_img_height_ = 1024 ; dnn_output -> image_msg_header_ = std :: make_shared < std_msgs :: msg :: Header > (); dnn_output -> image_msg_header_ -> set__frame_id ( \"test_frame\" ); dnn_output -> image_msg_header_ -> set__stamp ( rclcpp :: Time ()); dnn_output -> image_name_ = image ; // dnn_output->image_msg_header->set__frame_id(std::to_string(img_msg->index)); // dnn_output->image_msg_header->set__stamp(img_msg->time_stamp); // 3. 开始预测 uint32_t ret = Predict ( inputs , nullptr , dnn_output ); if ( ret != 0 ) { RCLCPP_ERROR ( rclcpp :: get_logger ( \"mono3d_indoor_detection\" ), \"predict img failed!\" ); } return ret ; } #ifdef SHARED_MEM_ENABLED void CenterNet3DDetectionNode :: SharedMemImgProcess ( const hbm_img_msgs :: msg :: HbmMsg1080P :: ConstSharedPtr img_msg ) { if ( ! img_msg || ! rclcpp :: ok ()) { return ; } RCLCPP_DEBUG ( rclcpp :: get_logger ( \"mono3d_indoor_detection\" ), \"go into shared mem\" ); // dump recved img msg // std::ofstream ofs(\"img_\" + std::to_string(img_msg->index) + \".\" + // std::string(reinterpret_cast<const char*>(img_msg->encoding.data()))); // ofs.write(reinterpret_cast<const char*>(img_msg->data.data()), // img_msg->data_size); auto tp_start = std :: chrono :: system_clock :: now (); // 1. 将图片处理成模型输入数据类型DNNInput // 使用图片生成pym，NV12PyramidInput为DNNInput的子类 std :: shared_ptr < hobot :: easy_dnn :: NV12PyramidInput > pyramid = nullptr ; if ( \"nv12\" == std :: string ( reinterpret_cast < const char *> ( img_msg -> encoding . data ()))) { pyramid = ImageUtils :: GetNV12PyramidFromNV12Img ( reinterpret_cast < const char *> ( img_msg -> data . data ()), img_msg -> height , img_msg -> width , model_input_height_ , model_input_width_ ); } else { RCLCPP_INFO ( rclcpp :: get_logger ( \"mono3d_indoor_detection\" ), \"share mem unsupported img encoding: %s\" , img_msg -> encoding ); } if ( ! pyramid ) { RCLCPP_ERROR ( rclcpp :: get_logger ( \"mono3d_indoor_detection\" ), \"Get Nv12 pym fail!\" ); return ; } { auto tp_now = std :: chrono :: system_clock :: now (); auto interval = std :: chrono :: duration_cast < std :: chrono :: milliseconds > ( tp_now - tp_start ) . count (); RCLCPP_DEBUG ( rclcpp :: get_logger ( \"mono3d_indoor_detection\" ), \"after GetNV12Pyramid cost ms: %d\" , interval ); } // 2. 使用pyramid创建DNNInput对象inputs // inputs将会作为模型的输入通过RunInferTask接口传入 auto inputs = std :: vector < std :: shared_ptr < DNNInput >> { pyramid }; auto dnn_output = std :: make_shared < CenterNet3DOutput > (); dnn_output -> src_img_width_ = img_msg -> width ; dnn_output -> src_img_height_ = img_msg -> height ; dnn_output -> image_msg_header_ = std :: make_shared < std_msgs :: msg :: Header > (); dnn_output -> image_msg_header_ -> set__frame_id ( std :: to_string ( img_msg -> index )); dnn_output -> image_msg_header_ -> set__stamp ( img_msg -> time_stamp ); // 3. 开始预测 int ret = Predict ( inputs , nullptr , dnn_output ); { auto tp_now = std :: chrono :: system_clock :: now (); auto interval = std :: chrono :: duration_cast < std :: chrono :: milliseconds > ( tp_now - tp_start ) . count (); RCLCPP_DEBUG ( rclcpp :: get_logger ( \"mono3d_indoor_detection\" ), \"after Predict cost ms: %d\" , interval ); } // 4. 处理预测结果，如渲染到图片或者发布预测结果 if ( ret != 0 ) { RCLCPP_ERROR ( rclcpp :: get_logger ( \"mono3d_indoor_detection\" ), \"Run predict failed!\" ); } return ; } #endif","text_tokens":["copyright","169067461","settype","frame","里","bind","就","constsharedptr","put","setoutputdescription","，","static","conditions","msgs","predict","识别","parameter","break","unless","distributed","拷贝","language","under","|","declare","governing","class","nv12","nullptr","通过","3.0","create","boxes","安装","pkg","d","ai","go","h","2.0","不仅","by","1542.727947","p0","imageutils","dection","282","milliseconds","step","topic","move","license","attribute","生成","i","[","dnninput","\\","使用","024127","dump","吧","struct","detection","charging","一张","中","time","fstream","什么","973215","w","ipos","rois","stringstream","centernet3doutputparser","ofstream","可以","169368921","image","manage","如","r","n","sys","sec","src","not","in","路径","subscription","compliance","两个","169265004","and","~","example","render3dbox","169168795","setoutputparser","$","+","l","mem","cout","corners2d","out","http","666","模型","很","168812334","define","attributes","height","imagetype","5","getmodelinputsize","室内","1088","last","]","draw","物体","include","box","cvtcolorfordisplay","sub","__","'","const","ret","---","成","pym","robotics","接下","paser","继续","law","encoding","init","obtain","文件","不仅仅","emplace","path","source","depth","push","168704333","stamp","358164","3d","=","invalid","may","nv12pyramidinput","bbox3d","to","unsupport","rgb8","(","sync","perf","is","smart","branch","明显","warranties","endl","count","2","licenses","font","applicable","了","task","as","getmodel","代码","pyramid","of","渲染","来看","express","getnv12pyramid","这样",".","\"","using","limitations","unsupported","org","hbmem","ok","168759584","without","width","1","switch","1920","nanosec","substr","配置","182129","system","。","text","uint32","图片","sharedmemimgprocess","options","base","stat","dnn","dnnnodeoutput","horizon","void","py","map","sensor","714","utils","学习","unistd","timespec","licensed","opt","253","centernet","y","起来","share","出人","ptr","一套","implied","类型","assist","info","config","test","either","interval","success","------","int32","体验","启动","结果","indoor","++","mono3d","find","集成","168592166","fps","检测","perceptiontargets","将","接下来","postprocess","8","164.073169","value","算法","use","writing","cast","hobot","sharedmem","g","label","/","input","下来","case","预测","_","list","啦","816406","到","hersheyfonts","desc","已经","runinfertask","str","要","%","s","index","单目","imread","3","string","offset","at","10","specific","feed","or","read","224","point","143.963307","168966502","!",":","reinterpret","dynamic","except","}","targets","{","看到","875521","unmatch","perfs","p1","hbmmsg1080p","从","dnnnode","file","rotation","if","0",";","name","uniqueptr","puttext","framecount","出","detect","px","发布","an","fail","run","nsec","552","对象","环境","168862543","t","开始","传入","pub","7","permissions","ms","程序","resize","www",")","placeholders","thickness","&","write","centernet3doutput","数据类型","169616464","459776","for","return","机器人","就是","upscale","pointer","让","inputs","int","outputdescription","publisher","f","ofs","垃圾桶","result","169470588","*","begin","node","rect","togetherros","required","6","nodeoptions","接口","basis","plain","back","#","get","line","subscriptions","一","reserve","664062","getnv12pyramidfromnv12img","还要","easy","169517505","this","处理","rclcpp","char","128","<","hpp",">","men","上","setup","1571.989179","hbdnnroi","mode","mat","data","大家","getdependencies","size","msg","数据","that","model","ros","输入","output","gettextsize","tocvshare","255","getoutputcount","z","new","you","有时","duration","logger","memory","any","empty","支持","运行","bash","169566839","cv","c","v","on","bgr8","publish","169317046","cp","after","version","software","img","into","tv","clock","机器","else","id","x","解析","centernet3ddetectionnode","m","kind"," ","type","centernet3ddetresult","agreed","169212837","东西","以下","-","trash","rgb","double","chrono","051758","tros","有时候","房间","parser","示例","failed","shared","先","end","191.977829","配置文件","point32","这","copy","num","target","can","fontscale","1654858490","a","baseline","子类","hershey","imwrite","305","launch","images","257","tp","endif","enabled","centernet3dassistparser","std","垃圾","236","----------","gettime","bridge","setnodepara","ifdef","corners","filename","图中","cost","debug","时候","see","slipper","det","rosimgprocess","outputs","score","header","geometry","我们","934570","pi","的","vector","error","warn","2022","ss","points","hbm","169016794","ros2","348633","outputparser","169418671","predictbyimage","para","在","set","the","bgr","now","仅仅","apache","1000","recved","作为","mkdir","3u",",","auto","make","为","或者","length","^","lib","创建","start","将会","有","168644750","realtime","168916168","1024","需要","with","4"],"title":"单目3D室内检测","title_tokens":["单目","检测","室内","3d"]},{"location":"hhp/5.7_%E5%8D%95%E7%9B%AE3D%E5%AE%A4%E5%86%85%E6%A3%80%E6%B5%8B/#3d","text":"接下来，我们继续学习物体 3D 检测算法。 机器人有时候不仅仅要识别出人，还要识别出房间里有什么东西，这就是室内物体 3D 检测啦。 在TogetherROS上，就集成了这样一套算法，接下来让我们一起来体验以下吧。 先来看一张图片，很明显大家可以看到图中有两个垃圾桶。","text_tokens":["有时候","房间","togetherros","大家","先","这样","起来","3d","什么","出人","图中","不仅","时候","下来","一套","在","里","这","很","就","看到","一","啦","仅仅","机器人","，","机器","就是","可以","我们","还要","室内","要","。","体验","物体","明显","识别","让","图片","出"," ","集成","垃圾桶","了","垃圾","接下","检测","上","继续","有","东西","接下来","有时","以下","来看","吧","两个","不仅仅","算法","一张","学习"],"title":"单目3D室内检测","title_tokens":["单目","检测","室内","3d"]},{"location":"hhp/5.7_%E5%8D%95%E7%9B%AE3D%E5%AE%A4%E5%86%85%E6%A3%80%E6%B5%8B/#_1","text":"# 配置ROS2环境 $ source /opt/tros/setup.bash # 从tros的安装路径中拷贝出运行示例需要的配置文件。 $ cp -r /opt/tros/lib/mono3d_indoor_detection/config/ . # 启动launch文件 $ ros2 launch /opt/tros/share/mono3d_indoor_detection/launch/mono3d_indoor_detection.launch.py [ INFO ] [ 1654858490 .168592166 ] [ mono3d_detection ] : target type: trash_can [ INFO ] [ 1654858490 .168644750 ] [ mono3d_detection ] : target type: width, value: 236 .816406 [ INFO ] [ 1654858490 .168704333 ] [ mono3d_detection ] : target type: height, value: 305 .664062 [ INFO ] [ 1654858490 .168759584 ] [ mono3d_detection ] : target type: length, value: 224 .182129 [ INFO ] [ 1654858490 .168812334 ] [ mono3d_detection ] : target type: rotation, value: -1571.989179 [ INFO ] [ 1654858490 .168862543 ] [ mono3d_detection ] : target type: x, value: -191.977829 [ INFO ] [ 1654858490 .168916168 ] [ mono3d_detection ] : target type: y, value: -143.963307 [ INFO ] [ 1654858490 .168966502 ] [ mono3d_detection ] : target type: z, value: 714 .024127 [ INFO ] [ 1654858490 .169016794 ] [ mono3d_detection ] : target type: depth, value: 714 .024127 [ INFO ] [ 1654858490 .169067461 ] [ mono3d_detection ] : target type: score, value: 0 .973215 [ INFO ] [ 1654858490 .169168795 ] [ mono3d_detection ] : target type: trash_can [ INFO ] [ 1654858490 .169212837 ] [ mono3d_detection ] : target type: width, value: 253 .051758 [ INFO ] [ 1654858490 .169265004 ] [ mono3d_detection ] : target type: height, value: 282 .348633 [ INFO ] [ 1654858490 .169317046 ] [ mono3d_detection ] : target type: length, value: 257 .934570 [ INFO ] [ 1654858490 .169368921 ] [ mono3d_detection ] : target type: rotation, value: -1542.727947 [ INFO ] [ 1654858490 .169418671 ] [ mono3d_detection ] : target type: x, value: 552 .459776 [ INFO ] [ 1654858490 .169470588 ] [ mono3d_detection ] : target type: y, value: -164.073169 [ INFO ] [ 1654858490 .169517505 ] [ mono3d_detection ] : target type: z, value: 1088 .358164 [ INFO ] [ 1654858490 .169566839 ] [ mono3d_detection ] : target type: depth, value: 1088 .358164 [ INFO ] [ 1654858490 .169616464 ] [ mono3d_detection ] : target type: score, value: 0 .875521 很明显，已经识别到了两个垃圾桶。","text_tokens":["169067461","224","358164","143.963307","168966502",":","169317046","cp","875521","从","，","x","rotation","0","明显","识别","出"," ","type","拷贝","了","169212837","trash","-","552","环境","051758","tros","168862543",".","示例","安装","191.977829","配置文件","1542.727947","168759584","169616464","459776","282","target","width","can","配置","182129","。","1654858490","305","launch","257","[","垃圾桶","236","024127","垃圾","detection","py","169470588","714","中","opt","253","y","share","973215","#","score","info","config","169368921","664062","934570","的","r","169517505","启动","路径","indoor","mono3d","168592166","1571.989179","setup","两个","169016794","ros2","169265004","164.073169","value","348633","169168795","$","169418671","/","_","168812334","很","height","816406","到","已经","1088","]",",","length","lib","z","168644750","文件","168916168","运行","bash","需要","source","depth","169566839","168704333"],"title":"运行示例程序","title_tokens":["运行","示例","程序"]},{"location":"hhp/5.7_%E5%8D%95%E7%9B%AE3D%E5%AE%A4%E5%86%85%E6%A3%80%E6%B5%8B/#_2","text":"// Copyright (c) 2022，Horizon Robotics. // // Licensed under the Apache License, Version 2.0 (the \"License\"); // you may not use this file except in compliance with the License. // You may obtain a copy of the License at // // http://www.apache.org/licenses/LICENSE-2.0 // // Unless required by applicable law or agreed to in writing, software // distributed under the License is distributed on an \"AS IS\" BASIS, // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. // See the License for the specific language governing permissions and // limitations under the License. #include \"include/centernet_3d_detection_node.h\" #include <unistd.h> #include <fstream> #include <memory> #include <string> #include <vector> #include \"dnn_node/dnn_node.h\" #include \"include/image_utils.h\" #include \"rclcpp/rclcpp.hpp\" #include <sys/stat.h> #ifdef CV_BRIDGE_PKG_ENABLED #include <cv_bridge/cv_bridge.h> #endif using hobot :: easy_dnn :: OutputDescription ; using hobot :: easy_dnn :: OutputParser ; CenterNet3DDetectionNode :: CenterNet3DDetectionNode ( const std :: string & node_name , const NodeOptions & options ) : DnnNode ( node_name , options ), output_frameCount_ ( 0 ) { this -> declare_parameter < int > ( \"is_sync_mode\" , is_sync_mode_ ); this -> declare_parameter < std :: string > ( \"config_file_path\" , config_file_path_ ); this -> declare_parameter < int > ( \"shared_mem\" , shared_mem_ ); this -> declare_parameter < std :: string > ( \"ai_msg_pub_topic_name\" , msg_pub_topic_name_ ); this -> declare_parameter < std :: string > ( \"image_sub_topic_name\" , ros_img_topic_name_ ); this -> declare_parameter < std :: string > ( \"feed_image\" , feed_image_ ); this -> get_parameter < int > ( \"is_sync_mode\" , is_sync_mode_ ); this -> get_parameter < std :: string > ( \"config_file_path\" , config_file_path_ ); this -> get_parameter < int > ( \"shared_mem\" , shared_mem_ ); this -> get_parameter < std :: string > ( \"ai_msg_pub_topic_name\" , msg_pub_topic_name_ ); this -> get_parameter < std :: string > ( \"image_sub_topic_name\" , ros_img_topic_name_ ); this -> get_parameter < std :: string > ( \"feed_image\" , feed_image_ ); model_file_name_ = config_file_path_ + \"/centernet.hbm\" ; mkdir ( \"./result/\" , 666 ); std :: stringstream ss ; ss << \"Parameter:\" << \" \\n config_file_path_:\" << config_file_path_ << \" \\n shared_men:\" << shared_mem_ << \" \\n is_sync_mode_: \" << is_sync_mode_ << \" \\n model_file_name_: \" << model_file_name_ << \" \\n feed_image:\" << feed_image_ ; RCLCPP_WARN ( rclcpp :: get_logger ( \"mono3d_indoor_detection\" ), \"%s\" , ss . str (). c_str ()); if ( Start () == 0 ) { RCLCPP_WARN ( rclcpp :: get_logger ( \"mono3d_indoor_detection\" ), \"start success!!!\" ); } else { RCLCPP_ERROR ( rclcpp :: get_logger ( \"mono3d_indoor_detection\" ), \"start fail!!!\" ); } } CenterNet3DDetectionNode ::~ CenterNet3DDetectionNode () {} int CenterNet3DDetectionNode :: Start () { int ret = Init (); if ( ret != 0 ) { RCLCPP_ERROR ( rclcpp :: get_logger ( \"mono3d_indoor_detection\" ), \"Init failed!\" ); return ret ; } ret = GetModelInputSize ( 0 , model_input_width_ , model_input_height_ ); if ( ret < 0 ) { RCLCPP_ERROR ( rclcpp :: get_logger ( \"mono3d_indoor_detection\" ), \"Get model input size fail!\" ); return ret ; } RCLCPP_INFO ( rclcpp :: get_logger ( \"mono3d_indoor_detection\" ), \"The model input width is %d and height is %d\" , model_input_width_ , model_input_height_ ); msg_publisher_ = this -> create_publisher < ai_msgs :: msg :: PerceptionTargets > ( msg_pub_topic_name_ , 10 ); RCLCPP_INFO ( rclcpp :: get_logger ( \"mono3d_indoor_detection\" ), \"msg_pub_topic_name: %s\" , msg_pub_topic_name_ . data ()); if ( ! feed_image_ . empty ()) { std :: cout << \"mono3d read image:\" << feed_image_ << \" to detect\" << std :: endl ; PredictByImage ( feed_image_ ); return 0 ; } // RCLCPP_INFO ( rclcpp :: get_logger ( \"mono3d_indoor_detection\" ), \"Detect images that use subscriptions\" ); if ( shared_mem_ ) { #ifdef SHARED_MEM_ENABLED RCLCPP_WARN ( rclcpp :: get_logger ( \"mono3d_indoor_detection\" ), \"Create hbmem_subscription with topic_name: %s\" , sharedmem_img_topic_name_ . c_str ()); sharedmem_img_subscription_ = this -> create_subscription_hbmem < hbm_img_msgs :: msg :: HbmMsg1080P > ( sharedmem_img_topic_name_ , 10 , std :: bind ( & CenterNet3DDetectionNode :: SharedMemImgProcess , this , std :: placeholders :: _1 )); #else RCLCPP_ERROR ( rclcpp :: get_logger ( \"mono3d_indoor_detection\" ), \"Unsupport shared mem\" ); #endif } else { RCLCPP_WARN ( rclcpp :: get_logger ( \"mono3d_indoor_detection\" ), \"Create subscription with topic_name: %s\" , ros_img_topic_name_ . c_str ()); ros_img_subscription_ = this -> create_subscription < sensor_msgs :: msg :: Image > ( ros_img_topic_name_ , 10 , std :: bind ( & CenterNet3DDetectionNode :: RosImgProcess , this , std :: placeholders :: _1 )); } return 0 ; } int CenterNet3DDetectionNode :: SetNodePara () { RCLCPP_INFO ( rclcpp :: get_logger ( \"mono3d_indoor_detection\" ), \"Set node para.\" ); if ( ! dnn_node_para_ptr_ ) { return -1 ; } dnn_node_para_ptr_ -> model_file = model_file_name_ ; dnn_node_para_ptr_ -> model_name = model_name_ ; dnn_node_para_ptr_ -> model_task_type = model_task_type_ ; dnn_node_para_ptr_ -> task_num = 1 ; return 0 ; } int CenterNet3DDetectionNode :: SetOutputParser () { // set output parser auto model_manage = GetModel (); if ( ! model_manage || ! dnn_node_para_ptr_ ) { RCLCPP_ERROR ( rclcpp :: get_logger ( \"mono3d_indoor_detection\" ), \"Invalid model\" ); return -1 ; } if ( model_manage -> GetOutputCount () < model_output_count_ ) { RCLCPP_ERROR ( rclcpp :: get_logger ( \"mono3d_indoor_detection\" ), \"Error! Model %s output count is %d, unmatch with count %d\" , dnn_node_para_ptr_ -> model_name . c_str (), model_manage -> GetOutputCount (), model_output_count_ ); return -1 ; } for ( int i = 0 ; i < output_index_ ; ++ i ) { std :: shared_ptr < OutputParser > assist_parser = std :: make_shared < CenterNet3DAssistParser > (); model_manage -> SetOutputParser ( i , assist_parser ); } // set 3D paser auto output_desc = std :: make_shared < OutputDescription > ( model_manage , output_index_ , \"3D_branch\" ); for ( int i = 0 ; i < output_index_ ; ++ i ) { output_desc -> GetDependencies (). push_back ( i ); } output_desc -> SetType ( \"3D\" ); model_manage -> SetOutputDescription ( output_desc ); std :: shared_ptr < OutputParser > out_parser = std :: make_shared < CenterNet3DOutputParser > ( config_file_path_ ); model_manage -> SetOutputParser ( output_index_ , out_parser ); return 0 ; } #define CV_DRAW_LINE(p0, p1) \\ cv::line(image, cv::Point(points[p0][0], points[p0][1]), \\ cv::Point(points[p1][0], points[p1][1]), \\ CV_RGB(0, 255, 0), 2); #define CV_PUT_TEXT(text, px, py, offset) \\ { double fontScale = 3.0l; int thickness = 3u, baseline; \\ cv::Size text_size = cv::getTextSize(text, \\ cv::HersheyFonts::FONT_HERSHEY_PLAIN, fontScale, thickness, &baseline); \\ cv::Point point(px , py); \\ point.y += offset;\\ cv::Rect rect(point.x, point.y, \\ text_size.width, text_size.height); \\ point.y += text_size.height;\\ offset += text_size.height;\\ cv::putText(image, text, point, \\ cv::HersheyFonts::FONT_HERSHEY_PLAIN, \\ fontScale, CV_RGB(0, 255, 128), thickness); } void Render3DBox ( const BBox3D & box , cv :: Mat & image ) { auto & points = box . corners2d_upscale ; CV_DRAW_LINE ( 0 , 1 ) CV_DRAW_LINE ( 0 , 3 ) CV_DRAW_LINE ( 0 , 4 ) CV_DRAW_LINE ( 1 , 2 ) CV_DRAW_LINE ( 1 , 5 ) CV_DRAW_LINE ( 2 , 3 ) CV_DRAW_LINE ( 2 , 6 ) CV_DRAW_LINE ( 3 , 7 ) CV_DRAW_LINE ( 4 , 5 ) CV_DRAW_LINE ( 4 , 7 ) CV_DRAW_LINE ( 5 , 6 ) CV_DRAW_LINE ( 6 , 7 ) std :: string box_type = std :: to_string ( box . class_label ); std :: string score = std :: to_string ( box . score ); int offset = 0 ; if ( - M_PI_2 <= box . r || box . r <= M_PI_2 ) { CV_PUT_TEXT ( box_type , points [ 7 ][ 0 ], points [ 7 ][ 1 ], offset ); CV_PUT_TEXT ( score , points [ 7 ][ 0 ], points [ 7 ][ 1 ], offset ); } else { CV_PUT_TEXT ( box_type , points [ 6 ][ 0 ], points [ 6 ][ 1 ], offset ); CV_PUT_TEXT ( score , points [ 6 ][ 0 ], points [ 6 ][ 1 ], offset ); } } int CenterNet3DDetectionNode :: PostProcess ( const std :: shared_ptr < DnnNodeOutput > & node_output ) { if ( ! msg_publisher_ ) { RCLCPP_ERROR ( rclcpp :: get_logger ( \"example\" ), \"Invalid msg_publisher_\" ); return -1 ; } struct timespec time_start = { 0 , 0 }; clock_gettime ( CLOCK_REALTIME , & time_start ); ai_msgs :: msg :: Perf perf ; perf . set__type ( \"PostProcess\" ); perf . stamp_start . sec = time_start . tv_sec ; perf . stamp_start . nanosec = time_start . tv_nsec ; auto centernet_3d_output = std :: dynamic_pointer_cast < CenterNet3DOutput > ( node_output ); if ( centernet_3d_output ) { std :: stringstream ss ; ss << \"3D output dection info\" ; if ( centernet_3d_output -> image_msg_header_ ) { ss << \", frame_id: \" << centernet_3d_output -> image_msg_header_ -> frame_id << \", stamp: \" << centernet_3d_output -> image_msg_header_ -> stamp . sec << \".\" << centernet_3d_output -> image_msg_header_ -> stamp . nanosec ; } RCLCPP_DEBUG ( rclcpp :: get_logger ( \"mono3d_indoor_detection\" ), \"%s\" , ss . str (). c_str ()); } const auto & outputs = node_output -> outputs ; RCLCPP_DEBUG ( rclcpp :: get_logger ( \"mono3d_indoor_detection\" ), \"outputs size: %d\" , outputs . size ()); if ( outputs . empty () || static_cast < int32_t > ( outputs . size ()) < model_output_count_ ) { RCLCPP_ERROR ( rclcpp :: get_logger ( \"mono3d_indoor_detection\" ), \"Invalid outputs\" ); return -1 ; } int smart_fps = 0 ; { auto tp_now = std :: chrono :: system_clock :: now (); output_frameCount_ ++ ; auto interval = std :: chrono :: duration_cast < std :: chrono :: milliseconds > ( tp_now - output_tp_ ) . count (); if ( interval >= 1000 ) { smart_fps = output_frameCount_ ; RCLCPP_INFO ( rclcpp :: get_logger ( \"mono3d_indoor_detection\" ), \"Smart fps = %d\" , smart_fps ); output_frameCount_ = 0 ; output_tp_ = std :: chrono :: system_clock :: now (); } } ai_msgs :: msg :: PerceptionTargets :: UniquePtr pub_data ( new ai_msgs :: msg :: PerceptionTargets ()); if ( centernet_3d_output -> image_msg_header_ ) { pub_data -> header . set__stamp ( centernet_3d_output -> image_msg_header_ -> stamp ); pub_data -> header . set__frame_id ( centernet_3d_output -> image_msg_header_ -> frame_id ); } pub_data -> set__fps ( smart_fps ); auto * det_result = dynamic_cast < CenterNet3DDetResult *> ( outputs [ output_index_ ]. get ()); if ( ! det_result ) { RCLCPP_INFO ( rclcpp :: get_logger ( \"mono3d_indoor_detection\" ), \"invalid cast\" ); } else { RCLCPP_DEBUG ( rclcpp :: get_logger ( \"mono3d_indoor_detection\" ), \"out box size: %d\" , det_result -> boxes . size ()); std :: map < std :: string , ai_msgs :: msg :: Target > target_list ; std :: vector < ai_msgs :: msg :: Target > targets ; targets . reserve ( det_result -> boxes . size ()); for ( auto & box : det_result -> boxes ) { ai_msgs :: msg :: Target target ; switch ( box . class_label ) { case BBox3D :: CHARGING_BASE : target . type = \"charging_base\" ; break ; case BBox3D :: SLIPPER : target . type = \"slipper\" ; break ; case BBox3D :: TRASH_CAN : target . type = \"trash_can\" ; break ; } RCLCPP_INFO ( rclcpp :: get_logger ( \"mono3d_detection\" ), \"target type: %s\" , target . type . c_str ()); ai_msgs :: msg :: Attribute attribute ; ai_msgs :: msg :: Point point ; attribute . type = \"width\" ; attribute . value = box . w * 1000. ; RCLCPP_INFO ( rclcpp :: get_logger ( \"mono3d_detection\" ), \"target type: %s, value: %f\" , attribute . type . c_str (), attribute . value ); target . attributes . push_back ( attribute ); attribute . type = \"height\" ; attribute . value = box . h * 1000. ; RCLCPP_INFO ( rclcpp :: get_logger ( \"mono3d_detection\" ), \"target type: %s, value: %f\" , attribute . type . c_str (), attribute . value ); target . attributes . push_back ( attribute ); attribute . type = \"length\" ; attribute . value = box . l * 1000. ; RCLCPP_INFO ( rclcpp :: get_logger ( \"mono3d_detection\" ), \"target type: %s, value: %f\" , attribute . type . c_str (), attribute . value ); target . attributes . push_back ( attribute ); attribute . type = \"rotation\" ; attribute . value = box . r * 1000. ; RCLCPP_INFO ( rclcpp :: get_logger ( \"mono3d_detection\" ), \"target type: %s, value: %f\" , attribute . type . c_str (), attribute . value ); target . attributes . push_back ( attribute ); attribute . type = \"x\" ; attribute . value = box . x * 1000. ; RCLCPP_INFO ( rclcpp :: get_logger ( \"mono3d_detection\" ), \"target type: %s, value: %f\" , attribute . type . c_str (), attribute . value ); target . attributes . push_back ( attribute ); attribute . type = \"y\" ; attribute . value = box . y * 1000. ; RCLCPP_INFO ( rclcpp :: get_logger ( \"mono3d_detection\" ), \"target type: %s, value: %f\" , attribute . type . c_str (), attribute . value ); target . attributes . push_back ( attribute ); attribute . type = \"z\" ; attribute . value = box . z * 1000. ; RCLCPP_INFO ( rclcpp :: get_logger ( \"mono3d_detection\" ), \"target type: %s, value: %f\" , attribute . type . c_str (), attribute . value ); target . attributes . push_back ( attribute ); attribute . type = \"depth\" ; attribute . value = box . d * 1000. ; RCLCPP_INFO ( rclcpp :: get_logger ( \"mono3d_detection\" ), \"target type: %s, value: %f\" , attribute . type . c_str (), attribute . value ); target . attributes . push_back ( attribute ); attribute . type = \"score\" ; attribute . value = box . score * 1000. ; RCLCPP_INFO ( rclcpp :: get_logger ( \"mono3d_detection\" ), \"target type: %s, value: %f\" , attribute . type . c_str (), box . score ); target . attributes . push_back ( attribute ); // 8 corners /* 4----------5 6----------7 /| /| /| /| / | / | / | / | / | / | / | / | 7---|------6 |5---|------4 | | | | || | | | | | | || | | | | 0------|---1| 2------|---3 | / | / | / | / | / ^ | / | / v | / |/ |/ |/ |/ 3----------2 1----------0 */ for ( const auto & corners : box . corners2d_upscale ) { geometry_msgs :: msg :: Point32 g_point ; g_point . x = corners [ 0 ]; g_point . y = corners [ 1 ]; point . point . push_back ( g_point ); } point . type = \"corners\" ; target . points . push_back ( point ); targets . push_back ( target ); } pub_data -> targets = std :: move ( targets ); if ( ! centernet_3d_output -> image_name_ . empty ()) { auto img_bgr = cv :: imread ( centernet_3d_output -> image_name_ ); for ( auto & box : det_result -> boxes ) { Render3DBox ( box , img_bgr ); } std :: string :: size_type iPos = centernet_3d_output -> image_name_ . find_last_of ( '/' ) + 1 ; std :: string filename = centernet_3d_output -> image_name_ . substr ( iPos , centernet_3d_output -> image_name_ . length () - iPos ); cv :: imwrite ( \"./result/\" + filename , img_bgr ); } } clock_gettime ( CLOCK_REALTIME , & time_start ); perf . stamp_end . sec = time_start . tv_sec ; perf . stamp_end . nanosec = time_start . tv_nsec ; pub_data -> perfs . emplace_back ( perf ); msg_publisher_ -> publish ( std :: move ( pub_data )); return 0 ; } int CenterNet3DDetectionNode :: Predict ( std :: vector < std :: shared_ptr < DNNInput >> & inputs , const std :: shared_ptr < std :: vector < hbDNNRoi >> rois , std :: shared_ptr < DnnNodeOutput > dnn_output ) { return Run ( inputs , dnn_output , rois , is_sync_mode_ == 1 ); } void CenterNet3DDetectionNode :: RosImgProcess ( const sensor_msgs :: msg :: Image :: ConstSharedPtr img_msg ) { if ( ! img_msg || ! rclcpp :: ok ()) { return ; } std :: stringstream ss ; ss << \"Recved img encoding: \" << img_msg -> encoding << \", h: \" << img_msg -> height << \", w: \" << img_msg -> width << \", step: \" << img_msg -> step << \", frame_id: \" << img_msg -> header . frame_id << \", stamp: \" << img_msg -> header . stamp . sec << \".\" << img_msg -> header . stamp . nanosec << \", data size: \" << img_msg -> data . size (); RCLCPP_INFO ( rclcpp :: get_logger ( \"mono3d_indoor_detection\" ), \"%s\" , ss . str (). c_str ()); auto tp_start = std :: chrono :: system_clock :: now (); // 1. 将图片处理成模型输入数据类型DNNInput // 使用图片生成pym，NV12PyramidInput为DNNInput的子类 std :: shared_ptr < hobot :: easy_dnn :: NV12PyramidInput > pyramid = nullptr ; if ( \"rgb8\" == img_msg -> encoding ) { #ifdef CV_BRIDGE_PKG_ENABLED auto cv_img = cv_bridge :: cvtColorForDisplay ( cv_bridge :: toCvShare ( img_msg ), \"bgr8\" ); { auto tp_now = std :: chrono :: system_clock :: now (); auto interval = std :: chrono :: duration_cast < std :: chrono :: milliseconds > ( tp_now - tp_start ) . count (); RCLCPP_DEBUG ( rclcpp :: get_logger ( \"mono3d_indoor_detection\" ), \"after cvtColorForDisplay cost ms: %d\" , interval ); } pyramid = ImageUtils :: GetNV12Pyramid ( cv_img -> image , model_input_height_ , model_input_width_ ); #else RCLCPP_ERROR ( rclcpp :: get_logger ( \"mono3d_indoor_detection\" ), \"Unsupport cv bridge\" ); #endif } else if ( \"nv12\" == img_msg -> encoding ) { pyramid = ImageUtils :: GetNV12PyramidFromNV12Img ( reinterpret_cast < const char *> ( img_msg -> data . data ()), img_msg -> height , img_msg -> width , model_input_height_ , model_input_width_ ); } if ( ! pyramid ) { RCLCPP_ERROR ( rclcpp :: get_logger ( \"mono3d_indoor_detection\" ), \"Get Nv12 pym fail\" ); return ; } { auto tp_now = std :: chrono :: system_clock :: now (); auto interval = std :: chrono :: duration_cast < std :: chrono :: milliseconds > ( tp_now - tp_start ) . count (); RCLCPP_DEBUG ( rclcpp :: get_logger ( \"mono3d_indoor_detection\" ), \"after GetNV12Pyramid cost ms: %d\" , interval ); } RCLCPP_INFO ( rclcpp :: get_logger ( \"mono3d_indoor_detection\" ), \"Dnn node begin to predict\" ); // 2. 使用pyramid创建DNNInput对象inputs // inputs将会作为模型的输入通过RunInferTask接口传入 auto inputs = std :: vector < std :: shared_ptr < DNNInput >> { pyramid }; auto dnn_output = std :: make_shared < CenterNet3DOutput > (); dnn_output -> src_img_width_ = img_msg -> width ; dnn_output -> src_img_height_ = img_msg -> height ; dnn_output -> image_msg_header_ = std :: make_shared < std_msgs :: msg :: Header > (); dnn_output -> image_msg_header_ -> set__frame_id ( img_msg -> header . frame_id ); dnn_output -> image_msg_header_ -> set__stamp ( img_msg -> header . stamp ); dnn_output -> image_name_ = \"\" ; // 3. 开始预测 uint32_t ret = Predict ( inputs , nullptr , dnn_output ); { auto tp_now = std :: chrono :: system_clock :: now (); auto interval = std :: chrono :: duration_cast < std :: chrono :: milliseconds > ( tp_now - tp_start ) . count (); RCLCPP_DEBUG ( rclcpp :: get_logger ( \"mono3d_indoor_detection\" ), \"after Predict cost ms: %d\" , interval ); } if ( ret != 0 ) { RCLCPP_ERROR ( rclcpp :: get_logger ( \"mono3d_indoor_detection\" ), \"predict img failed!\" ); } return ; } int CenterNet3DDetectionNode :: PredictByImage ( const std :: string & image ) { // 1. 将图片处理成模型输入数据类型DNNInput // 使用图片生成pym，NV12PyramidInput为DNNInput的子类 std :: shared_ptr < hobot :: easy_dnn :: NV12PyramidInput > pyramid = nullptr ; // bgr img，支持将图片resize到模型输入size pyramid = ImageUtils :: GetNV12Pyramid ( image , ImageType :: BGR , model_input_height_ , model_input_width_ ); if ( ! pyramid ) { RCLCPP_ERROR ( rclcpp :: get_logger ( \"mono3d_indoor_detection\" ), \"Get Nv12 pym fail with image: %s\" , image . c_str ()); return -1 ; } // 2. 使用pyramid创建DNNInput对象inputs // inputs将会作为模型的输入通过RunInferTask接口传入 auto inputs = std :: vector < std :: shared_ptr < DNNInput >> { pyramid }; auto dnn_output = std :: make_shared < CenterNet3DOutput > (); dnn_output -> src_img_width_ = 1920 ; dnn_output -> src_img_height_ = 1024 ; dnn_output -> image_msg_header_ = std :: make_shared < std_msgs :: msg :: Header > (); dnn_output -> image_msg_header_ -> set__frame_id ( \"test_frame\" ); dnn_output -> image_msg_header_ -> set__stamp ( rclcpp :: Time ()); dnn_output -> image_name_ = image ; // dnn_output->image_msg_header->set__frame_id(std::to_string(img_msg->index)); // dnn_output->image_msg_header->set__stamp(img_msg->time_stamp); // 3. 开始预测 uint32_t ret = Predict ( inputs , nullptr , dnn_output ); if ( ret != 0 ) { RCLCPP_ERROR ( rclcpp :: get_logger ( \"mono3d_indoor_detection\" ), \"predict img failed!\" ); } return ret ; } #ifdef SHARED_MEM_ENABLED void CenterNet3DDetectionNode :: SharedMemImgProcess ( const hbm_img_msgs :: msg :: HbmMsg1080P :: ConstSharedPtr img_msg ) { if ( ! img_msg || ! rclcpp :: ok ()) { return ; } RCLCPP_DEBUG ( rclcpp :: get_logger ( \"mono3d_indoor_detection\" ), \"go into shared mem\" ); // dump recved img msg // std::ofstream ofs(\"img_\" + std::to_string(img_msg->index) + \".\" + // std::string(reinterpret_cast<const char*>(img_msg->encoding.data()))); // ofs.write(reinterpret_cast<const char*>(img_msg->data.data()), // img_msg->data_size); auto tp_start = std :: chrono :: system_clock :: now (); // 1. 将图片处理成模型输入数据类型DNNInput // 使用图片生成pym，NV12PyramidInput为DNNInput的子类 std :: shared_ptr < hobot :: easy_dnn :: NV12PyramidInput > pyramid = nullptr ; if ( \"nv12\" == std :: string ( reinterpret_cast < const char *> ( img_msg -> encoding . data ()))) { pyramid = ImageUtils :: GetNV12PyramidFromNV12Img ( reinterpret_cast < const char *> ( img_msg -> data . data ()), img_msg -> height , img_msg -> width , model_input_height_ , model_input_width_ ); } else { RCLCPP_INFO ( rclcpp :: get_logger ( \"mono3d_indoor_detection\" ), \"share mem unsupported img encoding: %s\" , img_msg -> encoding ); } if ( ! pyramid ) { RCLCPP_ERROR ( rclcpp :: get_logger ( \"mono3d_indoor_detection\" ), \"Get Nv12 pym fail!\" ); return ; } { auto tp_now = std :: chrono :: system_clock :: now (); auto interval = std :: chrono :: duration_cast < std :: chrono :: milliseconds > ( tp_now - tp_start ) . count (); RCLCPP_DEBUG ( rclcpp :: get_logger ( \"mono3d_indoor_detection\" ), \"after GetNV12Pyramid cost ms: %d\" , interval ); } // 2. 使用pyramid创建DNNInput对象inputs // inputs将会作为模型的输入通过RunInferTask接口传入 auto inputs = std :: vector < std :: shared_ptr < DNNInput >> { pyramid }; auto dnn_output = std :: make_shared < CenterNet3DOutput > (); dnn_output -> src_img_width_ = img_msg -> width ; dnn_output -> src_img_height_ = img_msg -> height ; dnn_output -> image_msg_header_ = std :: make_shared < std_msgs :: msg :: Header > (); dnn_output -> image_msg_header_ -> set__frame_id ( std :: to_string ( img_msg -> index )); dnn_output -> image_msg_header_ -> set__stamp ( img_msg -> time_stamp ); // 3. 开始预测 int ret = Predict ( inputs , nullptr , dnn_output ); { auto tp_now = std :: chrono :: system_clock :: now (); auto interval = std :: chrono :: duration_cast < std :: chrono :: milliseconds > ( tp_now - tp_start ) . count (); RCLCPP_DEBUG ( rclcpp :: get_logger ( \"mono3d_indoor_detection\" ), \"after Predict cost ms: %d\" , interval ); } // 4. 处理预测结果，如渲染到图片或者发布预测结果 if ( ret != 0 ) { RCLCPP_ERROR ( rclcpp :: get_logger ( \"mono3d_indoor_detection\" ), \"Run predict failed!\" ); } return ; } #endif","text_tokens":["copyright","settype","frame","bind","constsharedptr","put","setoutputdescription","，","static","conditions","msgs","predict","parameter","break","unless","distributed","language","under","|","declare","governing","class","nv12","nullptr","通过","3.0","create","boxes","pkg","d","ai","go","h","2.0","by","p0","imageutils","dection","milliseconds","step","topic","move","license","attribute","生成","i","[","dnninput","\\","使用","dump","struct","detection","charging","time","fstream","w","ipos","rois","stringstream","centernet3doutputparser","ofstream","manage","image","如","r","n","sys","sec","src","not","in","subscription","compliance","and","~","example","render3dbox","setoutputparser","+","l","corners2d","mem","cout","out","http","666","模型","define","attributes","height","imagetype","5","getmodelinputsize","last","]","draw","include","box","cvtcolorfordisplay","sub","__","'","const","ret","---","成","pym","robotics","paser","law","encoding","init","obtain","emplace","path","depth","push","stamp","3d","=","invalid","may","nv12pyramidinput","bbox3d","to","unsupport","rgb8","(","sync","perf","is","smart","branch","warranties","endl","count","2","licenses","font","applicable","task","as","getmodel","pyramid","of","渲染","express","getnv12pyramid","\"",".","using","limitations","unsupported","org","hbmem","ok","without","width","1","switch","1920","nanosec","substr","system","text","uint32","图片","sharedmemimgprocess","options","base","stat","dnn","dnnnodeoutput","horizon","void","py","map","sensor","utils","timespec","unistd","licensed","centernet","y","share","ptr","类型","implied","assist","info","config","test","either","interval","success","------","int32","结果","indoor","++","mono3d","find","fps","perceptiontargets","将","postprocess","8","value","writing","cast","use","hobot","sharedmem","g","label","/","input","case","预测","_","list","hersheyfonts","到","desc","runinfertask","str","%","s","index","imread","3","string","offset","at","10","specific","feed","or","read","point","!",":","reinterpret","dynamic","except","}","targets","{","unmatch","perfs","p1","hbmmsg1080p","dnnnode","file","rotation","if",";","0","name","uniqueptr","puttext","framecount","px","detect","发布","an","fail","run","nsec","对象","t","开始","传入","pub","7","permissions","ms","resize","www",")","placeholders","thickness","&","write","centernet3doutput","数据类型","for","return","upscale","pointer","inputs","int","outputdescription","publisher","f","ofs","result","*","begin","node","rect","6","required","nodeoptions","接口","basis","plain","back","#","get","line","subscriptions","reserve","getnv12pyramidfromnv12img","easy","this","处理","rclcpp","char","128","<","hpp",">","men","hbdnnroi","mode","mat","data","getdependencies","size","msg","数据","that","model","ros","输入","output","gettextsize","tocvshare","255","getoutputcount","new","z","you","duration","logger","any","memory","empty","支持","cv","c","v","on","bgr8","publish","after","version","software","img","into","tv","clock","else","id","x","centernet3ddetectionnode","m","kind"," ","type","centernet3ddetresult","agreed","trash","rgb","-","double","chrono","parser","failed","shared","end","point32","copy","num","target","can","fontscale","baseline","a","子类","hershey","imwrite","tp","images","endif","enabled","centernet3dassistparser","std","----------","gettime","bridge","setnodepara","ifdef","corners","filename","cost","debug","see","slipper","det","rosimgprocess","outputs","score","header","geometry","pi","的","vector","error","warn","2022","ss","points","hbm","outputparser","predictbyimage","para","set","the","bgr","now","apache","1000","recved","作为","mkdir","3u",",","auto","make","为","或者","length","^","创建","start","将会","realtime","1024","with","4"],"title":"代码解析","title_tokens":["解析","代码"]},{"location":"hhp/6.1_SLAM%E5%BB%BA%E5%9B%BE/","text":"SLAM建图 从这一节开始，我们开始尝试将 TogetherROS 与机器人联系起来做一些小项目。 第一节将开始学习 SLAM 技术。SLAM一般指即时定位与地图构建，即时定位与地图构建（Simultaneous Localization and Mapping，简称SLAM） 这个章节，我们将联系ROS2 和 TogetherROS ，使用 ROS2 的 SLAM-Toolbox 作为建图算法，在仿真环境中构建地图。 准备工作 1、安装 SLAM - Toolbox建立软链接 $ sudo apt-get install ros-foxy-slam-toolbox $ cd /opt/tros $ sudo python3 create_soft_link.py --foxy /opt/ros/foxy/ --tros /opt/tros/ 2、搭载仿真环境，此处采用 turtlebot3 仿真环境 $ sudo apt-get install ros-foxy-gazebo-* $ sudo apt install ros-foxy-turtlebot3 $ sudo apt install ros-foxy-turtlebot3-bringup $ sudo apt install ros-foxy-turtlebot3-simulations $ sudo apt install ros-foxy-teleop-twist-keyboard 使用介绍 首先在 PC 端启动仿真环境 $ source /opt/ros/foxy/setup.bash $ export TURTLEBOT3_MODEL = burger $ ros2 launch turtlebot3_gazebo turtlebot3_world.launch.py Attention 第一次加载可能比较慢，原因是正在下载部分需要的插件。 打开后，即可看到如图: 在PC端打开一个新终端： $ source /opt/ros/foxy/setup.bash $ ros2 launch turtlebot3_bringup rviz2.launch.py 此时会打开一个RVIZ2 ，需要添加“map” 如下图： 旭日X3 派运行 SLAM-Toolbox： # 配置TogetherROS环境 $ source /opt/tros/setup.bash #启动SLAM launch文件 $ ros2 launch slam_toolbox online_sync_launch.py 此处有可能会遇到缺少lib文件问题，如果发生的话如下操作： $ sudo vi /etc/ld.so.conf #在其后增加： /usr/local/lib #保存退出： $ sudo ldconfig PC端再打开一个新终端，遥控建图： $ source /opt/ros/foxy/setup.bash $ ros2 run teleop_twist_keyboard teleop_twist_keyboard 效果如图： 建图结果","text_tokens":["章节","soft","simulations",":","=","此处","slam","构建","local","即时","首先","看到","仿真","so","从","地图","bringup","，","机器","建立","sync","工作","sudo","退出","vi","软","指","2","联系","attention"," ","这个","定位","mapping","效果","图","run","-","环境","twist","tros","开始","插件","create",".","安装","问题","比较慢","会","这","toolbox","一个","发生","usr","与","派","：","机器人","技术","1","link","配置","。","加载","“","再","keyboard","install","launch","后","etc","turtlebot3","终端","使用","采用","ldconfig","正在","py","*","map","一般","保存","添加","中","学习","（","opt","togetherros","ld","localization","rviz2","起来","#","get","缺少","小","、","apt","可能","遇到","）","比较","我们","增加","的","项目","启动","结果","介绍","链接","其后","online","是","如图","准备","setup","将","第一节","ros2","一节","算法","and","--","一次","即可","旭日","尝试","teleop","$","一些","/","在","model","部分","_","如下","simultaneous","较慢","”","打开","的话","burger","python3","搭载","ros","建图","和","x3","作为","下载","原因","遥控","简称","pc","gazebo","新","foxy","export","端","操作","lib","如果","world","第一","第一次","cd","此时","有","conf","文件","做","bash","需要","source","运行"],"title":"SLAM地图构建","title_tokens":["构建","地图","slam"]},{"location":"hhp/6.1_SLAM%E5%BB%BA%E5%9B%BE/#slam","text":"从这一节开始，我们开始尝试将 TogetherROS 与机器人联系起来做一些小项目。 第一节将开始学习 SLAM 技术。SLAM一般指即时定位与地图构建，即时定位与地图构建（Simultaneous Localization and Mapping，简称SLAM） 这个章节，我们将联系ROS2 和 TogetherROS ，使用 ROS2 的 SLAM-Toolbox 作为建图算法，在仿真环境中构建地图。","text_tokens":["（","章节","togetherros","localization","尝试","起来","一些","在","slam","这","构建","simultaneous","小","即时","toolbox","仿真","建图","与","从","地图","和","机器人","，","机器","技术","）","我们","算法","作为","的","中","。","项目","指","简称","联系"," ","这个","定位","mapping","使用","第一","将","第一节","-","ros2","环境","做","一节","一般","and","开始","学习"],"title":"SLAM建图","title_tokens":["建图","slam"]},{"location":"hhp/6.1_SLAM%E5%BB%BA%E5%9B%BE/#_1","text":"1、安装 SLAM - Toolbox建立软链接 $ sudo apt-get install ros-foxy-slam-toolbox $ cd /opt/tros $ sudo python3 create_soft_link.py --foxy /opt/ros/foxy/ --tros /opt/tros/ 2、搭载仿真环境，此处采用 turtlebot3 仿真环境 $ sudo apt-get install ros-foxy-gazebo-* $ sudo apt install ros-foxy-turtlebot3 $ sudo apt install ros-foxy-turtlebot3-bringup $ sudo apt install ros-foxy-turtlebot3-simulations $ sudo apt install ros-foxy-teleop-twist-keyboard","text_tokens":["soft","opt","安装","teleop","$","simulations","/","get","此处","slam","_","toolbox","python3","、","ros","搭载","仿真","apt","1","，","bringup","link","建立","sudo","软","keyboard","2","gazebo","链接","install","foxy"," ","turtlebot3","采用","-","cd","py","环境","*","twist","tros","--","create","."],"title":"准备工作","title_tokens":["工作","准备"]},{"location":"hhp/6.1_SLAM%E5%BB%BA%E5%9B%BE/#_2","text":"首先在 PC 端启动仿真环境 $ source /opt/ros/foxy/setup.bash $ export TURTLEBOT3_MODEL = burger $ ros2 launch turtlebot3_gazebo turtlebot3_world.launch.py Attention 第一次加载可能比较慢，原因是正在下载部分需要的插件。 打开后，即可看到如图: 在PC端打开一个新终端： $ source /opt/ros/foxy/setup.bash $ ros2 launch turtlebot3_bringup rviz2.launch.py 此时会打开一个RVIZ2 ，需要添加“map” 如下图： 旭日X3 派运行 SLAM-Toolbox： # 配置TogetherROS环境 $ source /opt/tros/setup.bash #启动SLAM launch文件 $ ros2 launch slam_toolbox online_sync_launch.py 此处有可能会遇到缺少lib文件问题，如果发生的话如下操作： $ sudo vi /etc/ld.so.conf #在其后增加： /usr/local/lib #保存退出： $ sudo ldconfig PC端再打开一个新终端，遥控建图： $ source /opt/ros/foxy/setup.bash $ ros2 run teleop_twist_keyboard teleop_twist_keyboard 效果如图：","text_tokens":[":","=","此处","slam","local","首先","看到","仿真","so","bringup","，","sync","sudo","退出","vi","attention"," ","效果","图","run","-","环境","twist","tros","插件",".","问题","比较慢","会","toolbox","一个","发生","usr","派","：","配置","。","加载","“","再","keyboard","launch","后","etc","turtlebot3","终端","ldconfig","正在","py","map","保存","添加","opt","togetherros","ld","rviz2","#","缺少","可能","遇到","比较","增加","的","启动","其后","online","是","如图","setup","ros2","旭日","即可","一次","teleop","$","/","在","如下","model","_","部分","较慢","”","的话","打开","burger","ros","建图","x3","下载","原因","遥控","pc","gazebo","新","foxy","export","端","操作","lib","如果","world","第一","第一次","此时","有","conf","文件","运行","bash","需要","source"],"title":"使用介绍","title_tokens":["使用","介绍"]},{"location":"hhp/6.1_SLAM%E5%BB%BA%E5%9B%BE/#_3","text":"","text_tokens":[],"title":"建图结果","title_tokens":["建图","结果"]},{"location":"hhp/6.2_%E5%B0%8F%E8%BD%A6%E4%BA%BA%E4%BD%93%E8%B7%9F%E9%9A%8F/","text":"小车人体跟随 之前我们介绍了如何利用 X3派 进行人体检测和跟踪，那么加入我们想要将体检测和跟踪和真实机器人做一个结合会是一种什么样的体验呢？ 这里，我们将通过X3派检测到的人体目标进行一个移动跟踪，最终的一个效果就是当装配着X3派和摄像头的小车面前出现一个人物时，小车将会跟随着人体一起移动。接下来，让我们一起来体验一下吧。 编程开发方法 先来看整个程序的流程图： 这里，我们将通过 Gazebo 仿真环境下的虚拟小车作为真实机器，首先，让我们来做一些准备工作。 在PC端搭建一个仿真环境： $ sudo apt-get install ros-foxy-gazebo-* $ sudo apt install ros-foxy-turtlebot3 $ sudo apt install ros-foxy-turtlebot3-simulations 使用介绍 首先在 PC 端启动仿真环境 $ source /opt/ros/foxy/setup.bash $ export TURTLEBOT3_MODEL = burger $ ros2 launch turtlebot3_gazebo empty_world.launch.py Attention 第一次加载可能比较慢，原因是正在下载部分需要的插件。 如下图所见： 旭日X3 派运行 如下指令： # 配置TogetherROS环境 $ source /opt/tros/setup.bash # 从TogetherROS的安装路径中拷贝出运行示例需要的配置文件。 $ cp -r /opt/tros/lib/mono2d_body_detection/config/ . #启动launch文件 $ ros2 launch body_tracking hobot_body_tracking_without_gesture.launch.py 接下来，只需要你站在摄像头面前左右前后移动，就会发现仿真环境下的小车也会跟着你移动。 再来看终端输出的信息： $ ros2 topic echo /cmd_vel linear: x: 0.5 y: 0.0 z: 0.0 angular: x: 0.0 y: 0.0 z: -0.5 --- linear: x: 0.5 y: 0.0 z: 0.0 angular: x: 0.0 y: 0.0 z: -0.5 --- 跟随效果","text_tokens":["0.0","出现","simulations","左右","echo","mono2d","一起","=",":","一种","cp","首先","就","进行","仿真","从","，","机器","x","将体","工作","sudo","站","如何","？","结合","你","真实","attention","出"," ","编程","拷贝","了","效果","-","angular","来看","环境","人物","tros","通过","流程","插件",".","示例","安装","先","利用","程序","随着","目标","输出","配置文件","会","比较慢","一个","without","派","：","机器人","就是","来","vel","配置","。","什么样","加载","搭建","小车","让","topic","再","install","launch","turtlebot3","tracking","开发","终端","使用","之前","吧","正在","人体","*","py","detection","虚拟","着","中","跟随","当","opt","togetherros","y","起来","什么","方法","发现","加入","#","get","也","config","一","apt","摄像头","可能","比较","图所见","我们","cmd","的","r","体验","所见","摄像","启动","路径","0.5","介绍","是","最终","开发方法","准备","检测","只","setup","将","接下来","想要","ros2","跟着","信息","那么","hobot","一下","装配","一次","旭日","前后","跟","$","一些","这里","/","像头","下来","在","model","呢","_","整个","较慢","部分","下","如下","指令","移动","时","burger","ros","跟踪","到","和","linear","x3","面前","作为","下载","原因","body","gesture","pc","gazebo","foxy","export","端","---","lib","world","接下","将会","第一","第一次","z","流程图","empty","文件","做","bash","需要","source","运行"],"title":"小车人体跟随","title_tokens":["人体","小车","跟随"]},{"location":"hhp/6.2_%E5%B0%8F%E8%BD%A6%E4%BA%BA%E4%BD%93%E8%B7%9F%E9%9A%8F/#_1","text":"之前我们介绍了如何利用 X3派 进行人体检测和跟踪，那么加入我们想要将体检测和跟踪和真实机器人做一个结合会是一种什么样的体验呢？ 这里，我们将通过X3派检测到的人体目标进行一个移动跟踪，最终的一个效果就是当装配着X3派和摄像头的小车面前出现一个人物时，小车将会跟随着人体一起移动。接下来，让我们一起来体验一下吧。","text_tokens":["当","出现","跟","利用","起来","什么","一起","随着","一种","这里","加入","目标","像头","下来","会","呢","着","一个","移动","进行","时","一","派","跟踪","到","和","摄像头","x3","机器人","，","机器","就是","面前","我们","将体","的","如何","？","。","结合","什么样","体验","小车","让","摄像","介绍","真实"," ","了","是","最终","效果","检测","接下","将会","将","之前","想要","接下来","吧","人体","一下","做","人物","通过","那么","装配"],"title":"小车人体跟随","title_tokens":["人体","小车","跟随"]},{"location":"hhp/6.2_%E5%B0%8F%E8%BD%A6%E4%BA%BA%E4%BD%93%E8%B7%9F%E9%9A%8F/#_2","text":"先来看整个程序的流程图： 这里，我们将通过 Gazebo 仿真环境下的虚拟小车作为真实机器，首先，让我们来做一些准备工作。 在PC端搭建一个仿真环境： $ sudo apt-get install ros-foxy-gazebo-* $ sudo apt install ros-foxy-turtlebot3 $ sudo apt install ros-foxy-turtlebot3-simulations","text_tokens":["先","$","simulations","程序","一些","这里","在","get","整个","下","首先","一个","仿真","ros","apt","：","，","机器","我们","来","作为","的","工作","sudo","。","搭建","小车","让","pc","gazebo","真实","install","foxy"," ","turtlebot3","端","准备","将","-","来看","流程图","环境","*","做","虚拟","通过","流程"],"title":"编程开发方法","title_tokens":["开发方法","编程","开发","方法"]},{"location":"hhp/6.2_%E5%B0%8F%E8%BD%A6%E4%BA%BA%E4%BD%93%E8%B7%9F%E9%9A%8F/#_3","text":"首先在 PC 端启动仿真环境 $ source /opt/ros/foxy/setup.bash $ export TURTLEBOT3_MODEL = burger $ ros2 launch turtlebot3_gazebo empty_world.launch.py Attention 第一次加载可能比较慢，原因是正在下载部分需要的插件。 如下图所见： 旭日X3 派运行 如下指令： # 配置TogetherROS环境 $ source /opt/tros/setup.bash # 从TogetherROS的安装路径中拷贝出运行示例需要的配置文件。 $ cp -r /opt/tros/lib/mono2d_body_detection/config/ . #启动launch文件 $ ros2 launch body_tracking hobot_body_tracking_without_gesture.launch.py 接下来，只需要你站在摄像头面前左右前后移动，就会发现仿真环境下的小车也会跟着你移动。 再来看终端输出的信息： $ ros2 topic echo /cmd_vel linear: x: 0.5 y: 0.0 z: 0.0 angular: x: 0.0 y: 0.0 z: -0.5 --- linear: x: 0.5 y: 0.0 z: 0.0 angular: x: 0.0 y: 0.0 z: -0.5 ---","text_tokens":["0.0","左右","echo","mono2d","=",":","cp","首先","就","仿真","从","，","x","站","你","attention","出"," ","拷贝","-","angular","来看","环境","tros","插件",".","示例","安装","输出","配置文件","比较慢","会","without","派","：","vel","配置","。","加载","小车","topic","再","launch","turtlebot3","tracking","终端","正在","py","detection","中","opt","togetherros","y","发现","#","也","config","摄像头","可能","比较","图所见","cmd","的","r","所见","摄像","启动","路径","0.5","是","只","setup","接下来","ros2","跟着","信息","hobot","旭日","一次","前后","$","/","下来","像头","在","model","部分","_","如下","较慢","下","指令","burger","移动","ros","linear","x3","面前","下载","原因","body","gesture","pc","gazebo","foxy","export","端","---","lib","world","接下","第一","第一次","z","empty","文件","运行","bash","需要","source"],"title":"使用介绍","title_tokens":["使用","介绍"]},{"location":"hhp/6.2_%E5%B0%8F%E8%BD%A6%E4%BA%BA%E4%BD%93%E8%B7%9F%E9%9A%8F/#_4","text":"","text_tokens":[],"title":"跟随效果","title_tokens":["跟随","效果"]}]}